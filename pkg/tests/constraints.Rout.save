
R version 2.13.2 (2011-09-30)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: i686-pc-linux-gnu (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### Various tests for constrained optimization
> ###
> 
> logLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    ll <- log(rho*dnorm(x - mu1) + (1 - rho)*dnorm(x - mu2))
+ #   ll <- sum(ll)
+    ll
+ }
> 
> gradLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    g <- matrix(0, length(x), 3)
+    g[,1] <- (f1 - f2)/L
+    g[,2] <- rho*(x - mu1)*f1/L
+    g[,3] <- (1 - rho)*(x - mu2)*f2/L
+ #   colSums(g)
+    g
+ }
> 
> hessLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    dldrho <- (f1 - f2)/L
+    dldmu1 <- rho*(x - mu1)*f1/L
+    dldmu2 <- (1 - rho)*(x - mu2)*f2/L
+    h <- matrix(0, 3, 3)
+    h[1,1] <- -sum(dldrho*(f1 - f2)/L)
+    h[2,1] <- h[1,2] <- sum((x - mu1)*f1/L - dldmu1*dldrho)
+    h[3,1] <- h[1,3] <- sum(-(x - mu2)*f2/L - dldmu2*dldrho)
+    h[2,2] <- sum(rho*(-f1 + (x - mu1)^2*f1)/L - dldmu1^2)
+    h[2,3] <- h[3,2] <- -sum(dldmu1*dldmu2)
+    h[3,3] <- sum((1 - rho)*(-f2 + (x - mu2)^2*f2)/L - dldmu2^2)
+    h
+ }
> ### --------------------------
> library(maxLik)
Loading required package: miscTools
> ## mixed normal
> set.seed(1)
> x <- c(rnorm(1000, mean=-1), rnorm(1000, mean=1))
> 
> cat("Test for inequality constraints\n")
Test for inequality constraints
> A <- matrix(c(-1, 0, 0,
+               0, -1, 0,
+               0, 0, 1), 3, 3, byrow=TRUE)
> B <- c(0.5, 1, 1)
> start <- c(0.4, 0, 0.9)
>                            # x < 0.5, y < 1, z < 1
> ## analytic gradient
> a <- maxLik(logLikMix, grad=gradLikMix, hess=hessLikMix,
+             start=start,
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
initial  value 4001.919360 
iter   2 value 3924.195249
iter   3 value 3761.072160
iter   4 value 3740.857495
iter   5 value 3739.836050
iter   6 value 3739.669310
iter   7 value 3739.505188
iter   8 value 3739.342555
iter   9 value 3739.271535
iter  10 value 3674.195730
iter  11 value 3671.068533
iter  12 value 3626.169748
iter  13 value 3589.952708
iter  14 value 3552.974360
iter  15 value 3551.811747
iter  16 value 3551.806169
iter  17 value 3551.796640
iter  18 value 3551.796393
iter  19 value 3551.782451
iter  20 value 3551.776235
iter  21 value 3551.776079
iter  22 value 3551.775692
iter  23 value 3551.774739
iter  24 value 3551.773814
iter  25 value 3551.773649
iter  26 value 3551.773567
iter  27 value 3551.773467
iter  27 value 3551.773450
iter  27 value 3551.773444
final  value 3551.773444 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 135 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.499998   0.025622  19.514 < 2.2e-16 ***
[2,] -1.035820   0.058120 -17.822 < 2.2e-16 ***
[3,]  1.011114   0.058412  17.310 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -8.064254e-05 
--------------------------------------------
> ## No analytic gradient
> a <- maxLik(logLikMix, 
+             start=start,
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
  Nelder-Mead direct search function minimizer
function value for initial parameters = 4001.919360
  Scaled convergence tolerance is 4.00192e-05
Stepsize computed as 0.090000
BUILD              4 4070.076454 3935.045207
EXTENSION          6 4019.701042 3817.775267
HI-REDUCTION       8 4001.919360 3817.775267
HI-REDUCTION      10 3964.166832 3817.775267
HI-REDUCTION      12 3951.510182 3817.775267
HI-REDUCTION      14 3935.045207 3817.775267
LO-REDUCTION      16 3930.566709 3817.775267
EXTENSION         18 3921.548057 3738.446564
REFLECTION        20 3849.017620 3697.331710
HI-REDUCTION      22 3817.775267 3697.331710
EXTENSION         24 3796.153961 3640.588444
REFLECTION        26 3738.446564 3610.867457
REFLECTION        28 3697.331710 3599.961281
LO-REDUCTION      30 3640.588444 3598.894741
REFLECTION        32 3610.867457 3582.230731
LO-REDUCTION      34 3599.961281 3582.230731
LO-REDUCTION      36 3598.894741 3582.230731
LO-REDUCTION      38 3596.438042 3582.230731
HI-REDUCTION      40 3591.172016 3582.230731
REFLECTION        42 3589.835414 3581.931032
HI-REDUCTION      44 3588.467346 3581.931032
EXTENSION         46 3586.686573 3580.648373
HI-REDUCTION      48 3583.294465 3580.648373
HI-REDUCTION      50 3582.230731 3580.648373
EXTENSION         52 3581.931032 3577.585887
HI-REDUCTION      54 3581.845094 3577.585887
HI-REDUCTION      56 3580.648373 3577.585887
LO-REDUCTION      58 3580.218011 3577.585887
REFLECTION        60 3580.057953 3577.484209
HI-REDUCTION      62 3579.426065 3577.484209
HI-REDUCTION      64 3578.981897 3577.484209
HI-REDUCTION      66 3578.579262 3577.484209
HI-REDUCTION      68 3578.345661 3577.484209
REFLECTION        70 3578.107041 3576.925041
HI-REDUCTION      72 3577.645941 3576.925041
HI-REDUCTION      74 3577.585887 3576.925041
LO-REDUCTION      76 3577.484209 3576.925041
LO-REDUCTION      78 3577.429087 3576.925041
HI-REDUCTION      80 3577.265061 3576.925041
LO-REDUCTION      82 3577.219538 3576.925041
HI-REDUCTION      84 3577.099728 3576.925041
HI-REDUCTION      86 3577.094501 3576.925041
LO-REDUCTION      88 3577.049601 3576.925041
REFLECTION        90 3577.022785 3576.878692
HI-REDUCTION      92 3576.964128 3576.878692
HI-REDUCTION      94 3576.958912 3576.878692
HI-REDUCTION      96 3576.939646 3576.878692
LO-REDUCTION      98 3576.934165 3576.878692
HI-REDUCTION     100 3576.925041 3576.878692
REFLECTION       102 3576.914390 3576.868685
HI-REDUCTION     104 3576.895203 3576.868685
HI-REDUCTION     106 3576.885769 3576.868685
HI-REDUCTION     108 3576.884633 3576.868685
EXTENSION        110 3576.881093 3576.859943
EXTENSION        112 3576.878692 3576.845912
LO-REDUCTION     114 3576.868685 3576.845912
EXTENSION        116 3576.859943 3576.826521
LO-REDUCTION     118 3576.849995 3576.826521
EXTENSION        120 3576.845912 3576.795330
LO-REDUCTION     122 3576.830662 3576.795330
EXTENSION        124 3576.826521 3576.770660
EXTENSION        126 3576.813020 3576.731071
EXTENSION        128 3576.795330 3576.670275
EXTENSION        130 3576.770660 3576.579130
EXTENSION        132 3576.731071 3576.442870
EXTENSION        134 3576.670275 3576.223364
EXTENSION        136 3576.579130 3575.955644
EXTENSION        138 3576.442870 3575.458073
EXTENSION        140 3576.223364 3574.737467
EXTENSION        142 3575.955644 3574.113654
EXTENSION        144 3575.458073 3572.466880
EXTENSION        146 3574.737467 3571.094709
LO-REDUCTION     148 3574.113654 3571.094709
EXTENSION        150 3572.466880 3567.948568
LO-REDUCTION     152 3571.223114 3567.948568
EXTENSION        154 3571.094709 3566.372458
LO-REDUCTION     156 3569.258169 3566.372458
EXTENSION        158 3567.948568 3563.385192
LO-REDUCTION     160 3567.462407 3563.385192
EXTENSION        162 3566.372458 3560.575507
LO-REDUCTION     164 3565.263653 3560.575507
EXTENSION        166 3563.385192 3555.903789
LO-REDUCTION     168 3560.581694 3555.903789
EXTENSION        170 3560.575507 3553.680731
LO-REDUCTION     172 3555.955914 3553.680731
LO-REDUCTION     174 3555.903789 3553.680731
LO-REDUCTION     176 3553.731647 3553.519969
HI-REDUCTION     178 3553.718501 3553.519969
REFLECTION       180 3553.680731 3553.510150
HI-REDUCTION     182 3553.573002 3553.510150
HI-REDUCTION     184 3553.529569 3553.501483
HI-REDUCTION     186 3553.519969 3553.490503
HI-REDUCTION     188 3553.510150 3553.489948
HI-REDUCTION     190 3553.501483 3553.489749
HI-REDUCTION     192 3553.490503 3553.488040
HI-REDUCTION     194 3553.489948 3553.485470
HI-REDUCTION     196 3553.489749 3553.485400
LO-REDUCTION     198 3553.488040 3553.485400
LO-REDUCTION     200 3553.485918 3553.484736
HI-REDUCTION     202 3553.485470 3553.484665
HI-REDUCTION     204 3553.485400 3553.484665
HI-REDUCTION     206 3553.484736 3553.484560
HI-REDUCTION     208 3553.484683 3553.484512
EXTENSION        210 3553.484665 3553.484220
HI-REDUCTION     212 3553.484560 3553.484220
LO-REDUCTION     214 3553.484512 3553.484220
EXTENSION        216 3553.484324 3553.483588
LO-REDUCTION     218 3553.484267 3553.483588
LO-REDUCTION     220 3553.484220 3553.483588
EXTENSION        222 3553.483927 3553.482745
EXTENSION        224 3553.483737 3553.482058
LO-REDUCTION     226 3553.483588 3553.482058
EXTENSION        228 3553.482745 3553.479736
LO-REDUCTION     230 3553.482159 3553.479736
EXTENSION        232 3553.482058 3553.477735
EXTENSION        234 3553.479813 3553.473219
LO-REDUCTION     236 3553.479736 3553.473219
EXTENSION        238 3553.477735 3553.466921
EXTENSION        240 3553.474260 3553.460407
EXTENSION        242 3553.473219 3553.452338
EXTENSION        244 3553.466921 3553.445248
EXTENSION        246 3553.460407 3553.439273
REFLECTION       248 3553.452338 3553.437117
HI-REDUCTION     250 3553.445248 3553.437117
REFLECTION       252 3553.442085 3553.436427
HI-REDUCTION     254 3553.439273 3553.436427
EXTENSION        256 3553.437623 3553.430059
LO-REDUCTION     258 3553.437117 3553.430059
LO-REDUCTION     260 3553.436427 3553.430059
EXTENSION        262 3553.433845 3553.423063
EXTENSION        264 3553.430236 3553.414532
LO-REDUCTION     266 3553.430059 3553.414532
EXTENSION        268 3553.423063 3553.400750
LO-REDUCTION     270 3553.420677 3553.400750
EXTENSION        272 3553.414532 3553.373635
LO-REDUCTION     274 3553.401635 3553.373635
EXTENSION        276 3553.400750 3553.350121
EXTENSION        278 3553.375099 3553.304141
EXTENSION        280 3553.373635 3553.268697
EXTENSION        282 3553.350121 3553.228954
EXTENSION        284 3553.304141 3553.137195
EXTENSION        286 3553.268697 3553.072284
LO-REDUCTION     288 3553.228954 3553.072284
REFLECTION       290 3553.137195 3553.047838
LO-REDUCTION     292 3553.130945 3553.047838
EXTENSION        294 3553.077446 3552.946352
LO-REDUCTION     296 3553.072284 3552.946352
REFLECTION       298 3553.047838 3552.945490
EXTENSION        300 3552.952477 3552.765586
LO-REDUCTION     302 3552.946352 3552.765586
LO-REDUCTION     304 3552.945490 3552.765586
EXTENSION        306 3552.873530 3552.652131
EXTENSION        308 3552.820374 3552.547437
EXTENSION        310 3552.765586 3552.363319
LO-REDUCTION     312 3552.652131 3552.363319
REFLECTION       314 3552.547437 3552.342417
REFLECTION       316 3552.487896 3552.333888
REFLECTION       318 3552.363319 3552.209942
HI-REDUCTION     320 3552.342417 3552.209942
LO-REDUCTION     322 3552.333888 3552.209942
EXTENSION        324 3552.310166 3552.151455
HI-REDUCTION     326 3552.253127 3552.151455
LO-REDUCTION     328 3552.243351 3552.151455
EXTENSION        330 3552.209942 3552.038121
LO-REDUCTION     332 3552.164303 3552.038121
LO-REDUCTION     334 3552.151455 3552.038121
EXTENSION        336 3552.108458 3552.000873
EXTENSION        338 3552.065555 3551.917788
EXTENSION        340 3552.038121 3551.884841
HI-REDUCTION     342 3552.000873 3551.884841
REFLECTION       344 3551.942648 3551.818977
LO-REDUCTION     346 3551.917788 3551.818977
LO-REDUCTION     348 3551.884841 3551.818977
REFLECTION       350 3551.854083 3551.806424
REFLECTION       352 3551.838070 3551.785276
HI-REDUCTION     354 3551.818977 3551.785276
LO-REDUCTION     356 3551.811745 3551.785276
HI-REDUCTION     358 3551.806424 3551.785276
LO-REDUCTION     360 3551.798951 3551.785276
HI-REDUCTION     362 3551.791099 3551.785276
REFLECTION       364 3551.788770 3551.778726
LO-REDUCTION     366 3551.785556 3551.778726
LO-REDUCTION     368 3551.785276 3551.778726
EXTENSION        370 3551.783206 3551.775138
HI-REDUCTION     372 3551.780826 3551.775138
LO-REDUCTION     374 3551.779709 3551.775138
HI-REDUCTION     376 3551.778726 3551.775138
LO-REDUCTION     378 3551.777730 3551.775138
HI-REDUCTION     380 3551.777198 3551.775138
EXTENSION        382 3551.776665 3551.774511
HI-REDUCTION     384 3551.776059 3551.774511
REFLECTION       386 3551.775748 3551.774016
HI-REDUCTION     388 3551.775138 3551.774016
LO-REDUCTION     390 3551.775021 3551.774016
LO-REDUCTION     392 3551.774511 3551.774016
EXTENSION        394 3551.774424 3551.773463
HI-REDUCTION     396 3551.774055 3551.773463
HI-REDUCTION     398 3551.774043 3551.773463
HI-REDUCTION     400 3551.774016 3551.773463
LO-REDUCTION     402 3551.773876 3551.773463
REFLECTION       404 3551.773812 3551.773411
HI-REDUCTION     406 3551.773647 3551.773411
HI-REDUCTION     408 3551.773620 3551.773411
HI-REDUCTION     410 3551.773548 3551.773411
HI-REDUCTION     412 3551.773523 3551.773411
HI-REDUCTION     414 3551.773487 3551.773411
HI-REDUCTION     416 3551.773470 3551.773411
HI-REDUCTION     418 3551.773463 3551.773411
Exiting from Nelder Mead minimizer
    420 function evaluations used
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 420 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.499997   0.025624  19.513 < 2.2e-16 ***
[2,] -1.036016   0.058131 -17.822 < 2.2e-16 ***
[3,]  1.010560   0.058404  17.303 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -7.879367e-05 
--------------------------------------------
> ## No analytic gradient, BFGS
> a <- maxLik(logLikMix, 
+             start=start,
+             method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
initial  value 4001.919360 
iter   2 value 3924.195249
iter   3 value 3761.072160
iter   4 value 3740.857495
iter   5 value 3739.836050
iter   6 value 3739.669310
iter   7 value 3739.505188
iter   8 value 3739.342554
iter   9 value 3739.271535
iter  10 value 3674.195391
iter  11 value 3671.068131
iter  12 value 3626.157704
iter  13 value 3589.946385
iter  14 value 3552.974009
iter  15 value 3551.811720
iter  16 value 3551.806145
iter  17 value 3551.796622
iter  18 value 3551.796375
iter  19 value 3551.782439
iter  20 value 3551.776228
iter  21 value 3551.776073
iter  22 value 3551.775690
iter  23 value 3551.774437
iter  24 value 3551.773439
iter  24 value 3551.773426
iter  24 value 3551.773425
final  value 3551.773425 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 126 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.499998   0.025610  19.524 < 2.2e-16 ***
[2,] -1.036024   0.058110 -17.829 < 2.2e-16 ***
[3,]  1.011119   0.058354  17.327 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -8.081729e-05 
--------------------------------------------
> ## ----
> cat("Test for equality constraints\n")
Test for equality constraints
> A <- matrix(c(0, 1, 2), 1, 3)
> B <- 0
> ## default, analytic gradient
> a <- maxLik(logLikMix, grad=gradLikMix, hess=hessLikMix,
+             start=start,
+             constraints=list(eqA=A, eqB=B),
+             print.level=1)
SUMT initial: rho =  0 , function =  -3551.765 , penalty =  1.003726 
Estimate:[1]  0.5032979 -1.0306790  1.0162701
SUMT iteration 1: rho = 0.000308642, function = -3551.765, penalty = 1.003695
Estimate:[1]  0.5032959 -1.0306836  1.0162646
SUMT iteration 2: rho = 0.00308642, function = -3551.765, penalty = 1.003413
Estimate:[1]  0.5032777 -1.0307253  1.0162150
SUMT iteration 3: rho = 0.0308642, function = -3551.765, penalty = 1.000599
Estimate:[1]  0.5030961 -1.0311412  1.0157202
SUMT iteration 4: rho = 0.308642, function = -3551.77, penalty = 0.9731375
Estimate:[1]  0.5013089 -1.0352384  1.0108579
SUMT iteration 5: rho = 3.08642, function = -3552.123, penalty = 0.7532229
Estimate:[1]  0.4858952 -1.0709656  0.9694249
SUMT iteration 6: rho = 30.8642, function = -3559.122, penalty = 0.1604146
Estimate:[1]  0.4240635 -1.2225001  0.8115090
SUMT iteration 7: rho = 308.642, function = -3569.861, penalty = 0.003967026
Estimate:[1]  0.3788904 -1.3438654  0.7034249
SUMT iteration 8: rho = 3086.42, function = -3572.116, penalty = 4.45768e-05
Estimate:[1]  0.3713616 -1.3651918  0.6859342
SUMT iteration 9: rho = 30864.2, function = -3572.364, penalty = 4.511515e-07
Estimate:[1]  0.3705592 -1.3674852  0.6840785
SUMT iteration 10: rho = 308642, function = -3572.389, penalty = 4.51695e-09
Estimate:[1]  0.3704785 -1.3677163  0.6838918
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -3572.39 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.370478   0.025464  14.549 < 2.2e-16 ***
[2,] -1.367716   0.069674 -19.630 < 2.2e-16 ***
[3,]  0.683892   0.051366  13.314 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 4.51695e-09 
--------------------------------------------
> ## BFGS, numeric gradient
> a <- maxLik(logLikMix, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1)
initial  value 4005.159409 
iter   2 value 3739.377952
iter   3 value 3557.996031
iter   4 value 3557.243792
iter   5 value 3553.534181
iter   6 value 3552.770637
iter   7 value 3552.720577
iter   8 value 3552.720532
iter   8 value 3552.720532
final  value 3552.720532 
converged
SUMT iteration 1: rho = 1, function = -3551.811, penalty = 0.9096973
Estimate:[1]  0.4970742 -1.0449813  0.9993809
initial  value 3560.907807 
iter   2 value 3559.815796
iter   3 value 3558.860634
iter   4 value 3558.554875
iter   5 value 3558.470121
iter   5 value 3558.470095
iter   5 value 3558.470095
final  value 3558.470095 
converged
SUMT iteration 2: rho = 10, function = -3553.968, penalty = 0.4501833
Estimate:[1]  0.4600214 -1.1326423  0.9017996
initial  value 3598.986588 
iter   2 value 3581.662692
iter   3 value 3575.592026
iter   4 value 3574.296760
iter   5 value 3568.837187
iter   6 value 3568.828225
iter   6 value 3568.828218
iter   6 value 3568.828218
final  value 3568.828218 
converged
SUMT iteration 3: rho = 100, function = -3565.88, penalty = 0.02948372
Estimate:[1]  0.3934445 -1.3035813  0.7376448
initial  value 3595.363567 
iter   2 value 3575.235881
iter   3 value 3574.538052
iter   4 value 3574.332600
iter   5 value 3571.971345
iter   6 value 3571.969966
iter   6 value 3571.969966
iter   6 value 3571.969966
final  value 3571.969966 
converged
SUMT iteration 4: rho = 1000, function = -3571.557, penalty = 0.0004130861
Estimate:[1]  0.3731857 -1.3599930  0.6901587
initial  value 3575.687740 
iter   2 value 3572.641972
iter   3 value 3572.631516
iter   4 value 3572.627232
iter   5 value 3572.353862
iter   6 value 3572.348648
iter   6 value 3572.348648
iter   6 value 3572.348648
final  value 3572.348648 
converged
SUMT iteration 5: rho = 10000, function = -3572.306, penalty = 4.285695e-06
Estimate:[1]  0.3707461 -1.3669508  0.6845105
initial  value 3572.734360 
iter   2 value 3572.469952
iter   3 value 3572.469793
iter   4 value 3572.469005
iter   5 value 3572.387435
iter   6 value 3572.387291
iter   6 value 3572.387291
iter   6 value 3572.387291
final  value 3572.387291 
converged
SUMT iteration 6: rho = 1e+05, function = -3572.383, penalty = 4.301614e-08
Estimate:[1]  0.3704972 -1.3676627  0.6839351
initial  value 3572.426005 
iter   2 value 3572.391185
iter   2 value 3572.391184
iter   2 value 3572.391164
final  value 3572.391164 
converged
SUMT iteration 7: rho = 1e+06, function = -3572.391, penalty = 4.348272e-10
Estimate:[1]  0.3704624 -1.3677051  0.6838630
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 29 iterations
Return code 0: successful convergence 
Log-Likelihood: -3572.391 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.370462   0.025476  14.542 < 2.2e-16 ***
[2,] -1.367705   0.069700 -19.623 < 2.2e-16 ***
[3,]  0.683863   0.051374  13.311 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 4.348272e-10 
--------------------------------------------
> ## BHHH, analytic gradient (numeric does not converge?)
> try( maxLik(logLikMix, gradLikMix,
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1) )
--------------
successive function values within tolerance limit 
18  iterations
estimate: 0.4902298 1.031313 -1.013298 
Function value: -3552.805 
SUMT iteration 1: rho = 1, function = -3551.815, penalty = 0.9905901
Estimate:[1]  0.4902298  1.0313127 -1.0132983
--------------
successive function values within tolerance limit 
10  iterations
estimate: 0.4515734 1.124017 -0.9126028 
Function value: -3559.076 
SUMT iteration 2: rho = 10, function = -3554.159, penalty = 0.4916661
Estimate:[1]  0.4515734  1.1240165 -0.9126028
--------------
successive function values within tolerance limit 
18  iterations
estimate: 0.3819155 1.306777 -0.7430252 
Function value: -3570.389 
SUMT iteration 3: rho = 100, function = -3567.175, penalty = 0.03213909
Estimate:[1]  0.3819155  1.3067766 -0.7430252
--------------
successive function values within tolerance limit 
88  iterations
estimate: 0.3608079 1.367393 -0.6942959 
Function value: -3573.808 
SUMT iteration 4: rho = 1000, function = -3573.359, penalty = 0.0004493975
Estimate:[1]  0.3608079  1.3673928 -0.6942959
--------------
Iteration limit exceeded. 
100  iterations
estimate: 0.3582631 1.375572 -0.6888693 
Function value: -3574.22 
SUMT iteration 5: rho = 10000, function = -3574.173, penalty = 4.694195e-06
Estimate:[1]  0.3582631  1.3755721 -0.6888693
--------------
Iteration limit exceeded. 
100  iterations
estimate: 0.3580136 1.376398 -0.6883422 
Function value: -3574.262 
SUMT iteration 6: rho = 1e+05, function = -3574.254, penalty = 8.219892e-08
Estimate:[1]  0.3580136  1.3763977 -0.6883422
--------------
successive function values within tolerance limit 
65  iterations
estimate: 0.3579784 1.376516 -0.6882688 
Function value: -3574.266 
SUMT iteration 7: rho = 1e+06, function = -3574.265, penalty = 4.576319e-10
Estimate:[1]  0.3579784  1.3765163 -0.6882688
Maximum Likelihood estimation
BHHH maximisation, 65 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -3574.266 (3 free parameter(s))
Estimate(s): 0.3579784 1.376516 -0.6882688 
> # summary(a)
> 
> 
> ### ------------------ Now test extra parameters for the function ----
> logLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    ll <- log(rho*dnorm(x - mu1) + (1 - rho)*dnorm(x - mu2))
+ #   ll <- sum(ll)
+    ll
+ }
> 
> gradLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    g <- matrix(0, length(x), 2)
+    g[,1] <- rho*(x - mu1)*f1/L
+    g[,2] <- (1 - rho)*(x - mu2)*f2/L
+ #   colSums(g)
+    g
+ }
> 
> hessLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    dldrho <- (f1 - f2)/L
+    dldmu1 <- rho*(x - mu1)*f1/L
+    dldmu2 <- (1 - rho)*(x - mu2)*f2/L
+    h <- matrix(0, 2, 2)
+    h[1,1] <- sum(rho*(-f1 + (x - mu1)^2*f1)/L - dldmu1^2)
+    h[1,2] <- h[2,1] <- -sum(dldmu1*dldmu2)
+    h[2,2] <- sum((1 - rho)*(-f2 + (x - mu2)^2*f2)/L - dldmu2^2)
+    h
+ }
> 
> ## ----------
> A <- matrix(c(1, 2), 1, 2)
> B <- 0
> start <- c(0, 1)
> ## nr, numeric gradient
> a <- maxLik(logLikMix2,
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303367   0.045816 -28.448 < 2.2e-16 ***
[2,]  0.651713   0.035383  18.419 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.49829e-09 
--------------------------------------------
> ## nr, numeric hessian
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303367   0.045806 -28.454 < 2.2e-16 ***
[2,]  0.651713   0.035383  18.419 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.49829e-09 
--------------------------------------------
> ## nr, analytic hessian
> a <- maxLik(logLikMix2, gradLikMix2, hessLikMix2,
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303367   0.045806 -28.454 < 2.2e-16 ***
[2,]  0.651713   0.035383  18.419 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.49829e-09 
--------------------------------------------
> ## BHHH
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371305
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005272
Estimate:[1] -1.0714974  0.9542362
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327019
Estimate:[1] -1.1949208  0.7796018
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.00309626
Estimate:[1] -1.2859611  0.6708026
SUMT iteration 5: rho = 10000, function = -3608.112, penalty = 3.455521e-05
Estimate:[1] -1.3015909  0.6537346
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.479892e-07
Estimate:[1] -1.3034798  0.6520349
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.515288e-09
Estimate:[1] -1.3036720  0.6518656
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 22 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303672   0.045809 -28.459 < 2.2e-16 ***
[2,]  0.651866   0.035383  18.423 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.515288e-09 
--------------------------------------------
> ## BHHH, analytic
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371305
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005272
Estimate:[1] -1.0714974  0.9542362
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327019
Estimate:[1] -1.1949208  0.7796018
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.00309626
Estimate:[1] -1.2859611  0.6708026
SUMT iteration 5: rho = 10000, function = -3608.112, penalty = 3.455521e-05
Estimate:[1] -1.3015909  0.6537346
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.479892e-07
Estimate:[1] -1.3034798  0.6520349
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.515288e-09
Estimate:[1] -1.3036720  0.6518656
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 22 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303672   0.045809 -28.459 < 2.2e-16 ***
[2,]  0.651866   0.035383  18.423 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.515288e-09 
--------------------------------------------
> ## bfgs, no analytic gradient
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1, rho=0.5)
initial  value 3940.429579 
iter   2 value 3568.484771
iter   3 value 3565.703967
iter   4 value 3553.364145
iter   5 value 3552.730547
iter   6 value 3552.727255
iter   6 value 3552.727251
final  value 3552.727251 
converged
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371047
Estimate:[1] -1.040207  1.004125
initial  value 3561.161194 
iter   2 value 3560.033226
iter   3 value 3560.021863
iter   4 value 3560.015406
iter   4 value 3560.015405
iter   4 value 3560.015405
final  value 3560.015405 
converged
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.700527
Estimate:[1] -1.0714975  0.9542362
initial  value 3623.062833 
iter   2 value 3595.991939
iter   3 value 3595.709045
iter   4 value 3587.340552
iter   5 value 3587.300893
iter   5 value 3587.300887
iter   5 value 3587.300887
final  value 3587.300887 
converged
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.132701
Estimate:[1] -1.1949199  0.7796007
initial  value 3706.731798 
iter   2 value 3616.033745
iter   3 value 3615.699091
iter   4 value 3605.546681
iter   5 value 3605.514797
iter   5 value 3605.514797
iter   5 value 3605.514797
final  value 3605.514797 
converged
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095606
Estimate:[1] -1.285964  0.670801
initial  value 3633.375253 
iter   2 value 3610.546095
iter   3 value 3610.527291
iter   4 value 3608.619658
iter   5 value 3608.458020
iter   5 value 3608.458020
iter   5 value 3608.458020
final  value 3608.458020 
converged
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
initial  value 3611.567446 
iter   2 value 3609.435906
iter   3 value 3609.427333
iter   4 value 3609.093783
iter   5 value 3608.770731
iter   5 value 3608.770731
iter   5 value 3608.770731
final  value 3608.770731 
converged
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518951
initial  value 3609.085219 
iter   2 value 3608.802363
iter   2 value 3608.802361
iter   3 value 3608.802198
iter   3 value 3608.802198
iter   3 value 3608.802197
final  value 3608.802197 
converged
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.496707e-09
Estimate:[1] -1.3033688  0.6517139
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 44 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303369   0.045816 -28.448 < 2.2e-16 ***
[2,]  0.651714   0.035383  18.419 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.496707e-09 
--------------------------------------------
> ## bfgs, analytic gradient
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1, rho=0.5)
initial  value 3940.429579 
iter   2 value 3568.484771
iter   3 value 3565.703967
iter   4 value 3553.364145
iter   5 value 3552.730547
iter   6 value 3552.727255
iter   6 value 3552.727251
final  value 3552.727251 
converged
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371047
Estimate:[1] -1.040207  1.004125
initial  value 3561.161194 
iter   2 value 3560.033226
iter   3 value 3560.021863
iter   4 value 3560.015406
iter   4 value 3560.015405
iter   4 value 3560.015405
final  value 3560.015405 
converged
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.700527
Estimate:[1] -1.0714975  0.9542362
initial  value 3623.062833 
iter   2 value 3595.991939
iter   3 value 3595.709045
iter   4 value 3587.340552
iter   5 value 3587.300893
iter   5 value 3587.300887
iter   5 value 3587.300887
final  value 3587.300887 
converged
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.132701
Estimate:[1] -1.1949199  0.7796007
initial  value 3706.731798 
iter   2 value 3616.033745
iter   3 value 3615.699091
iter   4 value 3605.546681
iter   5 value 3605.514797
iter   5 value 3605.514797
iter   5 value 3605.514797
final  value 3605.514797 
converged
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095606
Estimate:[1] -1.285964  0.670801
initial  value 3633.375253 
iter   2 value 3610.546095
iter   3 value 3610.527291
iter   4 value 3608.619658
iter   5 value 3608.458020
iter   5 value 3608.458020
iter   5 value 3608.458020
final  value 3608.458020 
converged
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
initial  value 3611.567446 
iter   2 value 3609.435906
iter   3 value 3609.427333
iter   4 value 3609.093783
iter   5 value 3608.770731
iter   5 value 3608.770731
iter   5 value 3608.770731
final  value 3608.770731 
converged
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518951
initial  value 3609.085219 
iter   2 value 3608.802363
iter   2 value 3608.802361
iter   3 value 3608.802198
iter   3 value 3608.802198
iter   3 value 3608.802197
final  value 3608.802197 
converged
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.496707e-09
Estimate:[1] -1.3033688  0.6517139
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 44 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303369   0.045816 -28.448 < 2.2e-16 ***
[2,]  0.651714   0.035383  18.419 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.496707e-09 
--------------------------------------------
> ## SANN, analytic gradient
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="SANN",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371899
Estimate:[1] -1.040574  1.004330
SUMT iteration 2: rho = 10, function = -3552.98, penalty = 0.7039426
Estimate:[1] -1.0737836  0.9563982
SUMT iteration 3: rho = 100, function = -3573.843, penalty = 0.1345904
Estimate:[1] -1.194322  0.780594
SUMT iteration 4: rho = 1000, function = -3602.368, penalty = 0.003155974
Estimate:[1] -1.2905877  0.6733829
SUMT iteration 5: rho = 10000, function = -3608.075, penalty = 3.855302e-05
Estimate:[1] -1.2994901  0.6528496
SUMT iteration 6: rho = 1e+05, function = -3608.735, penalty = 3.590469e-07
Estimate:[1] -1.3022878  0.6514435
SUMT iteration 7: rho = 1e+06, function = -3608.826, penalty = 6.049114e-09
Estimate:[1] -1.312110  0.656094
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.832 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.312110   0.045875 -28.602 < 2.2e-16 ***
[2,]  0.656094   0.035381  18.544 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 6.049114e-09 
--------------------------------------------
> ## NM, numeric
> a <- maxLik(logLikMix2, 
+             start=start, method="nm",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT iteration 1: rho = 1, function = -3551.789, penalty = 0.938336
Estimate:[1] -1.040056  1.004367
SUMT iteration 2: rho = 10, function = -3553.007, penalty = 0.7008836
Estimate:[1] -1.0715386  0.9543633
SUMT iteration 3: rho = 100, function = -3574.01, penalty = 0.1329042
Estimate:[1] -1.194810  0.779685
SUMT iteration 4: rho = 1000, function = -3602.426, penalty = 0.003088951
Estimate:[1] -1.2861703  0.6708743
SUMT iteration 5: rho = 10000, function = -3608.115, penalty = 3.433149e-05
Estimate:[1] -1.3015164  0.6536878
SUMT iteration 6: rho = 1e+05, function = -3608.737, penalty = 3.390919e-07
Estimate:[1] -1.303138  0.651860
SUMT iteration 7: rho = 1e+06, function = -3608.798, penalty = 3.755006e-09
Estimate:[1] -1.3033865  0.6517239
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 55 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.802 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303387   0.045768 -28.478 < 2.2e-16 ***
[2,]  0.651724   0.035379  18.421 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
7  outer iterations, barrier value 3.755006e-09 
--------------------------------------------
> ## ----------- inequality -------------
> A <- matrix(c(-1, 0,
+               0,  1), 2,2, byrow=TRUE)
> B <- c(1, 1)
> start <- c(0.8, 0.9)
> ##
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
initial  value 4650.395504 
iter   2 value 4126.486293
iter   3 value 3988.319246
iter   4 value 3794.409355
iter   5 value 3612.875661
iter   6 value 3579.444764
iter   7 value 3552.403784
iter   8 value 3551.977036
iter   9 value 3551.774563
iter  10 value 3551.773354
iter  10 value 3551.773354
iter  10 value 3551.773354
final  value 3551.773354 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 40 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036123   0.039845 -26.004 < 2.2e-16 ***
[2,]  1.010784   0.039954  25.299 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -5.775006e-05 
--------------------------------------------
> ##
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
initial  value 4650.395504 
iter   2 value 4126.486292
iter   3 value 3988.319244
iter   4 value 3794.409355
iter   5 value 3612.875661
iter   6 value 3579.444764
iter   7 value 3552.403784
iter   8 value 3551.977036
iter   9 value 3551.774563
iter  10 value 3551.773354
iter  10 value 3551.773354
iter  10 value 3551.773354
final  value 3551.773354 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 40 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036123   0.039862 -25.993 < 2.2e-16 ***
[2,]  1.010784   0.039961  25.294 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -5.775006e-05 
--------------------------------------------
> ##
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="nm",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
  Nelder-Mead direct search function minimizer
function value for initial parameters = 4650.395504
  Scaled convergence tolerance is 4.6504e-05
Stepsize computed as 0.090000
BUILD              3 4734.650205 4650.395504
EXTENSION          5 4717.867666 4545.541480
EXTENSION          7 4650.395504 4398.107307
EXTENSION          9 4545.541480 4057.025391
EXTENSION         11 4398.107307 3765.820064
REFLECTION        13 4057.025391 3607.605056
REFLECTION        15 3765.820064 3555.268193
LO-REDUCTION      17 3607.605056 3555.268193
HI-REDUCTION      19 3577.952096 3555.268193
LO-REDUCTION      21 3568.490004 3555.268193
REFLECTION        23 3562.899144 3551.815286
LO-REDUCTION      25 3555.268193 3551.815286
LO-REDUCTION      27 3554.962931 3551.815286
LO-REDUCTION      29 3552.878451 3551.815286
HI-REDUCTION      31 3552.035159 3551.815286
HI-REDUCTION      33 3551.928631 3551.815286
HI-REDUCTION      35 3551.835416 3551.804225
HI-REDUCTION      37 3551.815286 3551.786153
HI-REDUCTION      39 3551.804225 3551.775106
HI-REDUCTION      41 3551.786153 3551.775106
LO-REDUCTION      43 3551.782575 3551.774053
HI-REDUCTION      45 3551.775106 3551.774053
HI-REDUCTION      47 3551.774844 3551.773446
HI-REDUCTION      49 3551.774053 3551.773446
LO-REDUCTION      51 3551.773707 3551.773439
Exiting from Nelder Mead minimizer
    53 function evaluations used
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 53 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036178   0.039848 -26.003 < 2.2e-16 ***
[2,]  1.010351   0.039949  25.291 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -5.775265e-05 
--------------------------------------------
> 
> ## fixed parameters with constrained optimization, BFGS.  Thanks to Bob Loos for finding this error.
> ## Optimize 3D hat with one parameter fixed (== 2D hat).
> ## Add an equality constraint on that
> hat3 <- function(param) {
+    ## Hat function.  Hessian negative definite if sqrt(x^2 + y^2) < 0.5
+    x <- param[1]
+    y <- param[2]
+    z <- param[3]
+    exp(-x^2-y^2-z^2)
+ }
> library(maxLik)
> sv <- c(1,1,1)
> ## constraints: x + y + z >= 2.5
> A <- matrix(c(1,1,1), 1, 3)
> B <- -2.5
> constraints <- list(ineqA=A, ineqB=B)
> res <- maxBFGS(hat3, start=sv, constraints=constraints, fixed=3)
> summary(res)
--------------------------------------------
BFGS maximisation 
Number of iterations: 43 
Return code: 0 
successful convergence  
Function value: 0.1193829 
Estimates:
      estimate   gradient
[1,] 0.7501397 -0.1791077
[2,] 0.7501397 -0.1791077
[3,] 1.0000000 -0.2387658

Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0006591715 
--------------------------------------------
> 
