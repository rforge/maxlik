
R version 2.9.2 (2009-08-24)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> logLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    ll <- log(rho*dnorm(x - mu1) + (1 - rho)*dnorm(x - mu2))
+ #   ll <- sum(ll)
+    ll
+ }
> 
> gradLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    g <- matrix(0, length(x), 3)
+    g[,1] <- (f1 - f2)/L
+    g[,2] <- rho*(x - mu1)*f1/L
+    g[,3] <- (1 - rho)*(x - mu2)*f2/L
+ #   colSums(g)
+    g
+ }
> 
> hessLikMix <- function(param) {
+    rho <- param[1]
+    if(rho < 0 || rho > 1)
+        return(NA)
+    mu1 <- param[2]
+    mu2 <- param[3]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    dldrho <- (f1 - f2)/L
+    dldmu1 <- rho*(x - mu1)*f1/L
+    dldmu2 <- (1 - rho)*(x - mu2)*f2/L
+    h <- matrix(0, 3, 3)
+    h[1,1] <- -sum(dldrho*(f1 - f2)/L)
+    h[2,1] <- h[1,2] <- sum((x - mu1)*f1/L - dldmu1*dldrho)
+    h[3,1] <- h[1,3] <- sum(-(x - mu2)*f2/L - dldmu2*dldrho)
+    h[2,2] <- sum(rho*(-f1 + (x - mu1)^2*f1)/L - dldmu1^2)
+    h[2,3] <- h[3,2] <- -sum(dldmu1*dldmu2)
+    h[3,3] <- sum((1 - rho)*(-f2 + (x - mu2)^2*f2)/L - dldmu2^2)
+    h
+ }
> ### --------------------------
> library(maxLik)
> ## mixed normal
> set.seed(1)
> x <- c(rnorm(1000, mean=-1), rnorm(1000, mean=1))
> 
> cat("Test for inequality constraints\n")
Test for inequality constraints
> A <- matrix(c(-1, 0, 0,
+               0, -1, 0,
+               0, 0, 1), 3, 3, byrow=TRUE)
> B <- c(0.5, 1, 1)
> start <- c(0.4, 0.9, 0.9)
> ## analytic gradient
> a <- maxLik(logLikMix, grad=gradLikMix, hess=hessLikMix,
+             start=start,
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
initial  value 4743.812134 
iter   2 value 4168.292667
iter   3 value 4149.445161
iter   4 value 4076.012738
iter   5 value 3998.294252
iter   6 value 3997.798715
iter   7 value 3996.076468
iter   8 value 3995.581657
iter   9 value 3993.888215
iter  10 value 3993.394145
iter  11 value 3991.756882
iter  12 value 3991.752938
iter  13 value 3655.399871
iter  14 value 3633.676842
iter  15 value 3601.040141
iter  16 value 3582.384926
iter  17 value 3581.895162
iter  18 value 3581.419147
iter  19 value 3581.179106
iter  20 value 3581.121705
iter  21 value 3568.765914
iter  22 value 3562.709900
iter  23 value 3558.882309
iter  24 value 3556.430107
iter  25 value 3554.855596
iter  26 value 3553.910890
iter  27 value 3553.404590
iter  28 value 3553.398813
iter  29 value 3553.354904
iter  30 value 3553.239518
iter  31 value 3552.704034
iter  32 value 3552.692025
iter  33 value 3552.635535
iter  34 value 3552.627650
iter  35 value 3552.620813
iter  36 value 3552.552723
iter  37 value 3552.540488
iter  38 value 3552.528911
iter  39 value 3552.517979
iter  40 value 3552.516166
iter  41 value 3552.512260
iter  42 value 3552.512190
iter  43 value 3552.501863
iter  44 value 3552.494366
iter  45 value 3552.484682
iter  46 value 3552.447255
iter  47 value 3552.445751
iter  48 value 3552.426939
iter  49 value 3552.426580
iter  50 value 3552.407748
iter  51 value 3552.225541
iter  52 value 3552.217124
iter  53 value 3552.200967
iter  54 value 3552.200654
iter  55 value 3552.198011
iter  56 value 3552.195140
iter  57 value 3552.193411
iter  58 value 3552.190522
iter  59 value 3552.190472
iter  60 value 3552.189503
iter  60 value 3552.189479
final  value 3552.189479 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 34960 iterations
Return code 0: successful convergence 
Log-Likelihood: -3552.187 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.494261   0.025431  19.435 < 2.2e-16 ***
[2,]  0.999997   0.057609  17.358 < 2.2e-16 ***
[3,] -0.999984   0.056711 -17.633 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## No analytic gradient
> a <- maxLik(logLikMix, 
+             start=start,
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
  Nelder-Mead direct search function minimizer
function value for initial parameters = 4743.812134
  Scaled convergence tolerance is 4.74381e-05
Stepsize computed as 0.090000
BUILD              4 4841.500572 4743.812134
EXTENSION          6 4807.136271 4626.916182
HI-REDUCTION       8 4756.020200 4626.916182
LO-REDUCTION      10 4743.812148 4626.916182
EXTENSION         12 4743.812134 4481.463017
HI-REDUCTION      14 4668.720608 4481.463017
LO-REDUCTION      16 4658.343739 4481.463017
HI-REDUCTION      18 4626.916182 4481.463017
EXTENSION         20 4609.621463 4374.253368
HI-REDUCTION      22 4537.643476 4374.253368
LO-REDUCTION      24 4528.384872 4374.253368
EXTENSION         26 4481.463017 4197.906298
EXTENSION         28 4378.322760 4035.221736
LO-REDUCTION      30 4374.253368 4035.221736
HI-REDUCTION      32 4221.335266 4035.221736
REFLECTION        34 4197.906298 3993.974871
REFLECTION        36 4051.960588 3924.714951
EXTENSION         38 4035.221736 3881.262249
HI-REDUCTION      40 3993.974871 3881.262249
EXTENSION         42 3967.039655 3832.683728
LO-REDUCTION      44 3924.714951 3832.683728
LO-REDUCTION      46 3881.262249 3832.683728
LO-REDUCTION      48 3876.050057 3832.683728
EXTENSION         50 3844.876804 3746.095063
LO-REDUCTION      52 3832.811941 3746.095063
EXTENSION         54 3832.683728 3698.693406
EXTENSION         56 3760.278616 3580.969288
LO-REDUCTION      58 3746.095063 3580.969288
HI-REDUCTION      60 3698.693406 3580.969288
HI-REDUCTION      62 3669.599387 3580.969288
HI-REDUCTION      64 3645.552463 3580.969288
HI-REDUCTION      66 3631.992565 3580.969288
HI-REDUCTION      68 3619.396924 3580.969288
HI-REDUCTION      70 3612.192771 3580.969288
HI-REDUCTION      72 3605.435716 3580.969288
HI-REDUCTION      74 3601.330774 3580.969288
HI-REDUCTION      76 3597.589776 3580.969288
HI-REDUCTION      78 3595.155519 3580.969288
LO-REDUCTION      80 3593.015184 3580.969288
HI-REDUCTION      82 3591.490686 3580.969288
HI-REDUCTION      84 3588.579917 3580.969288
HI-REDUCTION      86 3587.397772 3580.969288
HI-REDUCTION      88 3585.866459 3580.969288
HI-REDUCTION      90 3585.051339 3580.969288
REFLECTION        92 3584.190545 3579.750310
HI-REDUCTION      94 3582.477464 3579.750310
HI-REDUCTION      96 3581.925490 3579.750310
LO-REDUCTION      98 3581.647628 3579.750310
REFLECTION       100 3580.969288 3578.888923
HI-REDUCTION     102 3580.207473 3578.888923
REFLECTION       104 3579.879337 3578.756380
HI-REDUCTION     106 3579.750310 3578.756380
EXTENSION        108 3579.483515 3578.384680
REFLECTION       110 3578.888923 3577.866899
EXTENSION        112 3578.756380 3577.679582
LO-REDUCTION     114 3578.384680 3577.679582
HI-REDUCTION     116 3578.059402 3577.679582
HI-REDUCTION     118 3578.013657 3577.679582
HI-REDUCTION     120 3577.910695 3577.679582
HI-REDUCTION     122 3577.866899 3577.679582
HI-REDUCTION     124 3577.859443 3577.679582
REFLECTION       126 3577.826115 3577.640527
HI-REDUCTION     128 3577.771582 3577.640527
REFLECTION       130 3577.750945 3577.635953
HI-REDUCTION     132 3577.689100 3577.635953
REFLECTION       134 3577.679582 3577.587357
HI-REDUCTION     136 3577.640527 3577.587357
HI-REDUCTION     138 3577.639765 3577.587357
HI-REDUCTION     140 3577.635953 3577.587357
HI-REDUCTION     142 3577.623854 3577.587357
REFLECTION       144 3577.619081 3577.584802
HI-REDUCTION     146 3577.614530 3577.584802
HI-REDUCTION     148 3577.605265 3577.584802
HI-REDUCTION     150 3577.601118 3577.584802
HI-REDUCTION     152 3577.597519 3577.584802
HI-REDUCTION     154 3577.594668 3577.584802
HI-REDUCTION     156 3577.592796 3577.584802
HI-REDUCTION     158 3577.591013 3577.584802
HI-REDUCTION     160 3577.589886 3577.584802
HI-REDUCTION     162 3577.588802 3577.584802
REFLECTION       164 3577.588090 3577.583828
HI-REDUCTION     166 3577.587357 3577.583828
LO-REDUCTION     168 3577.586320 3577.583828
HI-REDUCTION     170 3577.585098 3577.583828
REFLECTION       172 3577.584802 3577.583271
HI-REDUCTION     174 3577.584494 3577.583271
HI-REDUCTION     176 3577.584117 3577.583271
HI-REDUCTION     178 3577.583924 3577.583271
HI-REDUCTION     180 3577.583828 3577.583271
HI-REDUCTION     182 3577.583744 3577.583271
REFLECTION       184 3577.583633 3577.583172
HI-REDUCTION     186 3577.583480 3577.583172
LO-REDUCTION     188 3577.583416 3577.583172
HI-REDUCTION     190 3577.583285 3577.583172
REFLECTION       192 3577.583271 3577.583171
LO-REDUCTION     194 3577.583232 3577.583149
Exiting from Nelder Mead minimizer
    196 function evaluations used
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 196 iterations
Return code 0: successful convergence 
Log-Likelihood: -3577.581 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.416832   0.024267  17.177 < 2.2e-16 ***
[2,]  0.893346   0.051311  17.410 < 2.2e-16 ***
[3,] -0.999999   0.058592 -17.067 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## No analytic gradient, BFGS
> a <- maxLik(logLikMix, 
+             start=start,
+             method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1)
initial  value 4743.812134 
iter   2 value 4168.292668
iter   3 value 4149.445162
iter   4 value 4076.012739
iter   5 value 3998.294252
iter   6 value 3997.798715
iter   7 value 3996.076470
iter   8 value 3995.581659
iter   9 value 3993.888216
iter  10 value 3993.394146
iter  11 value 3991.756880
iter  12 value 3991.752936
iter  13 value 3655.397977
iter  14 value 3633.674848
iter  15 value 3601.038847
iter  16 value 3582.384068
iter  17 value 3581.894316
iter  18 value 3581.418359
iter  19 value 3581.178328
iter  20 value 3581.120937
iter  21 value 3568.759859
iter  22 value 3562.705471
iter  23 value 3558.879277
iter  24 value 3556.428037
iter  25 value 3554.854183
iter  26 value 3553.909364
iter  27 value 3553.403754
iter  28 value 3553.397975
iter  29 value 3553.354504
iter  30 value 3553.239171
iter  31 value 3552.717555
iter  32 value 3552.655215
iter  33 value 3552.600743
iter  34 value 3552.599287
iter  35 value 3552.573945
iter  36 value 3552.563521
iter  37 value 3552.507011
iter  38 value 3552.497159
iter  39 value 3552.494917
iter  40 value 3552.486232
iter  41 value 3552.484796
iter  42 value 3552.483833
iter  43 value 3552.458795
iter  44 value 3552.457183
iter  45 value 3552.456351
iter  46 value 3552.418132
iter  47 value 3552.416747
iter  48 value 3552.416008
iter  49 value 3552.398234
iter  50 value 3552.192732
iter  51 value 3552.191149
iter  52 value 3552.190535
iter  53 value 3552.190057
iter  54 value 3552.189142
iter  55 value 3552.189089
iter  55 value 3552.189078
iter  56 value 3552.188946
iter  56 value 3552.188928
iter  56 value 3552.188926
final  value 3552.188926 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36156 iterations
Return code 0: successful convergence 
Log-Likelihood: -3552.187 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.493680   0.025401  19.436 < 2.2e-16 ***
[2,]  0.999999   0.057485  17.396 < 2.2e-16 ***
[3,] -0.999984   0.056644 -17.654 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## ----
> cat("Test for equality constraints\n")
Test for equality constraints
> A <- matrix(c(0, 1, 2), 1, 3)
> B <- 0
> ## default, analytic gradient
> a <- maxLik(logLikMix, grad=gradLikMix, hess=hessLikMix,
+             start=start,
+             constraints=list(eqA=A, eqB=B),
+             print.level=1)
SUMT initial: rho =  0 , function =  -4013.758 , penalty =  133.1048 
Estimate:[1]  5.107684e-11 -1.086032e+01 -3.383917e-01
SUMT iteration 1: rho = 1.371742e-05, function = -4013.758, penalty = 133.1048
Estimate:[1]  5.107684e-11 -1.086032e+01 -3.383917e-01
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 1 iterations
Return code 3: Last step could not find a value above the current.
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -4013.759 
3  free parameters
Estimates:
        Estimate  Std. error   t value Pr(> t)    
[1,]  5.1077e-11  2.2361e-02 2.284e-09  1.0000    
[2,] -1.0860e+01  1.9092e+02   -0.0569  0.9546    
[3,] -3.3839e-01  2.2361e-02  -15.1333  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## BFGS, numeric gradient
> a <- maxLik(logLikMix, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1)
initial  value 4743.812250 
iter   2 value 4168.292379
iter   3 value 4065.826987
iter   4 value 3800.181137
iter   5 value 3620.224116
iter   6 value 3606.363246
iter   7 value 3566.879848
iter   8 value 3555.715988
iter   9 value 3551.846926
iter  10 value 3551.767683
iter  11 value 3551.766212
iter  12 value 3551.765878
iter  13 value 3551.765325
iter  14 value 3551.765013
iter  14 value 3551.765013
iter  14 value 3551.765013
final  value 3551.765013 
converged
SUMT initial: rho =  0 , function =  -3551.765 , penalty =  1.092209 
Estimate:[1]  0.4967021  1.0162701 -1.0306790
initial  value 3552.857222 
iter   2 value 3552.838368
iter   3 value 3552.817135
iter   4 value 3552.808965
iter   5 value 3552.805105
iter   5 value 3552.805105
iter   5 value 3552.805105
final  value 3552.805105 
converged
SUMT iteration 1: rho = 1, function = -3551.815, penalty = 0.9905916
Estimate:[1]  0.4902298  1.0313125 -1.0132986
initial  value 3561.720429 
iter   2 value 3560.545268
iter   3 value 3559.521601
iter   4 value 3559.169095
iter   5 value 3559.075840
iter   6 value 3559.075797
iter   6 value 3559.075797
iter   6 value 3559.075797
final  value 3559.075797 
converged
SUMT iteration 2: rho = 10, function = -3554.159, penalty = 0.4916601
Estimate:[1]  0.4515728  1.1240183 -0.9126015
initial  value 3603.325208 
iter   2 value 3584.440538
iter   3 value 3577.824104
iter   4 value 3576.293460
iter   5 value 3570.399646
iter   6 value 3570.388829
iter   6 value 3570.388819
iter   6 value 3570.388819
final  value 3570.388819 
converged
SUMT iteration 3: rho = 100, function = -3567.175, penalty = 0.03213976
Estimate:[1]  0.3819149  1.3067747 -0.7430252
initial  value 3599.314604 
iter   2 value 3577.387185
iter   3 value 3576.625960
iter   4 value 3576.378122
iter   5 value 3573.809592
iter   6 value 3573.808204
iter   6 value 3573.808204
iter   6 value 3573.808204
final  value 3573.808204 
converged
SUMT iteration 4: rho = 1000, function = -3573.359, penalty = 0.000448781
Estimate:[1]  0.3608162  1.3673629 -0.6942737
initial  value 3577.847233 
iter   2 value 3574.539105
iter   3 value 3574.527783
iter   4 value 3574.522695
iter   5 value 3574.224151
iter   6 value 3574.219505
iter   6 value 3574.219505
iter   6 value 3574.219505
final  value 3574.219505 
converged
SUMT iteration 5: rho = 10000, function = -3574.173, penalty = 4.653661e-06
Estimate:[1]  0.3582838  1.3748336 -0.6884954
initial  value 3574.638334 
iter   2 value 3574.351225
iter   3 value 3574.351053
iter   4 value 3574.350274
iter   5 value 3574.262636
iter   6 value 3574.261464
iter   6 value 3574.261464
iter   6 value 3574.261464
final  value 3574.261464 
converged
SUMT iteration 6: rho = 1e+05, function = -3574.257, penalty = 4.670715e-08
Estimate:[1]  0.3580256  1.3755980 -0.6879070
initial  value 3574.303501 
iter   2 value 3574.265693
iter   2 value 3574.265691
iter   2 value 3574.265670
final  value 3574.265670 
converged
SUMT iteration 7: rho = 1e+06, function = -3574.265, penalty = 4.721376e-10
Estimate:[1]  0.3579890  1.3756426 -0.6878322
initial  value 3574.269919 
iter   2 value 3574.267425
iter   2 value 3574.267423
iter   3 value 3574.266554
iter   3 value 3574.266553
iter   4 value 3574.266252
iter   4 value 3574.266238
iter   5 value 3574.266153
iter   6 value 3574.266097
iter   6 value 3574.266097
iter   6 value 3574.266094
final  value 3574.266094 
converged
SUMT iteration 8: rho = 1e+07, function = -3574.266, penalty = 6.373378e-12
Estimate:[1]  0.3580370  1.3756829 -0.6878427
initial  value 3574.266668 
iter   2 value 3574.266153
iter   2 value 3574.266150
iter   2 value 3574.266133
final  value 3574.266133 
converged
SUMT iteration 9: rho = 1e+08, function = -3574.266, penalty = 8.492677e-14
Estimate:[1]  0.3579757  1.3756808 -0.6878406
initial  value 3574.266209 
iter   2 value 3574.266166
iter   2 value 3574.266166
iter   2 value 3574.266148
final  value 3574.266148 
converged
SUMT iteration 10: rho = 1e+09, function = -3574.266, penalty = 1.732852e-14
Estimate:[1]  0.3580082  1.3756826 -0.6878414
initial  value 3574.266304 
iter   2 value 3574.266156
iter   2 value 3574.266156
iter   2 value 3574.266138
final  value 3574.266138 
converged
SUMT iteration 11: rho = 1e+10, function = -3574.266, penalty = 3.071573e-16
Estimate:[1]  0.3579909  1.3756820 -0.6878410
initial  value 3574.266166 
iter   1 value 3574.266139
final  value 3574.266139 
converged
SUMT iteration 12: rho = 1e+11, function = -3574.266, penalty = 2.664978e-17
Estimate:[1]  0.3579909  1.3756820 -0.6878410
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 191 iterations
Return code 0: successful convergence 
Log-Likelihood: -3574.266 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.357991   0.014590  24.537 < 2.2e-16 ***
[2,]  1.375682   0.036459  37.733 < 2.2e-16 ***
[3,] -0.687841   0.018229 -37.733 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## BHHH, analytic gradient (numeric does not converge?)
> a <- maxLik(logLikMix, gradLikMix,
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1)
--------------
successive function values within tolerance limit.
May be a solution 
14  iterations
estimate: 0.5032977 -1.030679 1.016270 
Function value: -3551.765 
SUMT initial: rho =  0 , function =  -3551.765 , penalty =  1.003724 
Estimate:[1]  0.5032977 -1.0306794  1.0162698
--------------
successive function values within tolerance limit.
May be a solution 
5  iterations
estimate: 0.4970771 -1.044977 0.9993931 
Function value: -3552.721 
SUMT iteration 1: rho = 1, function = -3551.811, penalty = 0.909752
Estimate:[1]  0.4970771 -1.0449771  0.9993931
--------------
successive function values within tolerance limit.
May be a solution 
5  iterations
estimate: 0.4600218 -1.132643 0.9018076 
Function value: -3558.47 
SUMT iteration 2: rho = 10, function = -3553.968, penalty = 0.4502039
Estimate:[1]  0.4600218 -1.1326428  0.9018076
--------------
successive function values within tolerance limit.
May be a solution 
6  iterations
estimate: 0.3934442 -1.303587 0.7376448 
Function value: -3568.828 
SUMT iteration 3: rho = 100, function = -3565.88, penalty = 0.02948186
Estimate:[1]  0.3934442 -1.3035869  0.7376448
--------------
successive function values within tolerance limit.
May be a solution 
6  iterations
estimate: 0.3731856 -1.359993 0.6901587 
Function value: -3571.97 
SUMT iteration 4: rho = 1000, function = -3571.557, penalty = 0.0004130851
Estimate:[1]  0.3731856 -1.3599929  0.6901587
--------------
successive function values within tolerance limit.
May be a solution 
5  iterations
estimate: 0.3707461 -1.366951 0.6845105 
Function value: -3572.349 
SUMT iteration 5: rho = 10000, function = -3572.306, penalty = 4.285689e-06
Estimate:[1]  0.3707461 -1.3669509  0.6845105
--------------
successive function values within tolerance limit.
May be a solution 
4  iterations
estimate: 0.3704972 -1.367663 0.683935 
Function value: -3572.387 
SUMT iteration 6: rho = 1e+05, function = -3572.383, penalty = 4.301651e-08
Estimate:[1]  0.3704972 -1.3676627  0.6839350
--------------
successive function values within tolerance limit.
May be a solution 
3  iterations
estimate: 0.3704723 -1.367734 0.6838775 
Function value: -3572.391 
SUMT iteration 7: rho = 1e+06, function = -3572.391, penalty = 4.303234e-10
Estimate:[1]  0.3704723 -1.3677342  0.6838775
--------------
successive function values within tolerance limit.
May be a solution 
2  iterations
estimate: 0.3704697 -1.367741 0.6838716 
Function value: -3572.392 
SUMT iteration 8: rho = 1e+07, function = -3572.392, penalty = 4.303411e-12
Estimate:[1]  0.3704697 -1.3677412  0.6838716
--------------
successive function values within tolerance limit.
May be a solution 
2  iterations
estimate: 0.3704695 -1.367742 0.683871 
Function value: -3572.392 
SUMT iteration 9: rho = 1e+08, function = -3572.392, penalty = 4.303416e-14
Estimate:[1]  0.3704695 -1.3677419  0.6838711
--------------
successive function values within tolerance limit.
May be a solution 
2  iterations
estimate: 0.3704695 -1.367742 0.683871 
Function value: -3572.392 
SUMT iteration 10: rho = 1e+09, function = -3572.392, penalty = 4.303416e-16
Estimate:[1]  0.3704695 -1.3677420  0.6838710
--------------
gradient close to zero. May be a solution 
2  iterations
estimate: 0.3704695 -1.367742 0.683871 
Function value: -3572.392 
SUMT iteration 11: rho = 1e+10, function = -3572.392, penalty = 4.303416e-18
Estimate:[1]  0.3704695 -1.3677420  0.6838710
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 2 iterations
Return code 1: gradient close to zero. May be a solution
Log-Likelihood: -3572.392 
3  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,]  0.370470   0.014585  25.401 < 2.2e-16 ***
[2,] -1.367742   0.036527 -37.445 < 2.2e-16 ***
[3,]  0.683871   0.018263  37.445 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> 
> 
> # ------------------ Now test extra parameters for the function ----
> logLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    ll <- log(rho*dnorm(x - mu1) + (1 - rho)*dnorm(x - mu2))
+ #   ll <- sum(ll)
+    ll
+ }
> 
> gradLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    g <- matrix(0, length(x), 2)
+    g[,1] <- rho*(x - mu1)*f1/L
+    g[,2] <- (1 - rho)*(x - mu2)*f2/L
+ #   colSums(g)
+    g
+ }
> 
> hessLikMix2 <- function(param, rho) {
+    mu1 <- param[1]
+    mu2 <- param[2]
+    f1 <- dnorm(x - mu1)
+    f2 <- dnorm(x - mu2)
+    L <- rho*f1 + (1 - rho)*f2
+    dldrho <- (f1 - f2)/L
+    dldmu1 <- rho*(x - mu1)*f1/L
+    dldmu2 <- (1 - rho)*(x - mu2)*f2/L
+    h <- matrix(0, 2, 2)
+    h[1,1] <- sum(rho*(-f1 + (x - mu1)^2*f1)/L - dldmu1^2)
+    h[1,2] <- h[2,1] <- -sum(dldmu1*dldmu2)
+    h[2,2] <- sum((1 - rho)*(-f2 + (x - mu2)^2*f2)/L - dldmu2^2)
+    h
+ }
> 
> ## ----------
> A <- matrix(c(1, 2), 1, 2)
> B <- 0
> start <- c(0, 1)
> ## nr, numeric gradient
> a <- maxLik(logLikMix2,
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9711006 
Estimate:[1] -1.036123  1.010784
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518951
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498688e-11
Estimate:[1] -1.303384  0.651695
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.498728e-13
Estimate:[1] -1.3033858  0.6516932
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 3.498732e-15
Estimate:[1] -1.303386  0.651693
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 3.498732e-17
Estimate:[1] -1.303386  0.651693
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 3.498733e-19
Estimate:[1] -1.303386  0.651693
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 2: successive function values within tolerance limit.
May be a solution
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303386   0.036193 -36.012 < 2.2e-16 ***
[2,]  0.651693   0.018096  36.012 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## nr, numeric hessian
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9711006 
Estimate:[1] -1.036123  1.010784
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498688e-11
Estimate:[1] -1.303384  0.651695
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.498728e-13
Estimate:[1] -1.3033858  0.6516932
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 3.498732e-15
Estimate:[1] -1.303386  0.651693
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 3.498732e-17
Estimate:[1] -1.303386  0.651693
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 3.498733e-19
Estimate:[1] -1.303386  0.651693
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 2: successive function values within tolerance limit.
May be a solution
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303386   0.036168 -36.037 < 2.2e-16 ***
[2,]  0.651693   0.018084  36.037 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## nr, analytic hessian
> a <- maxLik(logLikMix2, gradLikMix2, hessLikMix2,
+             start=start, method="nr",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9711006 
Estimate:[1] -1.036123  1.010784
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005268
Estimate:[1] -1.0714975  0.9542361
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327009
Estimate:[1] -1.1949215  0.7796014
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095607
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494313e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.49829e-09
Estimate:[1] -1.3033673  0.6517132
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498688e-11
Estimate:[1] -1.303384  0.651695
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.498728e-13
Estimate:[1] -1.3033858  0.6516932
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 3.498732e-15
Estimate:[1] -1.303386  0.651693
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 3.498732e-17
Estimate:[1] -1.303386  0.651693
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 3.498733e-19
Estimate:[1] -1.303386  0.651693
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 2: successive function values within tolerance limit.
May be a solution
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303386   0.036168 -36.037 < 2.2e-16 ***
[2,]  0.651693   0.018084  36.037 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## BHHH
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9711007 
Estimate:[1] -1.036123  1.010784
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371304
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005277
Estimate:[1] -1.0714974  0.9542364
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327008
Estimate:[1] -1.1949215  0.7796013
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095609
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454919e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.498292e-09
Estimate:[1] -1.3033674  0.6517133
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498693e-11
Estimate:[1] -1.3033843  0.6516951
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.498728e-13
Estimate:[1] -1.3033858  0.6516932
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 3.498732e-15
Estimate:[1] -1.303386  0.651693
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 3.498732e-17
Estimate:[1] -1.303386  0.651693
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 3.498733e-19
Estimate:[1] -1.303386  0.651693
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 2 iterations
Return code 2: successive function values within tolerance limit.
May be a solution
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303386   0.035253 -36.972 < 2.2e-16 ***
[2,]  0.651693   0.017627  36.972 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## BHHH, analytic
> a <- maxLik(logLikMix2, gradLikMix2, 
+             start=start, method="bhhh",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9711007 
Estimate:[1] -1.036123  1.010784
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371304
Estimate:[1] -1.040191  1.004123
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005277
Estimate:[1] -1.0714974  0.9542364
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.1327008
Estimate:[1] -1.1949215  0.7796013
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095609
Estimate:[1] -1.285964  0.670801
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454919e-05
Estimate:[1] -1.3015300  0.6537039
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518952
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.498292e-09
Estimate:[1] -1.3033674  0.6517133
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498693e-11
Estimate:[1] -1.3033843  0.6516951
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.498728e-13
Estimate:[1] -1.3033858  0.6516932
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 3.498732e-15
Estimate:[1] -1.303386  0.651693
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 3.498732e-17
Estimate:[1] -1.303386  0.651693
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 3.498733e-19
Estimate:[1] -1.303386  0.651693
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 2 iterations
Return code 2: successive function values within tolerance limit.
May be a solution
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303386   0.035253 -36.972 < 2.2e-16 ***
[2,]  0.651693   0.017627  36.972 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## bfgs, no analytic gradient
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1, rho=0.5)
initial  value 3936.429579 
iter   2 value 3566.541503
iter   3 value 3564.066479
iter   4 value 3552.366389
iter   5 value 3551.776255
iter   6 value 3551.773299
iter   6 value 3551.773297
final  value 3551.773297 
converged
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9710673 
Estimate:[1] -1.036138  1.010783
initial  value 3552.744364 
iter   2 value 3552.727530
iter   3 value 3552.727376
iter   4 value 3552.727251
iter   4 value 3552.727251
iter   4 value 3552.727251
final  value 3552.727251 
converged
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
initial  value 3561.161424 
iter   2 value 3560.033215
iter   3 value 3560.021854
iter   4 value 3560.015406
iter   4 value 3560.015405
iter   4 value 3560.015405
final  value 3560.015405 
converged
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005269
Estimate:[1] -1.0714975  0.9542362
initial  value 3623.062827 
iter   2 value 3595.991937
iter   3 value 3595.709044
iter   4 value 3587.340552
iter   5 value 3587.300893
iter   5 value 3587.300887
iter   5 value 3587.300887
final  value 3587.300887 
converged
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.132701
Estimate:[1] -1.1949199  0.7796007
initial  value 3706.731798 
iter   2 value 3616.033745
iter   3 value 3615.699091
iter   4 value 3605.546681
iter   5 value 3605.514797
iter   5 value 3605.514797
iter   5 value 3605.514797
final  value 3605.514797 
converged
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095606
Estimate:[1] -1.285964  0.670801
initial  value 3633.375253 
iter   2 value 3610.546095
iter   3 value 3610.527291
iter   4 value 3608.619658
iter   5 value 3608.458020
iter   5 value 3608.458020
iter   5 value 3608.458020
final  value 3608.458020 
converged
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
initial  value 3611.567446 
iter   2 value 3609.435906
iter   3 value 3609.427333
iter   4 value 3609.093792
iter   5 value 3608.770731
iter   5 value 3608.770731
iter   5 value 3608.770731
final  value 3608.770731 
converged
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518951
initial  value 3609.085219 
iter   2 value 3608.802363
iter   2 value 3608.802361
iter   3 value 3608.802198
iter   3 value 3608.802198
iter   3 value 3608.802197
final  value 3608.802197 
converged
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.496707e-09
Estimate:[1] -1.303369  0.651714
initial  value 3608.833668 
iter   2 value 3608.815218
iter   3 value 3608.808534
iter   4 value 3608.806287
iter   5 value 3608.805346
iter   5 value 3608.805346
iter   5 value 3608.805346
final  value 3608.805346 
converged
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498684e-11
Estimate:[1] -1.303384  0.651695
initial  value 3608.808495 
iter   2 value 3608.805754
iter   3 value 3608.805715
iter   3 value 3608.805686
iter   3 value 3608.805668
final  value 3608.805668 
converged
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.541394e-13
Estimate:[1] -1.303247  0.651624
initial  value 3608.805987 
iter   2 value 3608.805817
iter   2 value 3608.805809
iter   3 value 3608.805740
iter   3 value 3608.805739
iter   3 value 3608.805715
final  value 3608.805715 
converged
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 7.403837e-15
Estimate:[1] -1.3034377  0.6517188
initial  value 3608.805781 
iter   2 value 3608.805707
iter   2 value 3608.805706
iter   2 value 3608.805697
final  value 3608.805697 
converged
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 2.457234e-17
Estimate:[1] -1.3033871  0.6516936
initial  value 3608.805699 
iter   1 value 3608.805696
final  value 3608.805696 
converged
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 5.361752e-18
Estimate:[1] -1.3033871  0.6516936
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 191 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303387   0.036163 -36.042 < 2.2e-16 ***
[2,]  0.651694   0.018082  36.042 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## bfgs, analytic gradient
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(eqA=A, eqB=B),
+             print.level=2, SUMTRho0=1, rho=0.5)
initial  value 3936.429579 
iter   2 value 3566.541503
iter   3 value 3564.066479
iter   4 value 3552.366389
iter   5 value 3551.776255
iter   6 value 3551.773299
iter   6 value 3551.773297
final  value 3551.773297 
converged
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9710673 
Estimate:[1] -1.036138  1.010783
initial  value 3552.744364 
iter   2 value 3552.727530
iter   3 value 3552.727376
iter   4 value 3552.727251
iter   4 value 3552.727251
iter   4 value 3552.727251
final  value 3552.727251 
converged
SUMT iteration 1: rho = 1, function = -3551.79, penalty = 0.9371303
Estimate:[1] -1.040191  1.004123
initial  value 3561.161424 
iter   2 value 3560.033215
iter   3 value 3560.021854
iter   4 value 3560.015406
iter   4 value 3560.015405
iter   4 value 3560.015405
final  value 3560.015405 
converged
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005269
Estimate:[1] -1.0714975  0.9542362
initial  value 3623.062827 
iter   2 value 3595.991937
iter   3 value 3595.709044
iter   4 value 3587.340552
iter   5 value 3587.300893
iter   5 value 3587.300887
iter   5 value 3587.300887
final  value 3587.300887 
converged
SUMT iteration 3: rho = 100, function = -3574.031, penalty = 0.132701
Estimate:[1] -1.1949199  0.7796007
initial  value 3706.731798 
iter   2 value 3616.033745
iter   3 value 3615.699091
iter   4 value 3605.546681
iter   5 value 3605.514797
iter   5 value 3605.514797
iter   5 value 3605.514797
final  value 3605.514797 
converged
SUMT iteration 4: rho = 1000, function = -3602.419, penalty = 0.003095606
Estimate:[1] -1.285964  0.670801
initial  value 3633.375253 
iter   2 value 3610.546095
iter   3 value 3610.527291
iter   4 value 3608.619658
iter   5 value 3608.458020
iter   5 value 3608.458020
iter   5 value 3608.458020
final  value 3608.458020 
converged
SUMT iteration 5: rho = 10000, function = -3608.113, penalty = 3.454918e-05
Estimate:[1] -1.3015300  0.6537039
initial  value 3611.567446 
iter   2 value 3609.435906
iter   3 value 3609.427333
iter   4 value 3609.093792
iter   5 value 3608.770731
iter   5 value 3608.770731
iter   5 value 3608.770731
final  value 3608.770731 
converged
SUMT iteration 6: rho = 1e+05, function = -3608.736, penalty = 3.494314e-07
Estimate:[1] -1.3031992  0.6518951
initial  value 3609.085219 
iter   2 value 3608.802363
iter   2 value 3608.802361
iter   3 value 3608.802198
iter   3 value 3608.802198
iter   3 value 3608.802197
final  value 3608.802197 
converged
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.496707e-09
Estimate:[1] -1.303369  0.651714
initial  value 3608.833668 
iter   2 value 3608.815218
iter   3 value 3608.808534
iter   4 value 3608.806287
iter   5 value 3608.805346
iter   5 value 3608.805346
iter   5 value 3608.805346
final  value 3608.805346 
converged
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 3.498684e-11
Estimate:[1] -1.303384  0.651695
initial  value 3608.808495 
iter   2 value 3608.805754
iter   3 value 3608.805715
iter   3 value 3608.805686
iter   3 value 3608.805668
final  value 3608.805668 
converged
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 3.541394e-13
Estimate:[1] -1.303247  0.651624
initial  value 3608.805987 
iter   2 value 3608.805817
iter   2 value 3608.805809
iter   3 value 3608.805740
iter   3 value 3608.805739
iter   3 value 3608.805715
final  value 3608.805715 
converged
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 7.403837e-15
Estimate:[1] -1.3034377  0.6517188
initial  value 3608.805781 
iter   2 value 3608.805707
iter   2 value 3608.805706
iter   2 value 3608.805697
final  value 3608.805697 
converged
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 2.457234e-17
Estimate:[1] -1.3033871  0.6516936
initial  value 3608.805699 
iter   1 value 3608.805696
final  value 3608.805696 
converged
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 5.361752e-18
Estimate:[1] -1.3033871  0.6516936
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 191 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.303387   0.036163 -36.042 < 2.2e-16 ***
[2,]  0.651694   0.018082  36.042 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## SANN, analytic gradient
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="SANN",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.776 , penalty =  0.9814697 
Estimate:[1] -1.033119  1.011905
SUMT iteration 1: rho = 1, function = -3551.790, penalty = 0.9368044
Estimate:[1] -1.040312  1.004099
SUMT iteration 2: rho = 10, function = -3552.925, penalty = 0.7093408
Estimate:[1] -1.0715767  0.9569002
SUMT iteration 3: rho = 100, function = -3574, penalty = 0.1330147
Estimate:[1] -1.1939293  0.7793205
SUMT iteration 4: rho = 1000, function = -3602.652, penalty = 0.002879373
Estimate:[1] -1.2921933  0.6729266
SUMT iteration 5: rho = 10000, function = -3608.122, penalty = 3.397627e-05
Estimate:[1] -1.2983778  0.6521033
SUMT iteration 6: rho = 1e+05, function = -3608.831, penalty = 4.423519e-08
Estimate:[1] -1.3042925  0.6520411
SUMT iteration 7: rho = 1e+06, function = -3608.81, penalty = 3.638229e-09
Estimate:[1] -1.3089104  0.6544853
SUMT iteration 8: rho = 1e+07, function = -3608.81, penalty = 3.638229e-09
Estimate:[1] -1.3089104  0.6544853
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.847 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.308910   0.036118 -36.239 < 2.2e-16 ***
[2,]  0.654485   0.018059  36.241 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## NM, numeric
> a <- maxLik(logLikMix2, 
+             start=start, method="nm",
+             constraints=list(eqA=A, eqB=B),
+             print.level=1, SUMTRho0=1, rho=0.5)
SUMT initial: rho =  0 , function =  -3551.773 , penalty =  0.9710987 
Estimate:[1] -1.036197  1.010820
SUMT iteration 1: rho = 1, function = -3551.791, penalty = 0.936531
Estimate:[1] -1.040219  1.003982
SUMT iteration 2: rho = 10, function = -3553.01, penalty = 0.7005523
Estimate:[1] -1.0714443  0.9542171
SUMT iteration 3: rho = 100, function = -3574.042, penalty = 0.132589
Estimate:[1] -1.1950464  0.7795871
SUMT iteration 4: rho = 1000, function = -3602.416, penalty = 0.00309852
Estimate:[1] -1.2860675  0.6708659
SUMT iteration 5: rho = 10000, function = -3608.109, penalty = 3.489678e-05
Estimate:[1] -1.301445  0.653676
SUMT iteration 6: rho = 1e+05, function = -3608.735, penalty = 3.613656e-07
Estimate:[1] -1.3032044  0.6519028
SUMT iteration 7: rho = 1e+06, function = -3608.799, penalty = 3.252945e-09
Estimate:[1] -1.3032568  0.6516569
SUMT iteration 8: rho = 1e+07, function = -3608.805, penalty = 2.757146e-11
Estimate:[1] -1.3035064  0.6517558
SUMT iteration 9: rho = 1e+08, function = -3608.806, penalty = 5.38325e-13
Estimate:[1] -1.3033230  0.6516618
SUMT iteration 10: rho = 1e+09, function = -3608.806, penalty = 1.670679e-14
Estimate:[1] -1.3033987  0.6516994
SUMT iteration 11: rho = 1e+10, function = -3608.806, penalty = 1.999005e-15
Estimate:[1] -1.3034033  0.6517016
SUMT iteration 12: rho = 1e+11, function = -3608.806, penalty = 1.255626e-17
Estimate:[1] -1.3035307  0.6517654
SUMT iteration 13: rho = 1e+12, function = -3608.806, penalty = 2.582110e-21
Estimate:[1] -1.3032494  0.6516247
SUMT iteration 14: rho = 1e+13, function = -3608.806, penalty = 6.644046e-20
Estimate:[1] -1.303408  0.651704
SUMT iteration 15: rho = 1e+14, function = -3608.806, penalty = 6.644046e-20
Estimate:[1] -1.303408  0.651704
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 77 iterations
Return code 0: successful convergence 
Log-Likelihood: -3608.806 
2  free parameters
Estimates:
     Estimate Std. error t value   Pr(> t)    
[1,]  -1.3034     0.0000       0 < 2.2e-16 ***
[2,]   0.6517     0.0000       0 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ## ----------- inequality -------------
> A <- matrix(c(-1, 0,
+               0,  1), 2,2, byrow=TRUE)
> B <- c(1, 1)
> start <- c(0.8, 0.9)
> ##
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
initial  value 4650.395504 
iter   2 value 4126.486293
iter   3 value 3988.319246
iter   4 value 3794.409355
iter   5 value 3612.875661
iter   6 value 3579.444764
iter   7 value 3552.403784
iter   8 value 3551.977036
iter   9 value 3551.774563
iter  10 value 3551.773354
iter  10 value 3551.773354
iter  10 value 3551.773354
final  value 3551.773354 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 4010 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036123   0.039845 -26.004 < 2.2e-16 ***
[2,]  1.010784   0.039954  25.299 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ##
> a <- maxLik(logLikMix2, 
+             start=start, method="bfgs",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
initial  value 4650.395504 
iter   2 value 4126.486292
iter   3 value 3988.319244
iter   4 value 3794.409355
iter   5 value 3612.875661
iter   6 value 3579.444764
iter   7 value 3552.403784
iter   8 value 3551.977036
iter   9 value 3551.774563
iter  10 value 3551.773354
iter  10 value 3551.773354
iter  10 value 3551.773354
final  value 3551.773354 
converged
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 4010 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036123   0.039862 -25.993 < 2.2e-16 ***
[2,]  1.010784   0.039961  25.294 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> ##
> a <- maxLik(logLikMix2, gradLikMix2,
+             start=start, method="nm",
+             constraints=list(ineqA=A, ineqB=B),
+             print.level=1, rho=0.5)
  Nelder-Mead direct search function minimizer
function value for initial parameters = 4650.395504
  Scaled convergence tolerance is 4.6504e-05
Stepsize computed as 0.090000
BUILD              3 4734.650205 4650.395504
EXTENSION          5 4717.867666 4545.541480
EXTENSION          7 4650.395504 4398.107307
EXTENSION          9 4545.541480 4057.025391
EXTENSION         11 4398.107307 3765.820064
REFLECTION        13 4057.025391 3607.605056
REFLECTION        15 3765.820064 3555.268193
LO-REDUCTION      17 3607.605056 3555.268193
HI-REDUCTION      19 3577.952096 3555.268193
LO-REDUCTION      21 3568.490004 3555.268193
REFLECTION        23 3562.899144 3551.815286
LO-REDUCTION      25 3555.268193 3551.815286
LO-REDUCTION      27 3554.962931 3551.815286
LO-REDUCTION      29 3552.878451 3551.815286
HI-REDUCTION      31 3552.035159 3551.815286
HI-REDUCTION      33 3551.928631 3551.815286
HI-REDUCTION      35 3551.835416 3551.804225
HI-REDUCTION      37 3551.815286 3551.786153
HI-REDUCTION      39 3551.804225 3551.775106
HI-REDUCTION      41 3551.786153 3551.775106
LO-REDUCTION      43 3551.782575 3551.774053
HI-REDUCTION      45 3551.775106 3551.774053
HI-REDUCTION      47 3551.774844 3551.773446
HI-REDUCTION      49 3551.774053 3551.773446
LO-REDUCTION      51 3551.773707 3551.773439
Exiting from Nelder Mead minimizer
    53 function evaluations used
> summary(a)
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 53 iterations
Return code 0: successful convergence 
Log-Likelihood: -3551.773 
2  free parameters
Estimates:
      Estimate Std. error t value   Pr(> t)    
[1,] -1.036178   0.039848 -26.003 < 2.2e-16 ***
[2,]  1.010351   0.039949  25.291 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> 
