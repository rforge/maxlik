
R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # load the 'maxLik' package
> library(maxLik)
Loading required package: miscTools
> options(digits = 5)
>                            # just to avoid so many differences when comparing these output files
> ## data to fit a normal distribution
> # set seed for pseudo random numbers
> set.seed( 123 )
> # generate a variable from normally distributed random numbers
> x <- rnorm( 100, 1, 2 )
> xSaved <- x
> 
> ## log likelihood function
> llf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    return( llValue )
+ }
> 
> ## log likelihood function (individual observations)
> llfInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    return( llValues )
+ }
> 
> ## function to calculate analytical gradients
> gf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    N <- length( x )
+    llGrad <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    return( llGrad )
+ }
> 
> ## function to calculate analytical gradients (individual observations)
> gfInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    llGrads <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    return( llGrads )
+ }
> 
> ## log likelihood function with gradients as attributes
> llfGrad <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    attributes( llValue )$gradient <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    return( llValue )
+ }
> 
> ## log likelihood function with gradients as attributes (individual observations)
> llfGradInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    attributes( llValues )$gradient <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    return( llValues )
+ }
> 
> ## function to calculate analytical Hessians
> hf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    N <- length( x )
+    llHess <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llHess )
+ }
> 
> ## log likelihood function with gradients and Hessian as attributes
> llfGradHess <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    attributes( llValue )$gradient <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    attributes( llValue )$hessian <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llValue )
+ }
> 
> ## log likelihood function with gradients as attributes (individual observations)
> llfGradHessInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    attributes( llValues )$gradient <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    attributes( llValues )$hessian <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llValues )
+ }
> 
> 
> # start values
> startVal <- c( mu = 0, sigma = 1 )
> 
> ## NR method
> ml <- maxLik( llf, start = startVal )
> print( ml )
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.1808 1.8165 
> summary( ml )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( ml )
   mu sigma 
 TRUE  TRUE 
> AIC( ml )
[1] 407.17
> coef( ml )
    mu  sigma 
1.1808 1.8165 
> condiNumber( ml )
mu 	 1 
sigma 	 1.6686 
> hessian( ml )
              mu      sigma
mu    -30.325964  -0.028422
sigma  -0.028422 -60.623506
> logLik( ml )
[1] -201.58
> maximType( ml )
[1] "Newton-Raphson maximisation"
> nIter( ml )
[1] 7
> try( nObs( ml ) )
Error in nObs.maxLik(ml) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> nParam( ml )
[1] 2
> returnCode( ml )
[1] 2
> returnMessage( ml )
[1] "successive function values within tolerance limit"
> vcov( ml )
               mu       sigma
mu     3.2975e-02 -1.5459e-05
sigma -1.5459e-05  1.6495e-02
> logLik( summary( ml ) )
[1] -201.58
> mlInd <- maxLik( llfInd, start = startVal )
> summary( mlInd )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( ml[ ], mlInd[ -11 ] )
[1] "Component 3: Mean relative difference: 0.84467"  
[2] "Component 4: Mean relative difference: 0.0012492"
[3] "Component 5: Mean relative difference: 0.5"      
[4] "Component 6: 1 string mismatch"                  
> mlInd[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394521 -0.2677853
  [2,] -0.194316 -0.4819268
  [3,]  0.889988  0.8882791
  [4,] -0.012061 -0.5502509
  [5,]  0.023568 -0.5495061
  [6,]  0.984761  1.2110234
  [7,]  0.224579 -0.4588997
  [8,] -0.821594  0.6756407
  [9,] -0.471123 -0.1473352
 [10,] -0.324929 -0.3587334
 [11,]  0.687159  0.3072048
 [12,]  0.163297 -0.5020768
 [13,]  0.188123 -0.4862293
 [14,]  0.012290 -0.5502407
 [15,] -0.391712 -0.2717972
 [16,]  1.028310  1.3702713
 [17,]  0.246966 -0.4397240
 [18,] -1.246831  2.2733632
 [19,]  0.370317 -0.3014121
 [20,] -0.341373 -0.3388307
 [21,] -0.702042  0.3447610
 [22,] -0.186920 -0.4870489
 [23,] -0.676694  0.2812781
 [24,] -0.496604 -0.1025434
 [25,] -0.433655 -0.2089131
 [26,] -1.077160  1.5570986
 [27,]  0.453013 -0.1777357
 [28,]  0.038167 -0.5478690
 [29,] -0.744661  0.4567604
 [30,]  0.705181  0.3527859
 [31,]  0.203696 -0.4751454
 [32,] -0.233651 -0.4513485
 [33,]  0.487768 -0.1183427
 [34,]  0.477468 -0.1364012
 [35,]  0.443190 -0.1937268
 [36,]  0.362610 -0.3116733
 [37,]  0.280950 -0.4071349
 [38,] -0.092325 -0.5350316
 [39,] -0.240252 -0.4456656
 [40,] -0.285414 -0.4025421
 [41,] -0.475883 -0.1391458
 [42,] -0.180824 -0.4911212
 [43,] -0.821797  0.6762470
 [44,]  1.259879  2.3327769
 [45,]  0.677388  0.2829863
 [46,] -0.735552  0.4322678
 [47,] -0.299000 -0.3881197
 [48,] -0.337654 -0.3434182
 [49,]  0.417965 -0.2331853
 [50,] -0.105331 -0.5303620
 [51,]  0.098747 -0.5328027
 [52,] -0.072101 -0.5410719
 [53,] -0.080783 -0.5386608
 [54,]  0.774758  0.5398271
 [55,] -0.191645 -0.4837994
 [56,]  0.864386  0.8066920
 [57,] -0.993549  1.2426062
 [58,]  0.299556 -0.3875153
 [59,]  0.020274 -0.5497684
 [60,]  0.076091 -0.5399978
 [61,]  0.175314 -0.4946854
 [62,] -0.359273 -0.3160487
 [63,] -0.256766 -0.4307565
 [64,] -0.672191  0.2702447
 [65,] -0.704447  0.3509050
 [66,]  0.129181 -0.5202022
 [67,]  0.216877 -0.4650758
 [68,] -0.022670 -0.5495815
 [69,]  0.504219 -0.0886982
 [70,]  1.187827  2.0124190
 [71,] -0.352429 -0.3248974
 [72,] -1.454463  3.2921827
 [73,]  0.554814  0.0086313
 [74,] -0.484669 -0.1238172
 [75,] -0.471823 -0.1461352
 [76,]  0.566835  0.0331243
 [77,] -0.227409 -0.4565764
 [78,] -0.794716  0.5967266
 [79,]  0.055096 -0.5450010
 [80,] -0.138985 -0.5154265
 [81,] -0.051304 -0.5457339
 [82,]  0.178733 -0.4924865
 [83,] -0.279468 -0.4086440
 [84,]  0.335780 -0.3457098
 [85,] -0.188442 -0.4860109
 [86,]  0.146306 -0.5116324
 [87,]  0.610033  0.1254706
 [88,]  0.208980 -0.4711845
 [89,] -0.252356 -0.4348350
 [90,]  0.641533  0.1970839
 [91,]  0.547398 -0.0062163
 [92,]  0.277604 -0.4105300
 [93,]  0.089905 -0.5358325
 [94,] -0.435393 -0.2061700
 [95,]  0.769939  0.5263064
 [96,] -0.418636 -0.2321663
 [97,]  1.271018  2.3839862
 [98,]  0.874169  0.8375872
 [99,] -0.197664 -0.4795433
[100,] -0.676946  0.2818988

> nObs( mlInd )
[1] 100
> 
> # with analytical gradients
> mlg <- maxLik( llf, gf, start = startVal )
> summary( mlg )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( ml, mlg )
[1] "Component 2: Mean relative difference: 1.6411e-08"
[2] "Component 3: Mean relative difference: 1.0078"    
[3] "Component 4: Mean relative difference: 0.00094782"
[4] "Component 5: Mean relative difference: 0.5"       
[5] "Component 6: 1 string mismatch"                   
> mlgInd <- maxLik( llfInd, gfInd, start = startVal )
> all.equal( mlInd, mlgInd )
[1] "Component 3: Mean relative difference: 1.0502"    
[2] "Component 4: Mean relative difference: 0.00052447"
> all.equal( mlg[ ], mlgInd[ -11 ] )
[1] TRUE
> mlgInd[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394521 -0.2677853
  [2,] -0.194316 -0.4819268
  [3,]  0.889988  0.8882791
  [4,] -0.012061 -0.5502509
  [5,]  0.023568 -0.5495062
  [6,]  0.984761  1.2110234
  [7,]  0.224579 -0.4588997
  [8,] -0.821594  0.6756407
  [9,] -0.471123 -0.1473352
 [10,] -0.324929 -0.3587334
 [11,]  0.687159  0.3072048
 [12,]  0.163297 -0.5020768
 [13,]  0.188123 -0.4862293
 [14,]  0.012290 -0.5502407
 [15,] -0.391712 -0.2717972
 [16,]  1.028310  1.3702714
 [17,]  0.246966 -0.4397240
 [18,] -1.246831  2.2733632
 [19,]  0.370317 -0.3014121
 [20,] -0.341373 -0.3388307
 [21,] -0.702042  0.3447610
 [22,] -0.186920 -0.4870489
 [23,] -0.676694  0.2812781
 [24,] -0.496604 -0.1025434
 [25,] -0.433655 -0.2089131
 [26,] -1.077160  1.5570986
 [27,]  0.453013 -0.1777357
 [28,]  0.038167 -0.5478690
 [29,] -0.744661  0.4567604
 [30,]  0.705181  0.3527859
 [31,]  0.203696 -0.4751454
 [32,] -0.233651 -0.4513485
 [33,]  0.487768 -0.1183427
 [34,]  0.477468 -0.1364012
 [35,]  0.443190 -0.1937268
 [36,]  0.362610 -0.3116733
 [37,]  0.280950 -0.4071349
 [38,] -0.092325 -0.5350316
 [39,] -0.240252 -0.4456656
 [40,] -0.285414 -0.4025421
 [41,] -0.475883 -0.1391458
 [42,] -0.180824 -0.4911212
 [43,] -0.821797  0.6762470
 [44,]  1.259879  2.3327769
 [45,]  0.677388  0.2829863
 [46,] -0.735552  0.4322678
 [47,] -0.299000 -0.3881197
 [48,] -0.337654 -0.3434182
 [49,]  0.417965 -0.2331853
 [50,] -0.105331 -0.5303620
 [51,]  0.098747 -0.5328027
 [52,] -0.072101 -0.5410720
 [53,] -0.080783 -0.5386608
 [54,]  0.774758  0.5398271
 [55,] -0.191645 -0.4837994
 [56,]  0.864386  0.8066920
 [57,] -0.993549  1.2426062
 [58,]  0.299556 -0.3875153
 [59,]  0.020274 -0.5497684
 [60,]  0.076091 -0.5399978
 [61,]  0.175314 -0.4946854
 [62,] -0.359273 -0.3160487
 [63,] -0.256766 -0.4307565
 [64,] -0.672191  0.2702447
 [65,] -0.704447  0.3509051
 [66,]  0.129181 -0.5202022
 [67,]  0.216877 -0.4650758
 [68,] -0.022670 -0.5495815
 [69,]  0.504219 -0.0886982
 [70,]  1.187827  2.0124190
 [71,] -0.352429 -0.3248974
 [72,] -1.454463  3.2921827
 [73,]  0.554814  0.0086313
 [74,] -0.484669 -0.1238172
 [75,] -0.471823 -0.1461352
 [76,]  0.566835  0.0331243
 [77,] -0.227409 -0.4565764
 [78,] -0.794716  0.5967266
 [79,]  0.055096 -0.5450010
 [80,] -0.138985 -0.5154265
 [81,] -0.051304 -0.5457339
 [82,]  0.178733 -0.4924865
 [83,] -0.279468 -0.4086440
 [84,]  0.335780 -0.3457098
 [85,] -0.188442 -0.4860109
 [86,]  0.146306 -0.5116324
 [87,]  0.610033  0.1254706
 [88,]  0.208980 -0.4711845
 [89,] -0.252356 -0.4348350
 [90,]  0.641533  0.1970839
 [91,]  0.547398 -0.0062163
 [92,]  0.277604 -0.4105300
 [93,]  0.089905 -0.5358325
 [94,] -0.435393 -0.2061700
 [95,]  0.769939  0.5263064
 [96,] -0.418636 -0.2321663
 [97,]  1.271018  2.3839863
 [98,]  0.874169  0.8375872
 [99,] -0.197664 -0.4795433
[100,] -0.676946  0.2818988

> 
> # with analytical gradients as attribute
> mlG <- maxLik( llfGrad, start = startVal )
> all.equal( mlG, mlg, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlG$gradient, gf( coef( mlG ) ), check.attributes = FALSE )
[1] TRUE
> mlGInd <- maxLik( llfGradInd, start = startVal )
> all.equal( mlGInd, mlgInd, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlGInd$gradient, colSums( gfInd( coef( mlGInd ) ) ),
+    check.attributes = FALSE )
[1] TRUE
> all.equal( mlGInd$gradientObs, gfInd( coef( mlGInd ) ),
+    check.attributes = FALSE )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgG <- maxLik( llfGrad, gf, start = startVal )
Warning message:
In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgG, mlg, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlgG, mlG, tolerance = 1e-10 )
[1] TRUE
> 
> # with analytical gradients and Hessians
> mlgh <- maxLik( llf, gf, hf, start = startVal )
> all.equal( mlg, mlgh )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGH <- maxLik( llfGradHess, start = startVal )
> all.equal( mlGH, mlgh, tolerance = 1e-10 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhH <- maxLik( llfGradHess, gf, hf, start = startVal )
Warning messages:
1: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhH, mlgh, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlgGhH, mlGH, tolerance = 1e-10 )
[1] TRUE
> 
> 
> ## BHHH method
> mlBHHH <- try( maxLik( llf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  if the gradients (argument 'grad') are not provided by the user, the BHHH method requires that the log-likelihood function (argument 'fn') returns a numeric vector, where each element must be the log-likelihood value corresponding to an individual (independent) observation
> x <- xSaved[1]
> try( maxLik( llfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  if the gradients (argument 'grad') are not provided by the user, the BHHH method requires that the log-likelihood function (argument 'fn') returns a numeric vector, where each element must be the log-likelihood value corresponding to an individual (independent) observation
> x <- xSaved[1:2]
> try( maxLik( llfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.62274 (2 free parameter(s))
Estimate(s): 0.21583 0.33024 
> x <- xSaved
> mlBHHH <- maxLik( llfInd, start = startVal, method = "BHHH" )
> print( mlBHHH )
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.1808 1.8165 
> summary( mlBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182    6.49 8.4e-11 ***
sigma    1.816      0.134   13.55 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlBHHH )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBHHH )
[1] 407.17
> coef( mlBHHH )
    mu  sigma 
1.1808 1.8165 
> condiNumber( mlBHHH )
mu 	 1 
sigma 	 1.719 
> hessian( mlBHHH )
            mu    sigma
mu    -30.3067  -1.8335
sigma  -1.8335 -55.7325
attr(,"type")
[1] "BHHH"
> logLik( mlBHHH )
[1] -201.58
> maximType( mlBHHH )
[1] "BHHH maximisation"
> nIter( mlBHHH )
[1] 13
> nParam( mlBHHH )
[1] 2
> returnCode( mlBHHH )
[1] 2
> returnMessage( mlBHHH )
[1] "successive function values within tolerance limit"
> vcov( mlBHHH )
              mu      sigma
mu     0.0330618 -0.0010877
sigma -0.0010877  0.0179786
> logLik( summary( mlBHHH ) )
[1] -201.58
> all.equal( ml[ ], mlBHHH[ -11 ] )
[1] "Component 2: Mean relative difference: 2.472e-07"                              
[2] "Component 3: Mean relative difference: 19.398"                                 
[3] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[4] "Component 4: Mean relative difference: 0.093625"                               
[5] "Component 9: Mean relative difference: 0.85714"                                
[6] "Component 10: 1 string mismatch"                                               
> mlBHHH[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394522 -0.2677851
  [2,] -0.194317 -0.4819269
  [3,]  0.889988  0.8882798
  [4,] -0.012061 -0.5502510
  [5,]  0.023568 -0.5495063
  [6,]  0.984761  1.2110244
  [7,]  0.224579 -0.4588999
  [8,] -0.821595  0.6756418
  [9,] -0.471123 -0.1473348
 [10,] -0.324929 -0.3587332
 [11,]  0.687159  0.3072051
 [12,]  0.163297 -0.5020770
 [13,]  0.188123 -0.4862295
 [14,]  0.012290 -0.5502408
 [15,] -0.391712 -0.2717970
 [16,]  1.028311  1.3702724
 [17,]  0.246966 -0.4397242
 [18,] -1.246832  2.2733657
 [19,]  0.370317 -0.3014121
 [20,] -0.341373 -0.3388306
 [21,] -0.702042  0.3447618
 [22,] -0.186920 -0.4870489
 [23,] -0.676694  0.2812788
 [24,] -0.496604 -0.1025431
 [25,] -0.433656 -0.2089128
 [26,] -1.077160  1.5571004
 [27,]  0.453013 -0.1777357
 [28,]  0.038166 -0.5478692
 [29,] -0.744662  0.4567613
 [30,]  0.705182  0.3527863
 [31,]  0.203696 -0.4751455
 [32,] -0.233651 -0.4513485
 [33,]  0.487768 -0.1183427
 [34,]  0.477468 -0.1364012
 [35,]  0.443190 -0.1937268
 [36,]  0.362610 -0.3116733
 [37,]  0.280950 -0.4071350
 [38,] -0.092325 -0.5350317
 [39,] -0.240253 -0.4456656
 [40,] -0.285415 -0.4025420
 [41,] -0.475884 -0.1391455
 [42,] -0.180824 -0.4911212
 [43,] -0.821798  0.6762481
 [44,]  1.259880  2.3327787
 [45,]  0.677389  0.2829866
 [46,] -0.735553  0.4322687
 [47,] -0.299000 -0.3881197
 [48,] -0.337654 -0.3434181
 [49,]  0.417965 -0.2331854
 [50,] -0.105331 -0.5303621
 [51,]  0.098747 -0.5328029
 [52,] -0.072101 -0.5410721
 [53,] -0.080783 -0.5386609
 [54,]  0.774758  0.5398276
 [55,] -0.191646 -0.4837994
 [56,]  0.864386  0.8066926
 [57,] -0.993550  1.2426078
 [58,]  0.299556 -0.3875154
 [59,]  0.020274 -0.5497686
 [60,]  0.076091 -0.5399980
 [61,]  0.175314 -0.4946856
 [62,] -0.359274 -0.3160486
 [63,] -0.256767 -0.4307564
 [64,] -0.672191  0.2702455
 [65,] -0.704447  0.3509058
 [66,]  0.129181 -0.5202024
 [67,]  0.216877 -0.4650759
 [68,] -0.022671 -0.5495816
 [69,]  0.504220 -0.0886982
 [70,]  1.187828  2.0124205
 [71,] -0.352429 -0.3248973
 [72,] -1.454464  3.2921861
 [73,]  0.554814  0.0086314
 [74,] -0.484669 -0.1238169
 [75,] -0.471824 -0.1461349
 [76,]  0.566836  0.0331244
 [77,] -0.227409 -0.4565764
 [78,] -0.794717  0.5967277
 [79,]  0.055096 -0.5450012
 [80,] -0.138985 -0.5154266
 [81,] -0.051304 -0.5457340
 [82,]  0.178733 -0.4924866
 [83,] -0.279468 -0.4086440
 [84,]  0.335780 -0.3457099
 [85,] -0.188443 -0.4860109
 [86,]  0.146306 -0.5116326
 [87,]  0.610033  0.1254708
 [88,]  0.208980 -0.4711846
 [89,] -0.252356 -0.4348349
 [90,]  0.641533  0.1970842
 [91,]  0.547398 -0.0062162
 [92,]  0.277604 -0.4105302
 [93,]  0.089905 -0.5358327
 [94,] -0.435393 -0.2061697
 [95,]  0.769940  0.5263068
 [96,] -0.418636 -0.2321661
 [97,]  1.271019  2.3839881
 [98,]  0.874169  0.8375879
 [99,] -0.197664 -0.4795433
[100,] -0.676947  0.2818995

> nObs( mlBHHH )
[1] 100
> # final Hessian = usual Hessian
> mlBhhhH <- maxLik( llfInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlBhhhH, mlBHHH )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.094309"                               
> hessian( mlBhhhH ) 
           mu   sigma
mu    -30.326   0.000
sigma   0.000 -60.624
> summary( mlBhhhH ) 
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> 
> # with analytical gradients
> mlgBHHH <- try( maxLik( llf, gf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> mlgBHHH <- try( maxLik( llfInd, gf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> x <- xSaved[1]
> try( maxLik( llf, gfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> try( maxLik( llfInd, gfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> x <- xSaved[1:2]
> try( maxLik( llf, gfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.62274 (2 free parameter(s))
Estimate(s): 0.21583 0.33024 
> try( maxLik( llfInd, gfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.62274 (2 free parameter(s))
Estimate(s): 0.21583 0.33024 
> x <- xSaved
> mlgBHHH <- maxLik( llfInd, gfInd, start = startVal, method = "BHHH" )
> summary( mlgBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182    6.49 8.4e-11 ***
sigma    1.816      0.134   13.55 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlBHHH, mlgBHHH )
[1] "Component 3: Mean relative difference: 0.00065265"
> all.equal( mlg[ ], mlgBHHH[ -11 ] )
[1] "Component 2: Mean relative difference: 2.534e-07"                              
[2] "Component 3: Mean absolute difference: 1.8807e-05"                             
[3] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[4] "Component 4: Mean relative difference: 0.094017"                               
[5] "Component 5: Mean relative difference: 1"                                      
[6] "Component 6: 1 string mismatch"                                                
[7] "Component 9: Mean relative difference: 0.85714"                                
[8] "Component 10: 1 string mismatch"                                               
> mlgBHHH[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394522 -0.2677851
  [2,] -0.194317 -0.4819269
  [3,]  0.889988  0.8882798
  [4,] -0.012061 -0.5502510
  [5,]  0.023568 -0.5495063
  [6,]  0.984761  1.2110244
  [7,]  0.224579 -0.4588999
  [8,] -0.821595  0.6756418
  [9,] -0.471123 -0.1473348
 [10,] -0.324929 -0.3587332
 [11,]  0.687159  0.3072051
 [12,]  0.163297 -0.5020770
 [13,]  0.188123 -0.4862295
 [14,]  0.012290 -0.5502408
 [15,] -0.391712 -0.2717970
 [16,]  1.028311  1.3702724
 [17,]  0.246966 -0.4397242
 [18,] -1.246832  2.2733657
 [19,]  0.370317 -0.3014121
 [20,] -0.341373 -0.3388306
 [21,] -0.702042  0.3447618
 [22,] -0.186920 -0.4870489
 [23,] -0.676694  0.2812788
 [24,] -0.496604 -0.1025431
 [25,] -0.433656 -0.2089128
 [26,] -1.077160  1.5571004
 [27,]  0.453013 -0.1777357
 [28,]  0.038166 -0.5478692
 [29,] -0.744662  0.4567613
 [30,]  0.705182  0.3527863
 [31,]  0.203696 -0.4751455
 [32,] -0.233651 -0.4513485
 [33,]  0.487768 -0.1183427
 [34,]  0.477468 -0.1364012
 [35,]  0.443190 -0.1937268
 [36,]  0.362610 -0.3116733
 [37,]  0.280950 -0.4071350
 [38,] -0.092325 -0.5350317
 [39,] -0.240253 -0.4456656
 [40,] -0.285415 -0.4025420
 [41,] -0.475884 -0.1391455
 [42,] -0.180824 -0.4911212
 [43,] -0.821798  0.6762481
 [44,]  1.259880  2.3327787
 [45,]  0.677389  0.2829866
 [46,] -0.735553  0.4322687
 [47,] -0.299000 -0.3881197
 [48,] -0.337654 -0.3434181
 [49,]  0.417965 -0.2331854
 [50,] -0.105331 -0.5303621
 [51,]  0.098747 -0.5328029
 [52,] -0.072101 -0.5410721
 [53,] -0.080783 -0.5386609
 [54,]  0.774758  0.5398276
 [55,] -0.191646 -0.4837994
 [56,]  0.864386  0.8066926
 [57,] -0.993550  1.2426078
 [58,]  0.299556 -0.3875154
 [59,]  0.020274 -0.5497686
 [60,]  0.076091 -0.5399980
 [61,]  0.175314 -0.4946856
 [62,] -0.359274 -0.3160486
 [63,] -0.256767 -0.4307564
 [64,] -0.672191  0.2702455
 [65,] -0.704447  0.3509058
 [66,]  0.129181 -0.5202024
 [67,]  0.216877 -0.4650759
 [68,] -0.022671 -0.5495816
 [69,]  0.504220 -0.0886982
 [70,]  1.187828  2.0124205
 [71,] -0.352429 -0.3248973
 [72,] -1.454464  3.2921861
 [73,]  0.554814  0.0086314
 [74,] -0.484669 -0.1238169
 [75,] -0.471824 -0.1461349
 [76,]  0.566836  0.0331244
 [77,] -0.227409 -0.4565764
 [78,] -0.794717  0.5967277
 [79,]  0.055096 -0.5450012
 [80,] -0.138985 -0.5154266
 [81,] -0.051304 -0.5457340
 [82,]  0.178733 -0.4924866
 [83,] -0.279468 -0.4086440
 [84,]  0.335780 -0.3457099
 [85,] -0.188443 -0.4860109
 [86,]  0.146306 -0.5116326
 [87,]  0.610033  0.1254708
 [88,]  0.208980 -0.4711846
 [89,] -0.252356 -0.4348349
 [90,]  0.641533  0.1970842
 [91,]  0.547398 -0.0062162
 [92,]  0.277604 -0.4105302
 [93,]  0.089905 -0.5358327
 [94,] -0.435393 -0.2061697
 [95,]  0.769940  0.5263068
 [96,] -0.418636 -0.2321661
 [97,]  1.271019  2.3839881
 [98,]  0.874169  0.8375879
 [99,] -0.197664 -0.4795433
[100,] -0.676947  0.2818995

> mlgBHHH2 <- maxLik( llf, gfInd, start = startVal, method = "BHHH" )
> all.equal( mlgBHHH, mlgBHHH2 )
[1] TRUE
> # final Hessian = usual Hessian
> mlgBhhhH <- maxLik( llf, gfInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlgBhhhH, mlBhhhH )
[1] "Component 3: Mean relative difference: 0.00065222"
[2] "Component 4: Mean relative difference: 0.00032266"
> all.equal( mlgBhhhH, mlgBHHH )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.094017"                               
> hessian( mlgBhhhH ) 
               mu       sigma
mu    -3.0307e+01  9.2728e-06
sigma  9.2734e-06 -6.0613e+01
> 
> # with analytical gradients as attribute
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> x <- xSaved[1]
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> try( maxLik( llfGradInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> x <- xSaved[1:2]
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> try( maxLik( llfGradInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.62274 (2 free parameter(s))
Estimate(s): 0.21583 0.33024 
> x <- xSaved
> mlGBHHH <- maxLik( llfGradInd, start = startVal, method = "BHHH" )
> all.equal( mlGBHHH, mlgBHHH, tolerance = 1e-10 )
[1] TRUE
> # final Hessian = usual Hessian
> mlGBhhhH <- maxLik( llfGradInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlGBhhhH, mlgBhhhH )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBHHH <- maxLik( llfGradInd, gfInd, start = startVal, method = "BHHH" )
Warning message:
In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBHHH, mlgBHHH, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlgGBHHH, mlGBHHH, tolerance = 1e-10 )
[1] TRUE
> 
> # with unused Hessian
> mlghBHHH <- maxLik( llfInd, gfInd, hf, start = startVal, method = "BHHH" )
> all.equal( mlgBHHH, mlghBHHH )
[1] TRUE
> # final Hessian = usual Hessian
> mlghBhhhH <- maxLik( llfInd, gfInd, hf, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlghBhhhH, mlghBHHH )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.094017"                               
> all.equal( mlghBhhhH, mlgBhhhH )
[1] TRUE
> 
> # with unused Hessian as attribute
> mlGHBHHH <- maxLik( llfGradHessInd, start = startVal, method = "BHHH" )
> all.equal( mlGHBHHH, mlghBHHH, tolerance = 1e-10 )
[1] TRUE
> # final Hessian = usual Hessian
> mlGHBhhhH <- maxLik( llfGradHessInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlGHBhhhH, mlghBhhhH )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBHHH <- maxLik( llfGradHessInd, gfInd, hf, start = startVal, method = "BHHH" )
Warning messages:
1: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBHHH, mlghBHHH, tolerance = 1e-10 )
[1] TRUE
> all.equal( mlgGhHBHHH, mlGHBHHH, tolerance = 1e-10 )
[1] TRUE
> 
> 
> ### BFGS-YC method
> mlBFGSYC <- maxLik( llf, start = startVal, method = "bfgsr" )
> print( mlBFGSYC )
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.181 1.8165 
> summary( mlBFGSYC )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlBFGSYC )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBFGSYC )
[1] 407.17
> coef( mlBFGSYC )
    mu  sigma 
1.1810 1.8165 
> condiNumber( mlBFGSYC )
mu 	 1 
sigma 	 1.6679 
> hessian( mlBFGSYC )
              mu      sigma
mu    -30.297542   0.028422
sigma   0.028422 -60.538241
> logLik( mlBFGSYC )
[1] -201.58
> maximType( mlBFGSYC )
[1] "BFGSR maximization"
> nIter( mlBFGSYC )
[1] 15
> try( nObs( mlBFGSYC ) )
Error in nObs.maxLik(mlBFGSYC) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> nParam( mlBFGSYC )
[1] 2
> returnCode( mlBFGSYC )
[1] 2
> returnMessage( mlBFGSYC )
[1] "successive function values within tolerance limit"
> vcov( mlBFGSYC )
              mu      sigma
mu    3.3006e-02 1.5496e-05
sigma 1.5496e-05 1.6518e-02
> logLik( summary( mlBFGSYC ) )
[1] -201.58
> all.equal( ml[-c(5,6,9,10)], mlBFGSYC[-c(5,6,9,10)] )
[1] "Component 2: Mean relative difference: 6.8052e-05"
[2] "Component 3: Mean relative difference: 3592"      
[3] "Component 4: Mean relative difference: 0.0024984" 
> mlIndBFGSYC <- maxLik( llfInd, start = startVal, method = "BFGSR" )
> summary( mlIndBFGSYC )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 34 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlBFGSYC[ -9 ], mlIndBFGSYC[ -c(9,11) ] )
[1] "Component 2: Mean relative difference: 9.347e-05"
[2] "Component 3: Mean relative difference: 1.6615"   
[3] "Component 4: Mean relative difference: 0.0025016"
> mlIndBFGSYC[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394576 -0.2677651
  [2,] -0.194343 -0.4819508
  [3,]  0.890111  0.8885401
  [4,] -0.012062 -0.5502888
  [5,]  0.023571 -0.5495439
  [6,]  0.984897  1.2113513
  [7,]  0.224610 -0.4589186
  [8,] -0.821708  0.6758560
  [9,] -0.471188 -0.1472901
 [10,] -0.324973 -0.3587319
 [11,]  0.687254  0.3073451
 [12,]  0.163320 -0.5021047
 [13,]  0.188149 -0.4862539
 [14,]  0.012292 -0.5502786
 [15,] -0.391766 -0.2717778
 [16,]  1.028453  1.3706323
 [17,]  0.247000 -0.4397389
 [18,] -1.247003  2.2739092
 [19,]  0.370369 -0.3013981
 [20,] -0.341420 -0.3388252
 [21,] -0.702139  0.3449079
 [22,] -0.186946 -0.4870739
 [23,] -0.676787  0.2814119
 [24,] -0.496672 -0.1024891
 [25,] -0.433715 -0.2088807
 [26,] -1.077308  1.5574963
 [27,]  0.453076 -0.1776960
 [28,]  0.038172 -0.5479065
 [29,] -0.744764  0.4569304
 [30,]  0.705279  0.3529358
 [31,]  0.203725 -0.4751676
 [32,] -0.233683 -0.4513662
 [33,]  0.487835 -0.1182908
 [34,]  0.477534 -0.1363530
 [35,]  0.443251 -0.1936905
 [36,]  0.362660 -0.3116615
 [37,]  0.280989 -0.4071430
 [38,] -0.092337 -0.5350665
 [39,] -0.240285 -0.4456822
 [40,] -0.285454 -0.4025497
 [41,] -0.475949 -0.1390990
 [42,] -0.180848 -0.4911471
 [43,] -0.821911  0.6764625
 [44,]  1.260054  2.3333376
 [45,]  0.677482  0.2831216
 [46,] -0.735653  0.4324328
 [47,] -0.299041 -0.3881244
 [48,] -0.337700 -0.3434136
 [49,]  0.418023 -0.2331572
 [50,] -0.105345 -0.5303959
 [51,]  0.098761 -0.5328370
 [52,] -0.072111 -0.5411081
 [53,] -0.080794 -0.5386965
 [54,]  0.774865  0.5400157
 [55,] -0.191672 -0.4838238
 [56,]  0.864506  0.8069360
 [57,] -0.993686  1.2429389
 [58,]  0.299598 -0.3875193
 [59,]  0.020277 -0.5498063
 [60,]  0.076102 -0.5400336
 [61,]  0.175339 -0.4947117
 [62,] -0.359323 -0.3160385
 [63,] -0.256802 -0.4307699
 [64,] -0.672284  0.2703762
 [65,] -0.704544  0.3510532
 [66,]  0.129199 -0.5202338
 [67,]  0.216907 -0.4650959
 [68,] -0.022673 -0.5496194
 [69,]  0.504289 -0.0886401
 [70,]  1.187992  2.0129132
 [71,] -0.352477 -0.3248890
 [72,] -1.454664  3.2929397
 [73,]  0.554891  0.0087097
 [74,] -0.484735 -0.1237673
 [75,] -0.471888 -0.1460899
 [76,]  0.566914  0.0332077
 [77,] -0.227440 -0.4565952
 [78,] -0.794826  0.5969256
 [79,]  0.055104 -0.5450378
 [80,] -0.139004 -0.5154574
 [81,] -0.051311 -0.5457710
 [82,]  0.178758 -0.4925123
 [83,] -0.279506 -0.4086529
 [84,]  0.335827 -0.3457051
 [85,] -0.188468 -0.4860357
 [86,]  0.146327 -0.5116622
 [87,]  0.610118  0.1255732
 [88,]  0.209009 -0.4712059
 [89,] -0.252391 -0.4348493
 [90,]  0.641622  0.1972014
 [91,]  0.547474 -0.0061410
 [92,]  0.277642 -0.4105388
 [93,]  0.089918 -0.5358674
 [94,] -0.435453 -0.2061371
 [95,]  0.770046  0.5264922
 [96,] -0.418693 -0.2321387
 [97,]  1.271194  2.3845575
 [98,]  0.874290  0.8378377
 [99,] -0.197691 -0.4795668
[100,] -0.677040  0.2820327

> nObs( mlIndBFGSYC )
[1] 100
> 
> # with analytical gradients
> mlgBFGSYC <- maxLik( llf, gf, start = startVal, method = "BFGSR" , print.level=1)
Initial value of the function : -326.589781090132 
Iteration  1 
step = 1, lnL = -325.1, chi2 = 1.5039, function increment = 1.494
Iteration  2 
step = 1, lnL = -254.9, chi2 = 107.75, function increment = 70.193
Iteration  3 
step = 1, lnL = -254.76, chi2 = 0.14697, function increment = 0.14642
Iteration  4 
step = 1, lnL = -249.98, chi2 = 18.759, function increment = 4.7779
Iteration  5 
step = 0.25, lnL = -218.8, chi2 = 1496.1, function increment = 31.178
Iteration  6 
step = 1, lnL = -201.74, chi2 = 22.409, function increment = 17.059
Iteration  7 
step = 0.25, lnL = -201.65, chi2 = 0.75772, function increment = 0.086956
Iteration  8 
step = 1, lnL = -201.6, chi2 = 0.078918, function increment = 0.053616
Iteration  9 
step = 0.25, lnL = -201.6, chi2 = 0.071851, function increment = 0.0040907
Iteration  10 
step = 0.125, lnL = -201.58, chi2 = 0.22304, function increment = 0.012766
Iteration  11 
step = 0.0625, lnL = -201.58, chi2 = 0.0027953, function increment = 6.3138e-05
Iteration  12 
step = 0.5, lnL = -201.58, chi2 = 0.00012507, function increment = 2.4558e-05
Iteration  13 
step = 0.0625, lnL = -201.58, chi2 = 6.6452e-05, function increment = 4.2386e-07
Iteration  14 
step = 0.03125, lnL = -201.58, chi2 = 1.7822e-05, function increment = 2.5402e-07
Iteration  15 
step = 0.015625, lnL = -201.58, chi2 = 5.203e-08, function increment = 2.6043e-10
--------------
successive function values within tolerance limit 
15  iterations
estimate: 1.181 1.8165 
Function value: -201.58 
> summary(mlgBFGSYC)
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlBFGSYC, mlgBFGSYC )
[1] "Component 3: Mean relative difference: 1.9416e-05"
[2] "Component 4: Mean relative difference: 0.0014764" 
> mlgIndBFGSYC <- maxLik( llfInd, gfInd, start = startVal,
+    method = "BFGSR" )
> all.equal( mlIndBFGSYC, mlgIndBFGSYC )
[1] "Component 3: Mean relative difference: 6.6842e-06"
[2] "Component 4: Mean relative difference: 0.00067237"
> all.equal( mlgBFGSYC[ -9 ], mlgIndBFGSYC[ -c(9,11) ] )
[1] "Component 2: Mean relative difference: 9.3472e-05"
[2] "Component 3: Mean relative difference: 1.6615"    
[3] "Component 4: Mean relative difference: 0.00035303"
> mlgIndBFGSYC[ 11 ]
$gradientObs
              mu      sigma
  [1,] -0.394576 -0.2677651
  [2,] -0.194343 -0.4819508
  [3,]  0.890111  0.8885401
  [4,] -0.012062 -0.5502888
  [5,]  0.023571 -0.5495439
  [6,]  0.984897  1.2113513
  [7,]  0.224610 -0.4589186
  [8,] -0.821708  0.6758560
  [9,] -0.471188 -0.1472901
 [10,] -0.324973 -0.3587319
 [11,]  0.687254  0.3073451
 [12,]  0.163320 -0.5021047
 [13,]  0.188149 -0.4862539
 [14,]  0.012292 -0.5502786
 [15,] -0.391766 -0.2717779
 [16,]  1.028453  1.3706323
 [17,]  0.247000 -0.4397389
 [18,] -1.247003  2.2739092
 [19,]  0.370369 -0.3013981
 [20,] -0.341420 -0.3388252
 [21,] -0.702139  0.3449079
 [22,] -0.186946 -0.4870739
 [23,] -0.676787  0.2814119
 [24,] -0.496672 -0.1024891
 [25,] -0.433715 -0.2088807
 [26,] -1.077308  1.5574963
 [27,]  0.453076 -0.1776960
 [28,]  0.038172 -0.5479065
 [29,] -0.744764  0.4569304
 [30,]  0.705279  0.3529358
 [31,]  0.203725 -0.4751676
 [32,] -0.233683 -0.4513662
 [33,]  0.487835 -0.1182908
 [34,]  0.477534 -0.1363530
 [35,]  0.443251 -0.1936905
 [36,]  0.362660 -0.3116615
 [37,]  0.280989 -0.4071430
 [38,] -0.092337 -0.5350665
 [39,] -0.240285 -0.4456822
 [40,] -0.285454 -0.4025497
 [41,] -0.475949 -0.1390990
 [42,] -0.180848 -0.4911471
 [43,] -0.821911  0.6764625
 [44,]  1.260054  2.3333376
 [45,]  0.677482  0.2831216
 [46,] -0.735653  0.4324328
 [47,] -0.299041 -0.3881244
 [48,] -0.337700 -0.3434136
 [49,]  0.418023 -0.2331572
 [50,] -0.105345 -0.5303959
 [51,]  0.098761 -0.5328370
 [52,] -0.072111 -0.5411081
 [53,] -0.080794 -0.5386965
 [54,]  0.774865  0.5400157
 [55,] -0.191672 -0.4838238
 [56,]  0.864506  0.8069360
 [57,] -0.993686  1.2429389
 [58,]  0.299598 -0.3875193
 [59,]  0.020277 -0.5498063
 [60,]  0.076102 -0.5400336
 [61,]  0.175339 -0.4947117
 [62,] -0.359323 -0.3160385
 [63,] -0.256802 -0.4307699
 [64,] -0.672284  0.2703762
 [65,] -0.704544  0.3510532
 [66,]  0.129199 -0.5202338
 [67,]  0.216907 -0.4650959
 [68,] -0.022673 -0.5496194
 [69,]  0.504289 -0.0886401
 [70,]  1.187992  2.0129132
 [71,] -0.352477 -0.3248890
 [72,] -1.454664  3.2929397
 [73,]  0.554891  0.0087097
 [74,] -0.484735 -0.1237673
 [75,] -0.471888 -0.1460899
 [76,]  0.566914  0.0332077
 [77,] -0.227440 -0.4565952
 [78,] -0.794826  0.5969256
 [79,]  0.055104 -0.5450378
 [80,] -0.139004 -0.5154574
 [81,] -0.051311 -0.5457710
 [82,]  0.178758 -0.4925123
 [83,] -0.279506 -0.4086529
 [84,]  0.335827 -0.3457051
 [85,] -0.188468 -0.4860357
 [86,]  0.146327 -0.5116622
 [87,]  0.610118  0.1255732
 [88,]  0.209009 -0.4712059
 [89,] -0.252391 -0.4348493
 [90,]  0.641622  0.1972014
 [91,]  0.547474 -0.0061410
 [92,]  0.277642 -0.4105388
 [93,]  0.089918 -0.5358674
 [94,] -0.435453 -0.2061371
 [95,]  0.770046  0.5264922
 [96,] -0.418693 -0.2321387
 [97,]  1.271194  2.3845575
 [98,]  0.874290  0.8378377
 [99,] -0.197691 -0.4795668
[100,] -0.677040  0.2820327

> 
> # with analytical gradients as attribute
> mlGBFGSYC <- maxLik( llfGrad, start = startVal, method = "BFGSR" , print.level=1)
Initial value of the function : -326.589781090132 
Iteration  1 
step = 1, lnL = -325.1, chi2 = 1.5039, function increment = 1.494
Iteration  2 
step = 1, lnL = -254.9, chi2 = 107.75, function increment = 70.193
Iteration  3 
step = 1, lnL = -254.76, chi2 = 0.14697, function increment = 0.14642
Iteration  4 
step = 1, lnL = -249.98, chi2 = 18.759, function increment = 4.7779
Iteration  5 
step = 0.25, lnL = -218.8, chi2 = 1496.1, function increment = 31.178
Iteration  6 
step = 1, lnL = -201.74, chi2 = 22.409, function increment = 17.059
Iteration  7 
step = 0.25, lnL = -201.65, chi2 = 0.75772, function increment = 0.086956
Iteration  8 
step = 1, lnL = -201.6, chi2 = 0.078918, function increment = 0.053616
Iteration  9 
step = 0.25, lnL = -201.6, chi2 = 0.071851, function increment = 0.0040907
Iteration  10 
step = 0.125, lnL = -201.58, chi2 = 0.22304, function increment = 0.012766
Iteration  11 
step = 0.0625, lnL = -201.58, chi2 = 0.0027953, function increment = 6.3138e-05
Iteration  12 
step = 0.5, lnL = -201.58, chi2 = 0.00012507, function increment = 2.4558e-05
Iteration  13 
step = 0.0625, lnL = -201.58, chi2 = 6.6452e-05, function increment = 4.2386e-07
Iteration  14 
step = 0.03125, lnL = -201.58, chi2 = 1.7822e-05, function increment = 2.5402e-07
Iteration  15 
step = 0.015625, lnL = -201.58, chi2 = 5.203e-08, function increment = 2.6043e-10
--------------
successive function values within tolerance limit 
15  iterations
estimate: 1.181 1.8165 
Function value: -201.58 
> all.equal( mlGBFGSYC, mlgBFGSYC )
[1] TRUE
> mlGIndBFGSYC <- maxLik( llfGradInd, start = startVal, method = "BFGSR" )
> all.equal( mlGIndBFGSYC, mlgIndBFGSYC )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBFGSYC <- maxLik( llfGrad, gf, start = startVal, method = "BFGSR" )
Warning message:
In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBFGSYC, mlgBFGSYC )
[1] TRUE
> all.equal( mlgGBFGSYC, mlGBFGSYC )
[1] TRUE
> 
> # with analytical gradients and Hessians
> mlghBFGSYC <- maxLik( llf, gf, hf, start = startVal, method = "BFGSR" )
> all.equal( mlgBFGSYC, mlghBFGSYC )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGHBFGSYC <- maxLik( llfGradHess, start = startVal, method = "BFGSR" )
> all.equal( mlGHBFGSYC, mlghBFGSYC, tolerance = 1e-10 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBFGSYC <- maxLik( llfGradHess, gf, hf, start = startVal, method = "BFGSR" )
Warning messages:
1: In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBFGSYC, mlghBFGSYC )
[1] TRUE
> all.equal( mlgGhHBFGSYC, mlGHBFGSYC )
[1] TRUE
> 
> 
> ## BFGS method
> mlBFGS <- maxLik( llf, start = startVal, method = "BFGS" )
> print( mlBFGS )
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.1808 1.8165 
> summary( mlBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.2e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlBFGS )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBFGS )
[1] 407.17
> coef( mlBFGS )
    mu  sigma 
1.1808 1.8165 
> condiNumber( mlBFGS )
mu 	 1 
sigma 	 1.6715 
> hessian( mlBFGS )
              mu      sigma
mu    -30.269121   0.028422
sigma   0.028422 -60.623506
> logLik( mlBFGS )
[1] -201.58
> maximType( mlBFGS )
[1] "BFGS maximisation"
> nIter( mlBFGS )
function 
      36 
> nParam( mlBFGS )
[1] 2
> returnCode( mlBFGS )
[1] 0
> returnMessage( mlBFGS )
[1] "successful convergence "
> vcov( mlBFGS )
              mu      sigma
mu    3.3037e-02 1.5489e-05
sigma 1.5489e-05 1.6495e-02
> logLik( summary( mlBFGS ) )
[1] -201.58
> all.equal( ml, mlBFGS )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 2: Mean relative difference: 6.548e-07"  
[3] "Component 3: Mean relative difference: 41.721"     
[4] "Component 4: Mean relative difference: 0.0056127"  
[5] "Component 5: Mean relative difference: 1"          
[6] "Component 6: 1 string mismatch"                    
[7] "Component 9: names for current but not for target" 
[8] "Component 9: Mean relative difference: 4.1429"     
[9] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndBFGS <- maxLik( llfInd, start = startVal, method = "BFGS" )
> summary( mlIndBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlBFGS[], mlIndBFGS[-12] )
[1] "Component 3: Mean relative difference: 0.00063978"
[2] "Component 4: Mean relative difference: 0.00125"   
> mlIndBFGS[12]
$gradientObs
              mu      sigma
  [1,] -0.394521 -0.2677859
  [2,] -0.194316 -0.4819270
  [3,]  0.889987  0.8882788
  [4,] -0.012060 -0.5502507
  [5,]  0.023568 -0.5495059
  [6,]  0.984760  1.2110229
  [7,]  0.224579 -0.4588993
  [8,] -0.821593  0.6756383
  [9,] -0.471122 -0.1473360
 [10,] -0.324928 -0.3587338
 [11,]  0.687159  0.3072049
 [12,]  0.163297 -0.5020765
 [13,]  0.188123 -0.4862289
 [14,]  0.012291 -0.5502405
 [15,] -0.391711 -0.2717979
 [16,]  1.028310  1.3702707
 [17,]  0.246966 -0.4397236
 [18,] -1.246830  2.2733584
 [19,]  0.370317 -0.3014116
 [20,] -0.341372 -0.3388312
 [21,] -0.702041  0.3447592
 [22,] -0.186919 -0.4870490
 [23,] -0.676693  0.2812764
 [24,] -0.496603 -0.1025444
 [25,] -0.433655 -0.2089139
 [26,] -1.077159  1.5570949
 [27,]  0.453013 -0.1777353
 [28,]  0.038167 -0.5478688
 [29,] -0.744660  0.4567584
 [30,]  0.705181  0.3527860
 [31,]  0.203696 -0.4751450
 [32,] -0.233650 -0.4513487
 [33,]  0.487768 -0.1183424
 [34,]  0.477468 -0.1364009
 [35,]  0.443190 -0.1937264
 [36,]  0.362610 -0.3116729
 [37,]  0.280950 -0.4071345
 [38,] -0.092324 -0.5350316
 [39,] -0.240252 -0.4456659
 [40,] -0.285414 -0.4025424
 [41,] -0.475883 -0.1391467
 [42,] -0.180823 -0.4911213
 [43,] -0.821796  0.6762447
 [44,]  1.259879  2.3327755
 [45,]  0.677388  0.2829864
 [46,] -0.735551  0.4322659
 [47,] -0.299000 -0.3881201
 [48,] -0.337653 -0.3434187
 [49,]  0.417965 -0.2331849
 [50,] -0.105330 -0.5303619
 [51,]  0.098747 -0.5328024
 [52,] -0.072101 -0.5410718
 [53,] -0.080783 -0.5386607
 [54,]  0.774758  0.5398271
 [55,] -0.191645 -0.4837995
 [56,]  0.864386  0.8066918
 [57,] -0.993548  1.2426030
 [58,]  0.299556 -0.3875149
 [59,]  0.020275 -0.5497682
 [60,]  0.076092 -0.5399975
 [61,]  0.175314 -0.4946850
 [62,] -0.359273 -0.3160493
 [63,] -0.256766 -0.4307567
 [64,] -0.672190  0.2702431
 [65,] -0.704446  0.3509033
 [66,]  0.129181 -0.5202018
 [67,]  0.216877 -0.4650754
 [68,] -0.022670 -0.5495813
 [69,]  0.504219 -0.0886979
 [70,]  1.187827  2.0124178
 [71,] -0.352428 -0.3248979
 [72,] -1.454462  3.2921764
 [73,]  0.554814  0.0086316
 [74,] -0.484668 -0.1238182
 [75,] -0.471823 -0.1461361
 [76,]  0.566835  0.0331246
 [77,] -0.227408 -0.4565766
 [78,] -0.794715  0.5967244
 [79,]  0.055096 -0.5450007
 [80,] -0.138984 -0.5154265
 [81,] -0.051304 -0.5457337
 [82,]  0.178734 -0.4924861
 [83,] -0.279467 -0.4086444
 [84,]  0.335780 -0.3457094
 [85,] -0.188442 -0.4860110
 [86,]  0.146306 -0.5116320
 [87,]  0.610033  0.1254708
 [88,]  0.208980 -0.4711841
 [89,] -0.252356 -0.4348352
 [90,]  0.641533  0.1970841
 [91,]  0.547398 -0.0062160
 [92,]  0.277604 -0.4105296
 [93,]  0.089906 -0.5358322
 [94,] -0.435392 -0.2061708
 [95,]  0.769939  0.5263064
 [96,] -0.418635 -0.2321670
 [97,]  1.271018  2.3839847
 [98,]  0.874169  0.8375870
 [99,] -0.197663 -0.4795434
[100,] -0.676945  0.2818971

> nObs( mlIndBFGS )
[1] 100
> 
> # with analytical gradients
> mlgBFGS <- maxLik( llf, gf, start = startVal, method = "BFGS" )
> summary( mlgBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlBFGS, mlgBFGS )
[1] "Component 3: Mean relative difference: 0.00041338"
[2] "Component 4: Mean relative difference: 0.0011514" 
> all.equal( mlg, mlgBFGS )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 2: Mean relative difference: 6.4838e-07" 
[3] "Component 3: Mean absolute difference: 4.025e-05"  
[4] "Component 4: Mean relative difference: 2.4728e-06" 
[5] "Component 5: Mean relative difference: 1"          
[6] "Component 6: 1 string mismatch"                    
[7] "Component 9: names for current but not for target" 
[8] "Component 9: Mean relative difference: 4.1429"     
[9] "Component 10: 1 string mismatch"                   
> mlgIndBFGS <- maxLik( llfInd, gfInd, start = startVal, method = "BFGS" )
> all.equal( mlgBFGS[], mlgIndBFGS[-12] )
[1] TRUE
> mlgIndBFGS[12]
$gradientObs
              mu      sigma
  [1,] -0.394521 -0.2677859
  [2,] -0.194316 -0.4819270
  [3,]  0.889987  0.8882788
  [4,] -0.012060 -0.5502507
  [5,]  0.023568 -0.5495059
  [6,]  0.984760  1.2110229
  [7,]  0.224579 -0.4588993
  [8,] -0.821593  0.6756383
  [9,] -0.471122 -0.1473360
 [10,] -0.324928 -0.3587338
 [11,]  0.687159  0.3072049
 [12,]  0.163297 -0.5020765
 [13,]  0.188123 -0.4862289
 [14,]  0.012291 -0.5502405
 [15,] -0.391711 -0.2717979
 [16,]  1.028310  1.3702707
 [17,]  0.246966 -0.4397236
 [18,] -1.246830  2.2733584
 [19,]  0.370317 -0.3014116
 [20,] -0.341372 -0.3388312
 [21,] -0.702041  0.3447592
 [22,] -0.186919 -0.4870490
 [23,] -0.676693  0.2812764
 [24,] -0.496603 -0.1025444
 [25,] -0.433655 -0.2089139
 [26,] -1.077159  1.5570949
 [27,]  0.453013 -0.1777353
 [28,]  0.038167 -0.5478688
 [29,] -0.744660  0.4567584
 [30,]  0.705181  0.3527860
 [31,]  0.203696 -0.4751450
 [32,] -0.233650 -0.4513487
 [33,]  0.487768 -0.1183424
 [34,]  0.477468 -0.1364009
 [35,]  0.443190 -0.1937264
 [36,]  0.362610 -0.3116729
 [37,]  0.280950 -0.4071345
 [38,] -0.092324 -0.5350316
 [39,] -0.240252 -0.4456659
 [40,] -0.285414 -0.4025424
 [41,] -0.475883 -0.1391467
 [42,] -0.180823 -0.4911213
 [43,] -0.821796  0.6762447
 [44,]  1.259879  2.3327755
 [45,]  0.677388  0.2829864
 [46,] -0.735551  0.4322659
 [47,] -0.299000 -0.3881201
 [48,] -0.337653 -0.3434187
 [49,]  0.417965 -0.2331849
 [50,] -0.105330 -0.5303619
 [51,]  0.098747 -0.5328024
 [52,] -0.072101 -0.5410718
 [53,] -0.080783 -0.5386607
 [54,]  0.774758  0.5398271
 [55,] -0.191645 -0.4837995
 [56,]  0.864386  0.8066918
 [57,] -0.993548  1.2426030
 [58,]  0.299556 -0.3875149
 [59,]  0.020275 -0.5497682
 [60,]  0.076092 -0.5399975
 [61,]  0.175314 -0.4946850
 [62,] -0.359273 -0.3160493
 [63,] -0.256766 -0.4307567
 [64,] -0.672190  0.2702431
 [65,] -0.704446  0.3509033
 [66,]  0.129181 -0.5202018
 [67,]  0.216877 -0.4650754
 [68,] -0.022670 -0.5495813
 [69,]  0.504219 -0.0886979
 [70,]  1.187827  2.0124178
 [71,] -0.352428 -0.3248979
 [72,] -1.454462  3.2921764
 [73,]  0.554814  0.0086316
 [74,] -0.484668 -0.1238182
 [75,] -0.471823 -0.1461361
 [76,]  0.566835  0.0331246
 [77,] -0.227408 -0.4565766
 [78,] -0.794715  0.5967244
 [79,]  0.055096 -0.5450007
 [80,] -0.138984 -0.5154265
 [81,] -0.051304 -0.5457337
 [82,]  0.178734 -0.4924861
 [83,] -0.279467 -0.4086444
 [84,]  0.335780 -0.3457094
 [85,] -0.188442 -0.4860110
 [86,]  0.146306 -0.5116320
 [87,]  0.610033  0.1254708
 [88,]  0.208980 -0.4711841
 [89,] -0.252356 -0.4348352
 [90,]  0.641533  0.1970841
 [91,]  0.547398 -0.0062160
 [92,]  0.277604 -0.4105296
 [93,]  0.089906 -0.5358322
 [94,] -0.435392 -0.2061708
 [95,]  0.769939  0.5263064
 [96,] -0.418635 -0.2321670
 [97,]  1.271018  2.3839847
 [98,]  0.874169  0.8375870
 [99,] -0.197663 -0.4795434
[100,] -0.676945  0.2818971

> 
> # with analytical gradients as attribute
> mlGBFGS <- maxLik( llfGrad, start = startVal, method = "BFGS" )
> all.equal( mlGBFGS, mlgBFGS, tolerance = 1e-14 )
[1] TRUE
> mlGIndBFGS <- maxLik( llfGradInd, start = startVal, method = "BFGS" )
> all.equal( mlGIndBFGS, mlgIndBFGS, tolerance = 1e-14 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBFGS <- maxLik( llfGrad, gf, start = startVal, method = "BFGS" )
Warning message:
In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBFGS, mlgBFGS, tolerance = 1e-14 )
[1] TRUE
> all.equal( mlgGBFGS, mlGBFGS, tolerance = 1e-14 )
[1] TRUE
> 
> # with unused Hessian
> mlghBFGS <- maxLik( llf, gf, hf, start = startVal, method = "BFGS" )
> all.equal( mlgBFGS, mlghBFGS )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGHBFGS <- maxLik( llfGradHess, start = startVal, method = "BFGS" )
> all.equal( mlGHBFGS, mlghBFGS, tolerance = 1e-14 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBFGS <- maxLik( llfGradHess, gf, hf, start = startVal, method = "BFGS" )
Warning messages:
1: In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBFGS, mlghBFGS, tolerance = 1e-14 )
[1] TRUE
> all.equal( mlgGhHBFGS, mlGHBFGS, tolerance = 1e-14 )
[1] TRUE
> 
> 
> ## NM method
> mlNM <- maxLik( llf, start = startVal, method = "NM" )
> print( mlNM )
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.1806 1.8166 
> summary( mlNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.3e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlNM )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNM )
[1] 407.17
> coef( mlNM )
    mu  sigma 
1.1806 1.8166 
> condiNumber( mlNM )
mu 	 1 
sigma 	 1.6681 
> hessian( mlNM )
           mu   sigma
mu    -30.269   0.000
sigma   0.000 -60.595
> logLik( mlNM )
[1] -201.58
> maximType( mlNM )
[1] "Nelder-Mead maximisation"
> nIter( mlNM )
function 
      63 
> nParam( mlNM )
[1] 2
> returnCode( mlNM )
[1] 0
> returnMessage( mlNM )
[1] "successful convergence "
> vcov( mlNM )
            mu    sigma
mu    0.033037 0.000000
sigma 0.000000 0.016503
> logLik( summary( mlNM ) )
[1] -201.58
> all.equal( ml, mlNM )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 2: Mean relative difference: 0.00011984" 
[3] "Component 3: Mean relative difference: 8068.5"     
[4] "Component 4: Mean relative difference: 0.0015615"  
[5] "Component 5: Mean relative difference: 1"          
[6] "Component 6: 1 string mismatch"                    
[7] "Component 9: names for current but not for target" 
[8] "Component 9: Mean relative difference: 8"          
[9] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndNM <- maxLik( llfInd, start = startVal, method = "NM" )
> summary( mlIndNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.817      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlNM[], mlIndNM[-12] )
[1] "Component 3: Mean relative difference: 1.5236e-06"
[2] "Component 4: Mean relative difference: 0.0037559" 
> mlIndNM[12]
$gradientObs
              mu      sigma
  [1,] -0.394392 -0.2678992
  [2,] -0.194221 -0.4819409
  [3,]  0.889897  0.8881564
  [4,] -0.011997 -0.5502065
  [5,]  0.023625 -0.5494540
  [6,]  0.984654  1.2108392
  [7,]  0.224602 -0.4588258
  [8,] -0.821392  0.6751888
  [9,] -0.470980 -0.1474972
 [10,] -0.324811 -0.3588083
 [11,]  0.687103  0.3071858
 [12,]  0.163331 -0.5020055
 [13,]  0.188153 -0.4861565
 [14,]  0.012350 -0.5501909
 [15,] -0.391583 -0.2719095
 [16,]  1.028196  1.3700560
 [17,]  0.246985 -0.4396500
 [18,] -1.246556  2.2724058
 [19,]  0.370316 -0.3013459
 [20,] -0.341253 -0.3389145
 [21,] -0.701860  0.3444209
 [22,] -0.186826 -0.4870600
 [23,] -0.676516  0.2809600
 [24,] -0.496457 -0.1027227
 [25,] -0.433519 -0.2090509
 [26,] -1.076914  1.5563631
 [27,]  0.452997 -0.1776827
 [28,]  0.038222 -0.5478140
 [29,] -0.744472  0.4563820
 [30,]  0.705122  0.3527593
 [31,]  0.203723 -0.4750719
 [32,] -0.233549 -0.4513792
 [33,]  0.487746 -0.1182972
 [34,]  0.477448 -0.1363533
 [35,]  0.443176 -0.1936719
 [36,]  0.362610 -0.3116062
 [37,]  0.280964 -0.4070616
 [38,] -0.092247 -0.5350092
 [39,] -0.240150 -0.4456993
 [40,] -0.285304 -0.4025970
 [41,] -0.475740 -0.1393110
 [42,] -0.180731 -0.4911299
 [43,] -0.821595  0.6757950
 [44,]  1.259725  2.3323664
 [45,]  0.677334  0.2829713
 [46,] -0.735364  0.4318977
 [47,] -0.298887 -0.3881814
 [48,] -0.337534 -0.3435000
 [49,]  0.417955 -0.2331260
 [50,] -0.105251 -0.5303436
 [51,]  0.098792 -0.5327380
 [52,] -0.072027 -0.5410434
 [53,] -0.080708 -0.5386349
 [54,]  0.774687  0.5397681
 [55,] -0.191551 -0.4838124
 [56,]  0.864300  0.8065845
 [57,] -0.993318  1.2419702
 [58,]  0.299566 -0.3874429
 [59,]  0.020332 -0.5497170
 [60,]  0.076140 -0.5399364
 [61,]  0.175346 -0.4946133
 [62,] -0.359150 -0.3161424
 [63,] -0.256661 -0.4307977
 [64,] -0.672014  0.2699304
 [65,] -0.704265  0.3505628
 [66,]  0.129220 -0.5201339
 [67,]  0.216902 -0.4650020
 [68,] -0.022605 -0.5495397
 [69,]  0.504195 -0.0886566
 [70,]  1.187686  2.0120745
 [71,] -0.352307 -0.3249873
 [72,] -1.454152  3.2909172
 [73,]  0.554781  0.0086593
 [74,] -0.484524 -0.1239883
 [75,] -0.471681 -0.1462977
 [76,]  0.566800  0.0331487
 [77,] -0.227308 -0.4566044
 [78,] -0.794518  0.5963010
 [79,]  0.055148 -0.5449430
 [80,] -0.138899 -0.5154196
 [81,] -0.051234 -0.5456995
 [82,]  0.178765 -0.4924142
 [83,] -0.279358 -0.4086960
 [84,]  0.335785 -0.3456400
 [85,] -0.188348 -0.4860226
 [86,]  0.146343 -0.5115625
 [87,]  0.609990  0.1254810
 [88,]  0.209006 -0.4711109
 [89,] -0.252251 -0.4348741
 [90,]  0.641485  0.1970830
 [91,]  0.547366 -0.0061862
 [92,]  0.277618 -0.4104566
 [93,]  0.089952 -0.5357690
 [94,] -0.435257 -0.2063089
 [95,]  0.769869  0.5262497
 [96,] -0.418502 -0.2322948
 [97,]  1.270862  2.3835651
 [98,]  0.874081  0.8374740
 [99,] -0.197568 -0.4795587
[100,] -0.676769  0.2815804

> nObs( mlIndNM )
[1] 100
> 
> # with unused analytical gradients
> mlgNM <- maxLik( llf, gf, start = startVal, method = "NM" )
> summary( mlgNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlNM, mlgNM )
[1] "Component 3: Mean relative difference: 1.7481e-06"
[2] "Component 4: Mean relative difference: 0.00059006"
> # with individual log likelihood values and gradients
> mlgIndNM <- maxLik( llfInd, gfInd, start = startVal, method = "NM" )
> summary( mlgIndNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlgNM[], mlgIndNM[-12] )
[1] TRUE
> mlgIndNM[12]
$gradientObs
              mu      sigma
  [1,] -0.394392 -0.2678992
  [2,] -0.194221 -0.4819409
  [3,]  0.889897  0.8881564
  [4,] -0.011997 -0.5502065
  [5,]  0.023625 -0.5494540
  [6,]  0.984654  1.2108392
  [7,]  0.224602 -0.4588258
  [8,] -0.821392  0.6751888
  [9,] -0.470980 -0.1474972
 [10,] -0.324811 -0.3588083
 [11,]  0.687103  0.3071858
 [12,]  0.163331 -0.5020055
 [13,]  0.188153 -0.4861565
 [14,]  0.012350 -0.5501909
 [15,] -0.391583 -0.2719095
 [16,]  1.028196  1.3700560
 [17,]  0.246985 -0.4396500
 [18,] -1.246556  2.2724058
 [19,]  0.370316 -0.3013459
 [20,] -0.341253 -0.3389145
 [21,] -0.701860  0.3444209
 [22,] -0.186826 -0.4870600
 [23,] -0.676516  0.2809600
 [24,] -0.496457 -0.1027227
 [25,] -0.433519 -0.2090509
 [26,] -1.076914  1.5563631
 [27,]  0.452997 -0.1776827
 [28,]  0.038222 -0.5478140
 [29,] -0.744472  0.4563820
 [30,]  0.705122  0.3527593
 [31,]  0.203723 -0.4750719
 [32,] -0.233549 -0.4513792
 [33,]  0.487746 -0.1182972
 [34,]  0.477448 -0.1363533
 [35,]  0.443176 -0.1936719
 [36,]  0.362610 -0.3116062
 [37,]  0.280964 -0.4070616
 [38,] -0.092247 -0.5350092
 [39,] -0.240150 -0.4456993
 [40,] -0.285304 -0.4025970
 [41,] -0.475740 -0.1393110
 [42,] -0.180731 -0.4911299
 [43,] -0.821595  0.6757950
 [44,]  1.259725  2.3323664
 [45,]  0.677334  0.2829713
 [46,] -0.735364  0.4318977
 [47,] -0.298887 -0.3881814
 [48,] -0.337534 -0.3435000
 [49,]  0.417955 -0.2331260
 [50,] -0.105251 -0.5303436
 [51,]  0.098792 -0.5327380
 [52,] -0.072027 -0.5410434
 [53,] -0.080708 -0.5386349
 [54,]  0.774687  0.5397681
 [55,] -0.191551 -0.4838124
 [56,]  0.864300  0.8065845
 [57,] -0.993318  1.2419702
 [58,]  0.299566 -0.3874429
 [59,]  0.020332 -0.5497170
 [60,]  0.076140 -0.5399364
 [61,]  0.175346 -0.4946133
 [62,] -0.359150 -0.3161424
 [63,] -0.256661 -0.4307977
 [64,] -0.672014  0.2699304
 [65,] -0.704265  0.3505628
 [66,]  0.129220 -0.5201339
 [67,]  0.216902 -0.4650020
 [68,] -0.022605 -0.5495397
 [69,]  0.504195 -0.0886566
 [70,]  1.187686  2.0120745
 [71,] -0.352307 -0.3249873
 [72,] -1.454153  3.2909172
 [73,]  0.554781  0.0086593
 [74,] -0.484524 -0.1239883
 [75,] -0.471681 -0.1462977
 [76,]  0.566800  0.0331487
 [77,] -0.227308 -0.4566044
 [78,] -0.794518  0.5963010
 [79,]  0.055148 -0.5449430
 [80,] -0.138899 -0.5154196
 [81,] -0.051234 -0.5456995
 [82,]  0.178765 -0.4924142
 [83,] -0.279358 -0.4086960
 [84,]  0.335785 -0.3456400
 [85,] -0.188348 -0.4860226
 [86,]  0.146343 -0.5115625
 [87,]  0.609990  0.1254810
 [88,]  0.209006 -0.4711109
 [89,] -0.252251 -0.4348741
 [90,]  0.641485  0.1970830
 [91,]  0.547366 -0.0061862
 [92,]  0.277618 -0.4104566
 [93,]  0.089952 -0.5357690
 [94,] -0.435257 -0.2063089
 [95,]  0.769869  0.5262497
 [96,] -0.418502 -0.2322948
 [97,]  1.270862  2.3835651
 [98,]  0.874081  0.8374740
 [99,] -0.197568 -0.4795587
[100,] -0.676769  0.2815804

> 
> # with (unused) analytical gradients as attribute
> mlGNM <- maxLik( llfGrad, start = startVal, method = "NM" )
> all.equal( mlGNM, mlgNM, tolerance = 1e-14 )
[1] TRUE
> mlGIndNM <- maxLik( llfGradInd, start = startVal, method = "NM" )
> all.equal( mlGIndNM, mlgIndNM, tolerance = 1e-14 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGNM <- maxLik( llfGrad, gf, start = startVal, method = "NM" )
Warning message:
In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "Nelder-Mead",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGNM, mlgNM, tolerance = 1e-14 )
[1] TRUE
> all.equal( mlgGNM, mlGNM, tolerance = 1e-14 )
[1] TRUE
> 
> # with unused analytical gradients and Hessian
> mlghNM <- maxLik( llf, gf, hf, start = startVal, method = "NM" )
> all.equal( mlgNM, mlghNM )
[1] TRUE
> 
> 
> ## SANN method
> mlSANN <- maxLik( llf, start = startVal, method = "SANN" )
> print( mlSANN )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 (2 free parameter(s))
Estimate(s): 1.1818 1.8165 
> summary( mlSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182     6.5 7.9e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlSANN )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSANN )
[1] 407.17
> coef( mlSANN )
    mu  sigma 
1.1818 1.8165 
> condiNumber( mlSANN )
mu 	 1 
sigma 	 1.6735 
> hessian( mlSANN )
              mu      sigma
mu    -30.269121   0.056843
sigma   0.056843 -60.595085
> logLik( mlSANN )
[1] -201.58
> maximType( mlSANN )
[1] "SANN maximisation"
> nIter( mlSANN )
function 
   10000 
> nParam( mlSANN )
[1] 2
> returnCode( mlSANN )
[1] 0
> returnMessage( mlSANN )
[1] "successful convergence "
> vcov( mlSANN )
              mu      sigma
mu    3.3037e-02 3.0992e-05
sigma 3.0992e-05 1.6503e-02
> logLik( summary( mlSANN ) )
[1] -201.58
> all.equal( ml, mlSANN )
 [1] "Length mismatch: comparison on first 10 components"
 [2] "Component 1: Mean relative difference: 7.0286e-08" 
 [3] "Component 2: Mean relative difference: 0.0003349"  
 [4] "Component 3: Mean relative difference: 16334"      
 [5] "Component 4: Mean relative difference: 0.0028107"  
 [6] "Component 5: Mean relative difference: 1"          
 [7] "Component 6: 1 string mismatch"                    
 [8] "Component 9: names for current but not for target" 
 [9] "Component 9: Mean relative difference: 1427.6"     
[10] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndSANN <- maxLik( llfInd, start = startVal, method = "SANN" )
> summary( mlIndSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.6e-11 ***
sigma    1.817      0.128   14.15 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlSANN[], mlIndSANN[-12] )
[1] "Component 3: Mean relative difference: 1.0972e-06"
[2] "Component 4: Mean relative difference: 0.0024992" 
> mlIndSANN[12]
$gradientObs
              mu      sigma
  [1,] -0.394797 -0.2673721
  [2,] -0.194601 -0.4817128
  [3,]  0.889657  0.8872537
  [4,] -0.012353 -0.5502263
  [5,]  0.023274 -0.5495195
  [6,]  0.984426  1.2098768
  [7,]  0.224277 -0.4591325
  [8,] -0.821852  0.6764480
  [9,] -0.471395 -0.1468482
 [10,] -0.325208 -0.3583883
 [11,]  0.686838  0.3064318
 [12,]  0.162998 -0.5022417
 [13,]  0.187822 -0.4864216
 [14,]  0.011997 -0.5502420
 [15,] -0.391988 -0.2713867
 [16,]  1.027974  1.3690683
 [17,]  0.246663 -0.4399818
 [18,] -1.247071  2.2745212
 [19,]  0.370009 -0.3018097
 [20,] -0.341651 -0.3384695
 [21,] -0.702305  0.3454622
 [22,] -0.187205 -0.4868424
 [23,] -0.676958  0.2819564
 [24,] -0.496875 -0.1020322
 [25,] -0.433930 -0.2084620
 [26,] -1.077407  1.5581217
 [27,]  0.452701 -0.1782290
 [28,]  0.037872 -0.5478980
 [29,] -0.744922  0.4574999
 [30,]  0.704859  0.3519909
 [31,]  0.203395 -0.4753549
 [32,] -0.233934 -0.4510946
 [33,]  0.487455 -0.1188768
 [34,]  0.477155 -0.1369232
 [35,]  0.442879 -0.1942088
 [36,]  0.362302 -0.3120621
 [37,]  0.280646 -0.4074308
 [38,] -0.092614 -0.5349227
 [39,] -0.240535 -0.4454051
 [40,] -0.285695 -0.4022363
 [41,] -0.476156 -0.1386543
 [42,] -0.181109 -0.4909210
 [43,] -0.822055  0.6770546
 [44,]  1.259533  2.3312667
 [45,]  0.677067  0.2822252
 [46,] -0.735814  0.4329991
 [47,] -0.299280 -0.3878004
 [48,] -0.337932 -0.3430606
 [49,]  0.417655 -0.2336379
 [50,] -0.105619 -0.5302395
 [51,]  0.098450 -0.5328970
 [52,] -0.072391 -0.5409841
 [53,] -0.081072 -0.5385639
 [54,]  0.774433  0.5389462
 [55,] -0.191930 -0.4835881
 [56,]  0.864057  0.8056989
 [57,] -0.993800  1.2435604
 [58,]  0.299251 -0.3878323
 [59,]  0.019981 -0.5497782
 [60,]  0.075796 -0.5400676
 [61,]  0.175014 -0.4948635
 [62,] -0.359551 -0.3156699
 [63,] -0.257048 -0.4304793
 [64,] -0.672455  0.2709190
 [65,] -0.704710  0.3516085
 [66,]  0.128883 -0.5203296
 [67,]  0.216575 -0.4652999
 [68,] -0.022962 -0.5495457
 [69,]  0.503905 -0.0892517
 [70,]  1.187485  2.0110057
 [71,] -0.352706 -0.3245253
 [72,] -1.454694  3.2934968
 [73,]  0.554498  0.0080179
 [74,] -0.484941 -0.1233173
 [75,] -0.472096 -0.1456476
 [76,]  0.566519  0.0324966
 [77,] -0.227692 -0.4563288
 [78,] -0.794975  0.5975104
 [79,]  0.054801 -0.5450481
 [80,] -0.139272 -0.5152692
 [81,] -0.051595 -0.5456679
 [82,]  0.178433 -0.4926684
 [83,] -0.279748 -0.4083442
 [84,]  0.335473 -0.3460679
 [85,] -0.188727 -0.4858029
 [86,]  0.146007 -0.5117786
 [87,]  0.609715  0.1247911
 [88,]  0.208679 -0.4713999
 [89,] -0.252638 -0.4345623
 [90,]  0.641213  0.1963664
 [91,]  0.547082 -0.0068209
 [92,]  0.277299 -0.4108222
 [93,]  0.089609 -0.5359172
 [94,] -0.435667 -0.2057173
 [95,]  0.769614  0.5254315
 [96,] -0.418911 -0.2317297
 [97,]  1.270672  2.3824610
 [98,]  0.873839  0.8365818
 [99,] -0.197948 -0.4793259
[100,] -0.677210  0.2825774

> nObs( mlIndSANN )
[1] 100
> 
> # with unused analytical gradients
> mlgSANN <- maxLik( llf, gf, start = startVal, method = "SANN" )
> summary( mlgSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.7e-11 ***
sigma    1.817      0.128   14.14 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlSANN, mlgSANN )
[1] "Component 3: Mean relative difference: 1.0721e-06"
[2] "Component 4: Mean relative difference: 0.0010711" 
> # with individual log likelihood values and gradients
> mlgIndSANN <- maxLik( llfInd, gfInd, start = startVal, method = "SANN" )
> summary( mlgIndSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.58 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.7e-11 ***
sigma    1.817      0.128   14.14 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlgSANN[], mlgIndSANN[-12] )
[1] TRUE
> mlgIndSANN[12]
$gradientObs
              mu      sigma
  [1,] -0.394797 -0.2673721
  [2,] -0.194601 -0.4817128
  [3,]  0.889657  0.8872537
  [4,] -0.012353 -0.5502263
  [5,]  0.023274 -0.5495195
  [6,]  0.984426  1.2098768
  [7,]  0.224277 -0.4591325
  [8,] -0.821852  0.6764480
  [9,] -0.471395 -0.1468482
 [10,] -0.325208 -0.3583883
 [11,]  0.686838  0.3064318
 [12,]  0.162998 -0.5022417
 [13,]  0.187822 -0.4864216
 [14,]  0.011997 -0.5502420
 [15,] -0.391988 -0.2713867
 [16,]  1.027974  1.3690683
 [17,]  0.246663 -0.4399818
 [18,] -1.247071  2.2745212
 [19,]  0.370009 -0.3018097
 [20,] -0.341651 -0.3384695
 [21,] -0.702305  0.3454622
 [22,] -0.187205 -0.4868424
 [23,] -0.676958  0.2819564
 [24,] -0.496875 -0.1020322
 [25,] -0.433930 -0.2084620
 [26,] -1.077407  1.5581217
 [27,]  0.452701 -0.1782290
 [28,]  0.037872 -0.5478980
 [29,] -0.744922  0.4574999
 [30,]  0.704859  0.3519909
 [31,]  0.203395 -0.4753549
 [32,] -0.233934 -0.4510946
 [33,]  0.487455 -0.1188768
 [34,]  0.477155 -0.1369232
 [35,]  0.442879 -0.1942088
 [36,]  0.362302 -0.3120621
 [37,]  0.280646 -0.4074308
 [38,] -0.092614 -0.5349227
 [39,] -0.240535 -0.4454051
 [40,] -0.285695 -0.4022363
 [41,] -0.476156 -0.1386543
 [42,] -0.181109 -0.4909210
 [43,] -0.822055  0.6770546
 [44,]  1.259533  2.3312667
 [45,]  0.677067  0.2822252
 [46,] -0.735814  0.4329991
 [47,] -0.299280 -0.3878004
 [48,] -0.337932 -0.3430606
 [49,]  0.417655 -0.2336379
 [50,] -0.105619 -0.5302395
 [51,]  0.098450 -0.5328970
 [52,] -0.072391 -0.5409841
 [53,] -0.081072 -0.5385639
 [54,]  0.774433  0.5389462
 [55,] -0.191930 -0.4835881
 [56,]  0.864057  0.8056989
 [57,] -0.993800  1.2435604
 [58,]  0.299251 -0.3878323
 [59,]  0.019981 -0.5497782
 [60,]  0.075796 -0.5400676
 [61,]  0.175014 -0.4948635
 [62,] -0.359551 -0.3156699
 [63,] -0.257048 -0.4304793
 [64,] -0.672455  0.2709190
 [65,] -0.704710  0.3516085
 [66,]  0.128883 -0.5203296
 [67,]  0.216575 -0.4652999
 [68,] -0.022962 -0.5495457
 [69,]  0.503905 -0.0892517
 [70,]  1.187485  2.0110057
 [71,] -0.352706 -0.3245253
 [72,] -1.454694  3.2934968
 [73,]  0.554498  0.0080179
 [74,] -0.484941 -0.1233173
 [75,] -0.472096 -0.1456476
 [76,]  0.566519  0.0324966
 [77,] -0.227692 -0.4563288
 [78,] -0.794975  0.5975104
 [79,]  0.054801 -0.5450481
 [80,] -0.139272 -0.5152692
 [81,] -0.051595 -0.5456679
 [82,]  0.178433 -0.4926684
 [83,] -0.279748 -0.4083442
 [84,]  0.335473 -0.3460679
 [85,] -0.188727 -0.4858029
 [86,]  0.146007 -0.5117786
 [87,]  0.609715  0.1247911
 [88,]  0.208679 -0.4713999
 [89,] -0.252638 -0.4345623
 [90,]  0.641213  0.1963664
 [91,]  0.547082 -0.0068209
 [92,]  0.277299 -0.4108222
 [93,]  0.089609 -0.5359172
 [94,] -0.435667 -0.2057173
 [95,]  0.769614  0.5254315
 [96,] -0.418911 -0.2317297
 [97,]  1.270672  2.3824610
 [98,]  0.873839  0.8365818
 [99,] -0.197948 -0.4793259
[100,] -0.677210  0.2825774

> 
> # with unused analytical gradients and Hessian
> mlghSANN <- maxLik( llf, gf, hf, start = startVal, method = "SANN" )
> all.equal( mlgSANN, mlghSANN )
[1] TRUE
> 
> # with a user-specified function to generate a new candidate point
> mlSANNCand <- maxLik( llf, start = startVal, method = "SANN",
+    cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
> summary( mlSANNCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.59 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.200      0.181    6.62 3.5e-11 ***
sigma    1.813      0.128   14.18 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlSANNCand, mlSANN )
[1] "Component 1: Mean relative difference: 3.0992e-05"
[2] "Component 2: Mean relative difference: 0.0074753" 
[3] "Component 3: Mean relative difference: 0.96794"   
[4] "Component 4: Mean relative difference: 0.0214"    
> 
> ############### with fixed parameters ###############
> # start values
> startValFix <- c( mu = 1, sigma = 1 )
> 
> # fix mu (the mean ) at its start value
> isFixed <- c( TRUE, FALSE )
> 
> ## NR method with fixed parameters
> mlFix <- maxLik( llf, start = startValFix, activePar = !isFixed )
> mlFix1 <- maxLik( llf, start = startValFix, activePar = 2 )
> all.equal( mlFix, mlFix1 )
[1] TRUE
> mlFix2 <- maxLik( llf, start = startValFix, fixed = isFixed )
> all.equal( mlFix, mlFix2 )
[1] TRUE
> mlFix3 <- maxLik( llf, start = startValFix, fixed = "mu" )
> all.equal( mlFix, mlFix3 )
[1] TRUE
> mlFix4 <- maxLik( llf, start = startValFix, fixed = 1 )
> all.equal( mlFix, mlFix4 )
[1] TRUE
> print( mlFix )
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.08 (1 free parameter(s))
Estimate(s): 1 1.8255 
> summary( mlFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlFix )
   mu sigma 
FALSE  TRUE 
> AIC( mlFix )
[1] 406.15
> coef( mlFix )
    mu  sigma 
1.0000 1.8255 
> condiNumber( mlFix )
sigma 	 1 
> hessian( mlFix )
      mu  sigma
mu    NA     NA
sigma NA -59.97
> logLik( mlFix )
[1] -202.08
> maximType( mlFix )
[1] "Newton-Raphson maximisation"
> nIter( mlFix )
[1] 7
> nParam( mlFix )
[1] 2
> returnCode( mlFix )
[1] 1
> returnMessage( mlFix )
[1] "gradient close to zero"
> vcov( mlFix )
      mu    sigma
mu     0 0.000000
sigma  0 0.016675
> logLik( summary( mlFix ) )
[1] -202.08
> mlIndFix <- maxLik( llfInd, start = startValFix, activePar = !isFixed )
> mlIndFix1 <- maxLik( llfInd, start = startValFix, activePar = 2 )
> all.equal( mlIndFix, mlIndFix1 )
[1] TRUE
> mlIndFix2 <- maxLik( llfInd, start = startValFix, fixed = isFixed )
> all.equal( mlIndFix, mlIndFix2 )
[1] TRUE
> mlIndFix3 <- maxLik( llfInd, start = startValFix, fixed = "mu" )
> all.equal( mlIndFix, mlIndFix3 )
[1] TRUE
> mlIndFix4 <- maxLik( llfInd, start = startValFix, fixed = 1 )
> all.equal( mlIndFix, mlIndFix4 )
[1] TRUE
> summary( mlIndFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFix[ ], mlIndFix[ -11 ] )
[1] "Component 3: Mean relative difference: 0.13281"   
[2] "Component 4: Mean relative difference: 0.00047393"
> mlFix[[3]]
        mu      sigma 
        NA 2.8422e-08 
> mlIndFix[[3]]
        mu      sigma 
        NA 2.4647e-08 
> mlIndFix[ 11 ]
$gradientObs
       mu     sigma
  [1,] NA -0.341242
  [2,] NA -0.512969
  [3,] NA  1.049816
  [4,] NA -0.544539
  [5,] NA -0.536816
  [6,] NA  1.386413
  [7,] NA -0.408110
  [8,] NA  0.504561
  [9,] NA -0.237586
 [10,] NA -0.417204
 [11,] NA  0.437486
 [12,] NA -0.462674
 [13,] NA -0.442190
 [14,] NA -0.539752
 [15,] NA -0.344644
 [16,] NA  1.551865
 [17,] NA -0.384825
 [18,] NA  1.995415
 [19,] NA -0.224347
 [20,] NA -0.400819
 [21,] NA  0.201990
 [22,] NA -0.516565
 [23,] NA  0.144411
 [24,] NA -0.198450
 [25,] NA -0.290911
 [26,] NA  1.322948
 [27,] NA -0.086265
 [28,] NA -0.532340
 [29,] NA  0.303985
 [30,] NA  0.485933
 [31,] NA -0.428214
 [32,] NA -0.490555
 [33,] NA -0.020927
 [34,] NA -0.040740
 [35,] NA -0.103948
 [36,] NA -0.235969
 [37,] NA -0.346048
 [38,] NA -0.545287
 [39,] NA -0.486250
 [40,] NA -0.452619
 [41,] NA -0.230451
 [42,] NA -0.519381
 [43,] NA  0.505118
 [44,] NA  2.545665
 [45,] NA  0.411706
 [46,] NA  0.281639
 [47,] NA -0.441073
 [48,] NA -0.404610
 [49,] NA -0.147775
 [50,] NA -0.543237
 [51,] NA -0.505611
 [52,] NA -0.547272
 [53,] NA -0.546599
 [54,] NA  0.683876
 [55,] NA -0.514290
 [56,] NA  0.964405
 [57,] NA  1.029473
 [58,] NA -0.323067
 [59,] NA -0.537721
 [60,] NA -0.517145
 [61,] NA -0.453034
 [62,] NA -0.381883
 [63,] NA -0.474799
 [64,] NA  0.134423
 [65,] NA  0.207572
 [66,] NA -0.487226
 [67,] NA -0.415706
 [68,] NA -0.545960
 [69,] NA  0.011510
 [70,] NA  2.215877
 [71,] NA -0.389259
 [72,] NA  2.958550
 [73,] NA  0.117335
 [74,] NA -0.217071
 [75,] NA -0.236541
 [76,] NA  0.143827
 [77,] NA -0.494481
 [78,] NA  0.432078
 [79,] NA -0.526193
 [80,] NA -0.535123
 [81,] NA -0.547786
 [82,] NA -0.450197
 [83,] NA -0.457465
 [84,] NA -0.274769
 [85,] NA -0.515840
 [86,] NA -0.475423
 [87,] NA  0.243291
 [88,] NA -0.423275
 [89,] NA -0.477953
 [90,] NA  0.320032
 [91,] NA  0.101251
 [92,] NA -0.350050
 [93,] NA -0.510331
 [94,] NA -0.288549
 [95,] NA  0.669609
 [96,] NA -0.310876
 [97,] NA  2.598308
 [98,] NA  0.996765
 [99,] NA -0.511277
[100,] NA  0.144973

> nObs( mlIndFix )
[1] 100
> 
> # with analytical gradients
> mlgFix <- maxLik( llf, gf, start = startValFix, activePar = !isFixed )
> mlgFix1 <- maxLik( llf, gf, start = startValFix, activePar = 2 )
> all.equal( mlgFix, mlgFix1 )
[1] TRUE
> mlgFix2 <- maxLik( llf, gf, start = startValFix, fixed = isFixed )
> all.equal( mlgFix, mlgFix2 )
[1] TRUE
> summary( mlgFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFix, mlgFix )
[1] "Component 3: Mean relative difference: 0.99998"   
[2] "Component 4: Mean relative difference: 0.00081525"
> mlFix[[3]]
        mu      sigma 
        NA 2.8422e-08 
> mlgFix[[3]]
        mu      sigma 
        NA 5.4712e-13 
> mlFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -59.97
> mlgFix[[4]]
      mu   sigma
mu    NA      NA
sigma NA -60.019
> mlgIndFix <- maxLik( llfInd, gfInd, start = startValFix, activePar = !isFixed )
> all.equal( mlIndFix, mlgIndFix )
[1] "Component 3: Mean relative difference: 0.99998"   
[2] "Component 4: Mean relative difference: 0.00034115"
> mlIndFix[[3]]
        mu      sigma 
        NA 2.4647e-08 
> mlgIndFix[[3]]
        mu      sigma 
        NA 5.4839e-13 
> mlIndFix[[4]]
      mu   sigma
mu    NA      NA
sigma NA -59.998
> mlgIndFix[[4]]
      mu   sigma
mu    NA      NA
sigma NA -60.019
> all.equal( mlgFix[ ], mlgIndFix[ -11 ] )
[1] TRUE
> mlgIndFix[ 11 ]
$gradientObs
       mu     sigma
  [1,] NA -0.341242
  [2,] NA -0.512969
  [3,] NA  1.049816
  [4,] NA -0.544539
  [5,] NA -0.536816
  [6,] NA  1.386413
  [7,] NA -0.408110
  [8,] NA  0.504561
  [9,] NA -0.237586
 [10,] NA -0.417204
 [11,] NA  0.437486
 [12,] NA -0.462674
 [13,] NA -0.442190
 [14,] NA -0.539752
 [15,] NA -0.344644
 [16,] NA  1.551865
 [17,] NA -0.384825
 [18,] NA  1.995415
 [19,] NA -0.224347
 [20,] NA -0.400819
 [21,] NA  0.201990
 [22,] NA -0.516565
 [23,] NA  0.144411
 [24,] NA -0.198450
 [25,] NA -0.290911
 [26,] NA  1.322948
 [27,] NA -0.086265
 [28,] NA -0.532340
 [29,] NA  0.303985
 [30,] NA  0.485933
 [31,] NA -0.428214
 [32,] NA -0.490555
 [33,] NA -0.020927
 [34,] NA -0.040740
 [35,] NA -0.103948
 [36,] NA -0.235969
 [37,] NA -0.346048
 [38,] NA -0.545287
 [39,] NA -0.486250
 [40,] NA -0.452619
 [41,] NA -0.230451
 [42,] NA -0.519381
 [43,] NA  0.505118
 [44,] NA  2.545665
 [45,] NA  0.411706
 [46,] NA  0.281639
 [47,] NA -0.441073
 [48,] NA -0.404610
 [49,] NA -0.147775
 [50,] NA -0.543237
 [51,] NA -0.505611
 [52,] NA -0.547272
 [53,] NA -0.546599
 [54,] NA  0.683876
 [55,] NA -0.514290
 [56,] NA  0.964405
 [57,] NA  1.029473
 [58,] NA -0.323067
 [59,] NA -0.537721
 [60,] NA -0.517145
 [61,] NA -0.453034
 [62,] NA -0.381883
 [63,] NA -0.474799
 [64,] NA  0.134423
 [65,] NA  0.207572
 [66,] NA -0.487226
 [67,] NA -0.415706
 [68,] NA -0.545960
 [69,] NA  0.011510
 [70,] NA  2.215877
 [71,] NA -0.389259
 [72,] NA  2.958550
 [73,] NA  0.117335
 [74,] NA -0.217071
 [75,] NA -0.236541
 [76,] NA  0.143827
 [77,] NA -0.494481
 [78,] NA  0.432078
 [79,] NA -0.526193
 [80,] NA -0.535123
 [81,] NA -0.547786
 [82,] NA -0.450197
 [83,] NA -0.457465
 [84,] NA -0.274769
 [85,] NA -0.515840
 [86,] NA -0.475423
 [87,] NA  0.243291
 [88,] NA -0.423275
 [89,] NA -0.477953
 [90,] NA  0.320032
 [91,] NA  0.101251
 [92,] NA -0.350050
 [93,] NA -0.510331
 [94,] NA -0.288549
 [95,] NA  0.669609
 [96,] NA -0.310876
 [97,] NA  2.598308
 [98,] NA  0.996765
 [99,] NA -0.511277
[100,] NA  0.144973

> 
> # with analytical gradients and Hessians
> mlghFix <- maxLik( llf, gf, hf, start = startValFix, activePar = !isFixed )
> all.equal( mlgFix, mlghFix )
[1] TRUE
> mlgFix[[4]]
      mu   sigma
mu    NA      NA
sigma NA -60.019
> mlghFix[[4]]
      mu   sigma
mu    NA      NA
sigma NA -60.019
> 
> ## BHHH method with fixed parameters
> mlFixBHHH <- maxLik( llfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> mlFixBHHH1 <- maxLik( llfInd, start = startValFix, activePar = 2,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH1 )
[1] TRUE
> mlFixBHHH2 <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH2 )
[1] TRUE
> mlFixBHHH3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH3 )
[1] TRUE
> mlFixBHHH4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH4 )
[1] TRUE
> print( mlFixBHHH )
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.08 (1 free parameter(s))
Estimate(s): 1 1.8255 
> summary( mlFixBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.134    13.7  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlFixBHHH )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixBHHH )
[1] 406.15
> coef( mlFixBHHH )
    mu  sigma 
1.0000 1.8255 
> condiNumber( mlFixBHHH )
sigma 	 1 
> hessian( mlFixBHHH )
      mu   sigma
mu    NA      NA
sigma NA -55.983
attr(,"type")
[1] "BHHH"
> logLik( mlFixBHHH )
[1] -202.08
> maximType( mlFixBHHH )
[1] "BHHH maximisation"
> nIter( mlFixBHHH )
[1] 10
> nParam( mlFixBHHH )
[1] 2
> returnCode( mlFixBHHH )
[1] 2
> returnMessage( mlFixBHHH )
[1] "successive function values within tolerance limit"
> vcov( mlFixBHHH )
      mu    sigma
mu     0 0.000000
sigma  0 0.017863
> logLik( summary( mlFixBHHH ) )
[1] -202.08
> all.equal( mlFix[ -c( 5, 6, 9, 10 ) ], mlFixBHHH[ -c( 5, 6, 9, 10, 11 ) ] )
[1] "Component 2: Mean relative difference: 7.6899e-08"                             
[2] "Component 3: Mean relative difference: 298.54"                                 
[3] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[4] "Component 4: Mean relative difference: 0.066481"                               
> mlFix[[ 3 ]]
        mu      sigma 
        NA 2.8422e-08 
> mlFixBHHH[[ 3 ]]
         mu       sigma 
         NA -8.4566e-06 
> mlFix[[ 4 ]]
      mu  sigma
mu    NA     NA
sigma NA -59.97
> mlFixBHHH[[ 4 ]]
      mu   sigma
mu    NA      NA
sigma NA -55.983
attr(,"type")
[1] "BHHH"
> mlFixBHHH[ 11 ]
$gradientObs
       mu     sigma
  [1,] NA -0.341242
  [2,] NA -0.512968
  [3,] NA  1.049816
  [4,] NA -0.544539
  [5,] NA -0.536816
  [6,] NA  1.386412
  [7,] NA -0.408110
  [8,] NA  0.504561
  [9,] NA -0.237586
 [10,] NA -0.417204
 [11,] NA  0.437486
 [12,] NA -0.462674
 [13,] NA -0.442190
 [14,] NA -0.539752
 [15,] NA -0.344644
 [16,] NA  1.551865
 [17,] NA -0.384825
 [18,] NA  1.995415
 [19,] NA -0.224347
 [20,] NA -0.400819
 [21,] NA  0.201989
 [22,] NA -0.516564
 [23,] NA  0.144411
 [24,] NA -0.198450
 [25,] NA -0.290911
 [26,] NA  1.322947
 [27,] NA -0.086265
 [28,] NA -0.532340
 [29,] NA  0.303985
 [30,] NA  0.485933
 [31,] NA -0.428214
 [32,] NA -0.490555
 [33,] NA -0.020927
 [34,] NA -0.040740
 [35,] NA -0.103948
 [36,] NA -0.235969
 [37,] NA -0.346048
 [38,] NA -0.545287
 [39,] NA -0.486250
 [40,] NA -0.452619
 [41,] NA -0.230451
 [42,] NA -0.519381
 [43,] NA  0.505118
 [44,] NA  2.545664
 [45,] NA  0.411706
 [46,] NA  0.281638
 [47,] NA -0.441073
 [48,] NA -0.404610
 [49,] NA -0.147776
 [50,] NA -0.543237
 [51,] NA -0.505611
 [52,] NA -0.547272
 [53,] NA -0.546599
 [54,] NA  0.683876
 [55,] NA -0.514290
 [56,] NA  0.964404
 [57,] NA  1.029473
 [58,] NA -0.323067
 [59,] NA -0.537721
 [60,] NA -0.517145
 [61,] NA -0.453034
 [62,] NA -0.381883
 [63,] NA -0.474799
 [64,] NA  0.134423
 [65,] NA  0.207572
 [66,] NA -0.487226
 [67,] NA -0.415706
 [68,] NA -0.545960
 [69,] NA  0.011510
 [70,] NA  2.215876
 [71,] NA -0.389259
 [72,] NA  2.958549
 [73,] NA  0.117335
 [74,] NA -0.217071
 [75,] NA -0.236541
 [76,] NA  0.143826
 [77,] NA -0.494481
 [78,] NA  0.432077
 [79,] NA -0.526193
 [80,] NA -0.535123
 [81,] NA -0.547786
 [82,] NA -0.450197
 [83,] NA -0.457464
 [84,] NA -0.274769
 [85,] NA -0.515840
 [86,] NA -0.475423
 [87,] NA  0.243291
 [88,] NA -0.423275
 [89,] NA -0.477953
 [90,] NA  0.320032
 [91,] NA  0.101251
 [92,] NA -0.350050
 [93,] NA -0.510331
 [94,] NA -0.288549
 [95,] NA  0.669609
 [96,] NA -0.310876
 [97,] NA  2.598307
 [98,] NA  0.996765
 [99,] NA -0.511277
[100,] NA  0.144973

> nObs( mlFixBHHH )
[1] 100
> 
> # with analytical gradients
> mlgFixBHHH <- maxLik( llfInd, gfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> mlgFixBHHH1 <- maxLik( llfInd, gfInd, start = startValFix, activePar = 2,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH1 )
[1] TRUE
> mlgFixBHHH2 <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH2 )
[1] TRUE
> mlgFixBHHH3 <- maxLik( llfInd, gfInd, start = startValFix, fixed = "mu",
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH3 )
[1] TRUE
> mlgFixBHHH4 <- maxLik( llfInd, gfInd, start = startValFix, fixed = 1,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH4 )
[1] TRUE
> summary( mlgFixBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.134    13.7  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFixBHHH, mlgFixBHHH )
[1] "Component 3: Mean relative difference: 0.0011859"
> mlgFixBHHH2 <- maxLik( llf, gfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH")
> all.equal( mlgFixBHHH, mlgFixBHHH2 )
[1] TRUE
> 
> # with unused Hessians
> mlghFixBHHH <- maxLik( llfInd, gfInd, hf, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlghFixBHHH )
[1] TRUE
> 
> ## BFGS method with fixed parameters
> mlFixBfgs <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> mlFixBfgs3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlFixBfgs, mlFixBfgs3 )
[1] TRUE
> mlFixBfgs4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlFixBfgs, mlFixBfgs4 )
[1] TRUE
> print( mlFixBfgs )
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 (1 free parameter(s))
Estimate(s): 1 1.8255 
> summary( mlFixBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlFixBfgs )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixBfgs )
[1] 406.15
> coef( mlFixBfgs )
    mu  sigma 
1.0000 1.8255 
> condiNumber( mlFixBfgs )
sigma 	 1 
> hessian( mlFixBfgs )
            mu    sigma
mu    -30.0133  -5.9401
sigma  -5.9401 -60.0267
> logLik( mlFixBfgs )
[1] -202.08
> maximType( mlFixBfgs )
[1] "BFGS maximisation"
> nIter( mlFixBfgs )
function 
      27 
> nParam( mlFixBfgs )
[1] 2
> returnCode( mlFixBfgs )
[1] 0
> returnMessage( mlFixBfgs )
[1] "successful convergence "
> vcov( mlFixBfgs )
      mu    sigma
mu     0 0.000000
sigma  0 0.016659
> logLik( summary( mlFixBfgs ) )
[1] -202.08
> all.equal( mlghFix[ -c( 5, 6, 9, 10 ) ], mlFixBfgs[ -c( 5, 6, 9, 10, 11 ) ] )
[1] "Component 3: 'is.NA' value mismatch: 0 in current 1 in target"
[2] "Component 4: 'is.NA' value mismatch: 0 in current 3 in target"
> mlIndFixBfgs <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> all.equal( mlFixBfgs[ -9 ], mlIndFixBfgs[ -c(9,12) ] )
[1] "Component 3: Mean relative difference: 8.7205e-08"
[2] "Component 4: Mean relative difference: 0.0011154" 
> print(formatC(mlIndFixBfgs$gradientObs, format="f", digits=4, width=7), quote=FALSE)
       mu      sigma  
  [1,] -0.3364 -0.3412
  [2,] -0.1381 -0.5130
  [3,]  0.9355  1.0498
  [4,]  0.0423 -0.5445
  [5,]  0.0776 -0.5368
  [6,]  1.0294  1.3864
  [7,]  0.2766 -0.4081
  [8,] -0.7593  0.5046
  [9,] -0.4122 -0.2376
 [10,] -0.2675 -0.4172
 [11,]  0.7347  0.4375
 [12,]  0.2160 -0.4627
 [13,]  0.2405 -0.4422
 [14,]  0.0664 -0.5398
 [15,] -0.3336 -0.3446
 [16,]  1.0725  1.5519
 [17,]  0.2988 -0.3848
 [18,] -1.1803  1.9954
 [19,]  0.4209 -0.2243
 [20,] -0.2838 -0.4008
 [21,] -0.6409  0.2020
 [22,] -0.1308 -0.5166
 [23,] -0.6158  0.1444
 [24,] -0.4375 -0.1985
 [25,] -0.3751 -0.2909
 [26,] -1.0123  1.3229
 [27,]  0.5028 -0.0863
 [28,]  0.0921 -0.5323
 [29,] -0.6831  0.3040
 [30,]  0.7525  0.4859
 [31,]  0.2560 -0.4282
 [32,] -0.1771 -0.4906
 [33,]  0.5372 -0.0209
 [34,]  0.5270 -0.0407
 [35,]  0.4931 -0.1039
 [36,]  0.4133 -0.2360
 [37,]  0.3325 -0.3460
 [38,] -0.0372 -0.5453
 [39,] -0.1836 -0.4863
 [40,] -0.2284 -0.4526
 [41,] -0.4170 -0.2305
 [42,] -0.1248 -0.5194
 [43,] -0.7595  0.5051
 [44,]  1.3018  2.5457
 [45,]  0.7250  0.4117
 [46,] -0.6741  0.2816
 [47,] -0.2418 -0.4411
 [48,] -0.2801 -0.4046
 [49,]  0.4681 -0.1478
 [50,] -0.0500 -0.5432
 [51,]  0.1520 -0.5056
 [52,] -0.0171 -0.5473
 [53,] -0.0257 -0.5466
 [54,]  0.8214  0.6839
 [55,] -0.1355 -0.5143
 [56,]  0.9102  0.9644
 [57,] -0.9295  1.0295
 [58,]  0.3509 -0.3231
 [59,]  0.0743 -0.5377
 [60,]  0.1296 -0.5171
 [61,]  0.2279 -0.4530
 [62,] -0.3015 -0.3819
 [63,] -0.2000 -0.4748
 [64,] -0.6113  0.1344
 [65,] -0.6433  0.2076
 [66,]  0.1822 -0.4872
 [67,]  0.2690 -0.4157
 [68,]  0.0318 -0.5460
 [69,]  0.5535  0.0115
 [70,]  1.2304  2.2159
 [71,] -0.2947 -0.3893
 [72,] -1.3859  2.9585
 [73,]  0.6036  0.1173
 [74,] -0.4257 -0.2171
 [75,] -0.4129 -0.2365
 [76,]  0.6155  0.1438
 [77,] -0.1709 -0.4945
 [78,] -0.7327  0.4321
 [79,]  0.1088 -0.5262
 [80,] -0.0834 -0.5351
 [81,]  0.0035 -0.5478
 [82,]  0.2312 -0.4502
 [83,] -0.2225 -0.4575
 [84,]  0.3867 -0.2748
 [85,] -0.1323 -0.5158
 [86,]  0.1991 -0.4754
 [87,]  0.6583  0.2433
 [88,]  0.2612 -0.4233
 [89,] -0.1956 -0.4780
 [90,]  0.6895  0.3200
 [91,]  0.5963  0.1013
 [92,]  0.3291 -0.3500
 [93,]  0.1433 -0.5103
 [94,] -0.3769 -0.2885
 [95,]  0.8166  0.6696
 [96,] -0.3603 -0.3109
 [97,]  1.3128  2.5983
 [98,]  0.9199  0.9968
 [99,] -0.1415 -0.5113
[100,] -0.6160  0.1450
>                            # print fradient, only 4 digits to avoid clutter in R CMD tests
> mlIndFixBfgs3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlIndFixBfgs, mlIndFixBfgs3 )
[1] TRUE
> mlIndFixBfgs4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlIndFixBfgs, mlIndFixBfgs4 )
[1] TRUE
> nObs( mlIndFixBfgs )
[1] 100
> 
> # with analytical gradients
> mlgFixBfgs <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> mlgFixBfgs3 <- maxLik( llf, gf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlgFixBfgs3 )
[1] TRUE
> mlgFixBfgs4 <- maxLik( llf, gf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlgFixBfgs4 )
[1] TRUE
> summary( mlgFixBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFixBfgs[ -9 ], mlgFixBfgs[ -9 ] )
[1] "Component 4: Mean relative difference: 0.00020974"
> mlgIndFixBfgs <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "BFGS")
> all.equal( mlgFixBfgs[ ], mlgIndFixBfgs[ -12 ] )
[1] TRUE
> mlgIndFixBfgs[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3363902 -0.341242
  [2,] -0.1381495 -0.512969
  [3,]  0.9355164  1.049816
  [4,]  0.0423182 -0.544539
  [5,]  0.0775968 -0.536816
  [6,]  1.0293597  1.386413
  [7,]  0.2766359 -0.408110
  [8,] -0.7592733  0.504561
  [9,] -0.4122401 -0.237586
 [10,] -0.2674805 -0.417204
 [11,]  0.7346779  0.437486
 [12,]  0.2159556 -0.462674
 [13,]  0.2405378 -0.442190
 [14,]  0.0664303 -0.539752
 [15,] -0.3336086 -0.344644
 [16,]  1.0724820  1.551865
 [17,]  0.2988034 -0.384825
 [18,] -1.1803380  1.995415
 [19,]  0.4209447 -0.224347
 [20,] -0.2837632 -0.400819
 [21,] -0.6408939  0.201990
 [22,] -0.1308257 -0.516565
 [23,] -0.6157945  0.144411
 [24,] -0.4374710 -0.198450
 [25,] -0.3751404 -0.290911
 [26,] -1.0123313  1.322948
 [27,]  0.5028289 -0.086265
 [28,]  0.0920525 -0.532340
 [29,] -0.6830950  0.303985
 [30,]  0.7525234  0.485933
 [31,]  0.2559583 -0.428214
 [32,] -0.1770981 -0.490555
 [33,]  0.5372428 -0.020927
 [34,]  0.5270443 -0.040740
 [35,]  0.4931023 -0.103948
 [36,]  0.4133129 -0.235969
 [37,]  0.3324542 -0.346048
 [38,] -0.0371586 -0.545287
 [39,] -0.1836348 -0.486250
 [40,] -0.2283537 -0.452619
 [41,] -0.4169541 -0.230451
 [42,] -0.1247892 -0.519381
 [43,] -0.7594744  0.505118
 [44,]  1.3017791  2.545665
 [45,]  0.7250031  0.411706
 [46,] -0.6740751  0.281639
 [47,] -0.2418062 -0.441073
 [48,] -0.2800805 -0.404610
 [49,]  0.4681249 -0.147775
 [50,] -0.0500370 -0.543237
 [51,]  0.1520385 -0.505611
 [52,] -0.0171334 -0.547272
 [53,] -0.0257303 -0.546599
 [54,]  0.8214173  0.683876
 [55,] -0.1355048 -0.514290
 [56,]  0.9101659  0.964405
 [57,] -0.9295413  1.029473
 [58,]  0.3508776 -0.323067
 [59,]  0.0743357 -0.537721
 [60,]  0.1296053 -0.517145
 [61,]  0.2278547 -0.453034
 [62,] -0.3014880 -0.381883
 [63,] -0.1999867 -0.474799
 [64,] -0.6113357  0.134423
 [65,] -0.6432751  0.207572
 [66,]  0.1821739 -0.487226
 [67,]  0.2690097 -0.415706
 [68,]  0.0318124 -0.545960
 [69,]  0.5535329  0.011510
 [70,]  1.2304341  2.215876
 [71,] -0.2947105 -0.389259
 [72,] -1.3859331  2.958550
 [73,]  0.6036312  0.117335
 [74,] -0.4256531 -0.217071
 [75,] -0.4129338 -0.236541
 [76,]  0.6155346  0.143827
 [77,] -0.1709170 -0.494481
 [78,] -0.7326589  0.432078
 [79,]  0.1088160 -0.526193
 [80,] -0.0833608 -0.535123
 [81,]  0.0034596 -0.547786
 [82,]  0.2312403 -0.450197
 [83,] -0.2224653 -0.457465
 [84,]  0.3867464 -0.274769
 [85,] -0.1323332 -0.515840
 [86,]  0.1991312 -0.475423
 [87,]  0.6583085  0.243291
 [88,]  0.2611903 -0.423275
 [89,] -0.1956199 -0.477953
 [90,]  0.6894994  0.320032
 [91,]  0.5962881  0.101251
 [92,]  0.3291407 -0.350050
 [93,]  0.1432837 -0.510331
 [94,] -0.3768610 -0.288549
 [95,]  0.8166459  0.669609
 [96,] -0.3602680 -0.310876
 [97,]  1.3128088  2.598308
 [98,]  0.9198529  0.996765
 [99,] -0.1414643 -0.511277
[100,] -0.6160444  0.144973

> mlgIndFixBfgs3 <- maxLik( llfInd, gfInd, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlgIndFixBfgs, mlgIndFixBfgs3 )
[1] TRUE
> mlgIndFixBfgs4 <- maxLik( llfInd, gfInd, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlgIndFixBfgs, mlgIndFixBfgs4 )
[1] TRUE
> 
> # with unused Hessians
> mlghFixBfgs <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlghFixBfgs )
[1] TRUE
> mlghFixBfgs3 <- maxLik( llf, gf, hf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlghFixBfgs, mlghFixBfgs3 )
[1] TRUE
> mlghFixBfgs4 <- maxLik( llf, gf, hf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlghFixBfgs, mlghFixBfgs4 )
[1] TRUE
> 
> ## NM method with fixed parameters
> mlFixNm <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> mlFixNm3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm, mlFixNm3 )
[1] TRUE
> mlFixNm4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm, mlFixNm4 )
[1] TRUE
> print( mlFixNm )
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 (1 free parameter(s))
Estimate(s): 1 1.8254 
> summary( mlFixNm )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.2  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlFixNm )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixNm )
[1] 406.15
> coef( mlFixNm )
    mu  sigma 
1.0000 1.8254 
> condiNumber( mlFixNm )
sigma 	 1 
> hessian( mlFixNm )
            mu    sigma
mu    -30.0133  -5.9401
sigma  -5.9401 -60.0551
> logLik( mlFixNm )
[1] -202.08
> maximType( mlFixNm )
[1] "Nelder-Mead maximisation"
> nIter( mlFixNm )
function 
      28 
> nParam( mlFixNm )
[1] 2
> returnCode( mlFixNm )
[1] 0
> returnMessage( mlFixNm )
[1] "successful convergence "
> vcov( mlFixNm )
      mu    sigma
mu     0 0.000000
sigma  0 0.016651
> logLik( summary( mlFixNm ) )
[1] -202.08
> all.equal( mlFixBfgs[ -c( 9, 10 ) ], mlFixNm[ -c( 9, 10 ) ] )
[1] "Component 2: Mean relative difference: 3.6613e-05"
[2] "Component 3: Mean relative difference: 0.0008126" 
[3] "Component 4: Mean relative difference: 0.00047348"
> mlIndFixNm <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm[ ], mlIndFixNm[ -12 ] )
[1] "Component 4: Mean relative difference: 0.0020353"
> mlIndFixNm[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3364148 -0.341239
  [2,] -0.1381596 -0.512985
  [3,]  0.9355849  1.049971
  [4,]  0.0423213 -0.544559
  [5,]  0.0776025 -0.536835
  [6,]  1.0294350  1.386605
  [7,]  0.2766562 -0.408115
  [8,] -0.7593289  0.504656
  [9,] -0.4122703 -0.237572
 [10,] -0.2675001 -0.417210
 [11,]  0.7347317  0.437574
 [12,]  0.2159714 -0.462685
 [13,]  0.2405554 -0.442198
 [14,]  0.0664352 -0.539771
 [15,] -0.3336330 -0.344642
 [16,]  1.0725605  1.552076
 [17,]  0.2988253 -0.384827
 [18,] -1.1804244  1.995675
 [19,]  0.4209755 -0.224332
 [20,] -0.2837840 -0.400823
 [21,] -0.6409408  0.202052
 [22,] -0.1308353 -0.516581
 [23,] -0.6158396  0.144467
 [24,] -0.4375031 -0.198432
 [25,] -0.3751679 -0.290902
 [26,] -1.0124055  1.323133
 [27,]  0.5028657 -0.086234
 [28,]  0.0920593 -0.532358
 [29,] -0.6831450  0.304058
 [30,]  0.7525785  0.486027
 [31,]  0.2559770 -0.428221
 [32,] -0.1771110 -0.490569
 [33,]  0.5372821 -0.020889
 [34,]  0.5270829 -0.040705
 [35,]  0.4931384 -0.103920
 [36,]  0.4133432 -0.235955
 [37,]  0.3324785 -0.346046
 [38,] -0.0371613 -0.545307
 [39,] -0.1836483 -0.486264
 [40,] -0.2283705 -0.452628
 [41,] -0.4169846 -0.230436
 [42,] -0.1247984 -0.519398
 [43,] -0.7595300  0.505214
 [44,]  1.3018744  2.545985
 [45,]  0.7250561  0.411792
 [46,] -0.6741245  0.281710
 [47,] -0.2418239 -0.441081
 [48,] -0.2801010 -0.404614
 [49,]  0.4681592 -0.147752
 [50,] -0.0500407 -0.543257
 [51,]  0.1520496 -0.505627
 [52,] -0.0171346 -0.547292
 [53,] -0.0257322 -0.546619
 [54,]  0.8214774  0.683992
 [55,] -0.1355147 -0.514306
 [56,]  0.9102325  0.964551
 [57,] -0.9296093  1.029626
 [58,]  0.3509032 -0.323062
 [59,]  0.0743411 -0.537740
 [60,]  0.1296148 -0.517161
 [61,]  0.2278714 -0.453044
 [62,] -0.3015101 -0.381885
 [63,] -0.2000014 -0.474811
 [64,] -0.6113804  0.134478
 [65,] -0.6433222  0.207635
 [66,]  0.1821873 -0.487239
 [67,]  0.2690294 -0.415712
 [68,]  0.0318148 -0.545980
 [69,]  0.5535735  0.011551
 [70,]  1.2305242  2.216160
 [71,] -0.2947321 -0.389262
 [72,] -1.3860346  2.958915
 [73,]  0.6036754  0.117388
 [74,] -0.4256842 -0.217054
 [75,] -0.4129640 -0.236527
 [76,]  0.6155796  0.143882
 [77,] -0.1709296 -0.494496
 [78,] -0.7327125  0.432165
 [79,]  0.1088240 -0.526210
 [80,] -0.0833669 -0.535141
 [81,]  0.0034598 -0.547806
 [82,]  0.2312572 -0.450206
 [83,] -0.2224816 -0.457475
 [84,]  0.3867747 -0.274759
 [85,] -0.1323429 -0.515857
 [86,]  0.1991458 -0.475435
 [87,]  0.6583567  0.243358
 [88,]  0.2612094 -0.423281
 [89,] -0.1956342 -0.477965
 [90,]  0.6895499  0.320107
 [91,]  0.5963317  0.101302
 [92,]  0.3291648 -0.350048
 [93,]  0.1432942 -0.510347
 [94,] -0.3768886 -0.288540
 [95,]  0.8167057  0.669722
 [96,] -0.3602944 -0.310870
 [97,]  1.3129049  2.598633
 [98,]  0.9199203  0.996915
 [99,] -0.1414746 -0.511293
[100,] -0.6160896  0.145029

> mlIndFixNm3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlIndFixNm, mlIndFixNm3 )
[1] TRUE
> mlIndFixNm4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlIndFixNm, mlIndFixNm4 )
[1] TRUE
> nObs( mlIndFixNm )
[1] 100
> 
> # with analytical gradients
> mlgFixNm <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> mlgFixNm3 <- maxLik( llf, gf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlgFixNm3 )
[1] TRUE
> mlgFixNm4 <- maxLik( llf, gf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlgFixNm4 )
[1] TRUE
> summary( mlgFixNm )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFixNm, mlgFixNm )
[1] "Component 4: Mean relative difference: 0.00037194"
> mlgIndFixNm <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "NM")
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm[ ], mlgIndFixNm[ -12 ] )
[1] TRUE
> mlgIndFixNm[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3364148 -0.341239
  [2,] -0.1381596 -0.512985
  [3,]  0.9355849  1.049971
  [4,]  0.0423213 -0.544559
  [5,]  0.0776025 -0.536835
  [6,]  1.0294350  1.386605
  [7,]  0.2766562 -0.408115
  [8,] -0.7593289  0.504656
  [9,] -0.4122703 -0.237572
 [10,] -0.2675001 -0.417210
 [11,]  0.7347317  0.437574
 [12,]  0.2159714 -0.462685
 [13,]  0.2405554 -0.442198
 [14,]  0.0664352 -0.539771
 [15,] -0.3336330 -0.344642
 [16,]  1.0725605  1.552076
 [17,]  0.2988253 -0.384827
 [18,] -1.1804244  1.995675
 [19,]  0.4209755 -0.224332
 [20,] -0.2837840 -0.400823
 [21,] -0.6409408  0.202052
 [22,] -0.1308353 -0.516581
 [23,] -0.6158396  0.144467
 [24,] -0.4375031 -0.198432
 [25,] -0.3751679 -0.290902
 [26,] -1.0124055  1.323133
 [27,]  0.5028657 -0.086234
 [28,]  0.0920593 -0.532358
 [29,] -0.6831450  0.304058
 [30,]  0.7525785  0.486027
 [31,]  0.2559770 -0.428221
 [32,] -0.1771110 -0.490569
 [33,]  0.5372821 -0.020889
 [34,]  0.5270829 -0.040705
 [35,]  0.4931384 -0.103920
 [36,]  0.4133432 -0.235955
 [37,]  0.3324785 -0.346046
 [38,] -0.0371613 -0.545307
 [39,] -0.1836483 -0.486264
 [40,] -0.2283705 -0.452628
 [41,] -0.4169846 -0.230436
 [42,] -0.1247984 -0.519398
 [43,] -0.7595300  0.505214
 [44,]  1.3018744  2.545985
 [45,]  0.7250561  0.411792
 [46,] -0.6741245  0.281710
 [47,] -0.2418239 -0.441081
 [48,] -0.2801010 -0.404614
 [49,]  0.4681592 -0.147752
 [50,] -0.0500407 -0.543257
 [51,]  0.1520496 -0.505627
 [52,] -0.0171346 -0.547292
 [53,] -0.0257322 -0.546619
 [54,]  0.8214774  0.683992
 [55,] -0.1355147 -0.514306
 [56,]  0.9102325  0.964551
 [57,] -0.9296093  1.029626
 [58,]  0.3509032 -0.323062
 [59,]  0.0743411 -0.537740
 [60,]  0.1296148 -0.517161
 [61,]  0.2278714 -0.453044
 [62,] -0.3015101 -0.381885
 [63,] -0.2000014 -0.474811
 [64,] -0.6113804  0.134478
 [65,] -0.6433222  0.207635
 [66,]  0.1821873 -0.487239
 [67,]  0.2690294 -0.415712
 [68,]  0.0318148 -0.545980
 [69,]  0.5535735  0.011551
 [70,]  1.2305242  2.216160
 [71,] -0.2947321 -0.389262
 [72,] -1.3860346  2.958915
 [73,]  0.6036754  0.117388
 [74,] -0.4256842 -0.217054
 [75,] -0.4129640 -0.236527
 [76,]  0.6155796  0.143882
 [77,] -0.1709296 -0.494496
 [78,] -0.7327125  0.432165
 [79,]  0.1088240 -0.526210
 [80,] -0.0833669 -0.535141
 [81,]  0.0034598 -0.547806
 [82,]  0.2312572 -0.450206
 [83,] -0.2224816 -0.457475
 [84,]  0.3867747 -0.274759
 [85,] -0.1323429 -0.515857
 [86,]  0.1991458 -0.475435
 [87,]  0.6583567  0.243358
 [88,]  0.2612094 -0.423281
 [89,] -0.1956342 -0.477965
 [90,]  0.6895499  0.320107
 [91,]  0.5963317  0.101302
 [92,]  0.3291648 -0.350048
 [93,]  0.1432942 -0.510347
 [94,] -0.3768886 -0.288540
 [95,]  0.8167057  0.669722
 [96,] -0.3602944 -0.310870
 [97,]  1.3129049  2.598633
 [98,]  0.9199203  0.996915
 [99,] -0.1414746 -0.511293
[100,] -0.6160896  0.145029

> 
> # with unused Hessians
> mlghFixNm <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlghFixNm )
[1] TRUE
> mlghFixNm3 <- maxLik( llf, gf, hf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlghFixNm, mlghFixNm3 )
[1] TRUE
> mlghFixNm4 <- maxLik( llf, gf, hf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-diml optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlghFixNm, mlghFixNm4 )
[1] TRUE
> 
> ## SANN method with fixed parameters
> mlFixSann <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> mlFixSann3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "SANN" )
> all.equal( mlFixSann, mlFixSann3 )
[1] TRUE
> mlFixSann4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "SANN" )
> all.equal( mlFixSann, mlFixSann4 )
[1] TRUE
> print( mlFixSann )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 (1 free parameter(s))
Estimate(s): 1 1.8254 
> summary( mlFixSann )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> activePar( mlFixSann )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixSann )
[1] 406.15
> coef( mlFixSann )
    mu  sigma 
1.0000 1.8254 
> condiNumber( mlFixSann )
sigma 	 1 
> hessian( mlFixSann )
            mu    sigma
mu    -29.9849  -5.9401
sigma  -5.9401 -60.0267
> logLik( mlFixSann )
[1] -202.08
> maximType( mlFixSann )
[1] "SANN maximisation"
> nIter( mlFixSann )
function 
   10000 
> nParam( mlFixSann )
[1] 2
> returnCode( mlFixSann )
[1] 0
> returnMessage( mlFixSann )
[1] "successful convergence "
> vcov( mlFixSann )
      mu    sigma
mu     0 0.000000
sigma  0 0.016659
> logLik( summary( mlFixSann ) )
[1] -202.08
> all.equal( mlFixBfgs[ -c( 9, 10 ) ], mlFixSann[ -c( 9, 10 ) ] )
[1] "Component 2: Mean relative difference: 8.9402e-06"
[2] "Component 3: Mean relative difference: 0.00019841"
[3] "Component 4: Mean relative difference: 0.00094697"
> mlIndFixSann <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> all.equal( mlFixSann[ ], mlIndFixSann[ -12 ] )
[1] "Component 4: Mean relative difference: 0.00063151"
> mlIndFixSann[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3363962 -0.341241
  [2,] -0.1381520 -0.512972
  [3,]  0.9355331  1.049854
  [4,]  0.0423190 -0.544544
  [5,]  0.0775982 -0.536821
  [6,]  1.0293781  1.386460
  [7,]  0.2766408 -0.408111
  [8,] -0.7592868  0.504584
  [9,] -0.4122475 -0.237583
 [10,] -0.2674853 -0.417205
 [11,]  0.7346911  0.437507
 [12,]  0.2159594 -0.462677
 [13,]  0.2405421 -0.442192
 [14,]  0.0664315 -0.539757
 [15,] -0.3336146 -0.344644
 [16,]  1.0725012  1.551917
 [17,]  0.2988087 -0.384825
 [18,] -1.1803591  1.995479
 [19,]  0.4209522 -0.224343
 [20,] -0.2837683 -0.400820
 [21,] -0.6409053  0.202005
 [22,] -0.1308280 -0.516569
 [23,] -0.6158055  0.144424
 [24,] -0.4374788 -0.198446
 [25,] -0.3751471 -0.290909
 [26,] -1.0123494  1.322993
 [27,]  0.5028379 -0.086257
 [28,]  0.0920542 -0.532344
 [29,] -0.6831072  0.304003
 [30,]  0.7525368  0.485956
 [31,]  0.2559628 -0.428215
 [32,] -0.1771012 -0.490558
 [33,]  0.5372524 -0.020917
 [34,]  0.5270537 -0.040732
 [35,]  0.4931111 -0.103941
 [36,]  0.4133203 -0.235966
 [37,]  0.3324601 -0.346047
 [38,] -0.0371593 -0.545292
 [39,] -0.1836381 -0.486254
 [40,] -0.2283578 -0.452621
 [41,] -0.4169615 -0.230447
 [42,] -0.1247915 -0.519385
 [43,] -0.7594880  0.505142
 [44,]  1.3018024  2.545743
 [45,]  0.7250160  0.411727
 [46,] -0.6740872  0.281656
 [47,] -0.2418106 -0.441075
 [48,] -0.2800855 -0.404611
 [49,]  0.4681333 -0.147770
 [50,] -0.0500379 -0.543242
 [51,]  0.1520412 -0.505615
 [52,] -0.0171337 -0.547277
 [53,] -0.0257307 -0.546604
 [54,]  0.8214319  0.683904
 [55,] -0.1355072 -0.514294
 [56,]  0.9101822  0.964440
 [57,] -0.9295579  1.029510
 [58,]  0.3508838 -0.323065
 [59,]  0.0743370 -0.537725
 [60,]  0.1296076 -0.517149
 [61,]  0.2278587 -0.453037
 [62,] -0.3014934 -0.381883
 [63,] -0.1999903 -0.474802
 [64,] -0.6113466  0.134436
 [65,] -0.6432866  0.207587
 [66,]  0.1821772 -0.487229
 [67,]  0.2690145 -0.415708
 [68,]  0.0318130 -0.545965
 [69,]  0.5535428  0.011520
 [70,]  1.2304561  2.215946
 [71,] -0.2947158 -0.389260
 [72,] -1.3859578  2.958639
 [73,]  0.6036419  0.117348
 [74,] -0.4256607 -0.217067
 [75,] -0.4129412 -0.236538
 [76,]  0.6155456  0.143840
 [77,] -0.1709201 -0.494485
 [78,] -0.7326720  0.432099
 [79,]  0.1088179 -0.526197
 [80,] -0.0833623 -0.535127
 [81,]  0.0034597 -0.547791
 [82,]  0.2312444 -0.450199
 [83,] -0.2224693 -0.457467
 [84,]  0.3867533 -0.274767
 [85,] -0.1323355 -0.515844
 [86,]  0.1991348 -0.475426
 [87,]  0.6583203  0.243307
 [88,]  0.2611949 -0.423276
 [89,] -0.1956234 -0.477956
 [90,]  0.6895117  0.320050
 [91,]  0.5962987  0.101263
 [92,]  0.3291466 -0.350049
 [93,]  0.1432862 -0.510335
 [94,] -0.3768678 -0.288547
 [95,]  0.8166605  0.669637
 [96,] -0.3602744 -0.310875
 [97,]  1.3128322  2.598387
 [98,]  0.9198694  0.996802
 [99,] -0.1414668 -0.511280
[100,] -0.6160555  0.144987

> nObs( mlIndFixSann )
[1] 100
> 
> # with analytical gradients
> mlgFixSann <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> summary( mlgFixSann )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.08 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> all.equal( mlFixSann, mlgFixSann )
[1] "Component 4: Mean relative difference: 0.00039275"
> mlgIndFixSann <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "SANN")
> all.equal( mlgFixSann[ ], mlgIndFixSann[ -12 ] )
[1] TRUE
> mlgIndFixSann[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3363962 -0.341241
  [2,] -0.1381520 -0.512972
  [3,]  0.9355331  1.049854
  [4,]  0.0423190 -0.544544
  [5,]  0.0775982 -0.536821
  [6,]  1.0293781  1.386460
  [7,]  0.2766408 -0.408111
  [8,] -0.7592868  0.504584
  [9,] -0.4122475 -0.237583
 [10,] -0.2674853 -0.417205
 [11,]  0.7346911  0.437507
 [12,]  0.2159594 -0.462677
 [13,]  0.2405421 -0.442192
 [14,]  0.0664315 -0.539757
 [15,] -0.3336146 -0.344644
 [16,]  1.0725012  1.551917
 [17,]  0.2988087 -0.384825
 [18,] -1.1803591  1.995479
 [19,]  0.4209522 -0.224343
 [20,] -0.2837683 -0.400820
 [21,] -0.6409053  0.202005
 [22,] -0.1308280 -0.516569
 [23,] -0.6158055  0.144424
 [24,] -0.4374788 -0.198446
 [25,] -0.3751471 -0.290909
 [26,] -1.0123494  1.322993
 [27,]  0.5028379 -0.086257
 [28,]  0.0920542 -0.532344
 [29,] -0.6831072  0.304003
 [30,]  0.7525368  0.485956
 [31,]  0.2559628 -0.428215
 [32,] -0.1771012 -0.490558
 [33,]  0.5372524 -0.020917
 [34,]  0.5270537 -0.040732
 [35,]  0.4931111 -0.103941
 [36,]  0.4133203 -0.235966
 [37,]  0.3324601 -0.346047
 [38,] -0.0371593 -0.545292
 [39,] -0.1836381 -0.486254
 [40,] -0.2283578 -0.452621
 [41,] -0.4169615 -0.230447
 [42,] -0.1247915 -0.519385
 [43,] -0.7594880  0.505142
 [44,]  1.3018024  2.545743
 [45,]  0.7250160  0.411727
 [46,] -0.6740872  0.281656
 [47,] -0.2418106 -0.441075
 [48,] -0.2800855 -0.404611
 [49,]  0.4681333 -0.147770
 [50,] -0.0500379 -0.543242
 [51,]  0.1520412 -0.505615
 [52,] -0.0171337 -0.547277
 [53,] -0.0257307 -0.546604
 [54,]  0.8214319  0.683904
 [55,] -0.1355072 -0.514294
 [56,]  0.9101822  0.964440
 [57,] -0.9295579  1.029510
 [58,]  0.3508838 -0.323065
 [59,]  0.0743370 -0.537725
 [60,]  0.1296076 -0.517149
 [61,]  0.2278587 -0.453037
 [62,] -0.3014934 -0.381883
 [63,] -0.1999903 -0.474802
 [64,] -0.6113466  0.134436
 [65,] -0.6432866  0.207587
 [66,]  0.1821772 -0.487229
 [67,]  0.2690145 -0.415708
 [68,]  0.0318130 -0.545965
 [69,]  0.5535428  0.011520
 [70,]  1.2304561  2.215946
 [71,] -0.2947158 -0.389260
 [72,] -1.3859578  2.958639
 [73,]  0.6036419  0.117348
 [74,] -0.4256607 -0.217067
 [75,] -0.4129412 -0.236538
 [76,]  0.6155456  0.143840
 [77,] -0.1709201 -0.494485
 [78,] -0.7326720  0.432099
 [79,]  0.1088179 -0.526197
 [80,] -0.0833623 -0.535127
 [81,]  0.0034597 -0.547791
 [82,]  0.2312444 -0.450199
 [83,] -0.2224693 -0.457467
 [84,]  0.3867533 -0.274767
 [85,] -0.1323355 -0.515844
 [86,]  0.1991348 -0.475426
 [87,]  0.6583203  0.243307
 [88,]  0.2611949 -0.423276
 [89,] -0.1956234 -0.477956
 [90,]  0.6895117  0.320050
 [91,]  0.5962987  0.101263
 [92,]  0.3291466 -0.350049
 [93,]  0.1432862 -0.510335
 [94,] -0.3768678 -0.288547
 [95,]  0.8166605  0.669637
 [96,] -0.3602744 -0.310875
 [97,]  1.3128322  2.598387
 [98,]  0.9198694  0.996802
 [99,] -0.1414668 -0.511280
[100,] -0.6160555  0.144987

> 
> # with unused Hessians
> mlghFixSann <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> all.equal( mlgFixSann, mlghFixSann )
[1] TRUE
> 
> 
> ############### with parameter constraints ###############
> A <- matrix( -1, nrow = 1, ncol = 2 )
> 
> 
> ############### inequality constraints ###############
> inEq <- list( ineqA = A, ineqB = 2.5 )
> 
> ## NR method with inequality constraints
> try( maxLik( llf, start = startVal, constraints = inEq, method = "NR" ) )
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,  : 
  Inequality constraints not implemented for maxNR
> 
> ## BHHH method with inequality constraints
> try( maxLik( llf, start = startVal, constraints = inEq, method = "BHHH" ) )
Error in maxNR(fn = fn, grad = grad, hess = hess, start = start, iterlim = iterlim,  : 
  Inequality constraints not implemented for maxNR
> 
> ## BFGS method with inequality constraints
> mlBfgsInEq <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> print( mlBfgsInEq )
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.81972 1.6803 
> summary( mlBfgsInEq )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0014505 
--------------------------------------------
> activePar( mlBfgsInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBfgsInEq )
[1] 413.07
> coef( mlBfgsInEq )
     mu   sigma 
0.81972 1.68027 
> condiNumber( mlBfgsInEq )
mu 	 1 
sigma 	 3.6106 
> hessian( mlBfgsInEq )
           mu   sigma
mu    -35.442 -15.234
sigma -15.234 -93.706
> logLik( mlBfgsInEq )
[1] -204.53
> maximType( mlBfgsInEq )
[1] "BFGS maximisation"
> nIter( mlBfgsInEq )
function 
     130 
> nParam( mlBfgsInEq )
[1] 2
> returnCode( mlBfgsInEq )
[1] 0
> returnMessage( mlBfgsInEq )
[1] "successful convergence "
> vcov( mlBfgsInEq )
              mu      sigma
mu     0.0303350 -0.0049316
sigma -0.0049316  0.0114734
> logLik( summary( mlBfgsInEq ) )
[1] -204.53
> mlBfgsInEqInd <- maxLik( llfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> summary( mlBfgsInEqInd )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0014505 
--------------------------------------------
> all.equal( mlBfgsInEq[ ], mlBfgsInEqInd[ -12 ] )
[1] "Component 3: Mean relative difference: 1.4957e-08"              
[2] "Component 4: Mean relative difference: 0.00071225"              
[3] "Component 11: Component 2: Mean relative difference: 7.1367e-07"
> mlBfgsInEqInd[ 12 ]
$gradientObs
              mu     sigma
  [1,] -0.333180 -0.408617
  [2,] -0.099200 -0.578607
  [3,]  1.168027  1.697228
  [4,]  0.113802 -0.573381
  [5,]  0.155441 -0.554544
  [6,]  1.278788  2.152602
  [7,]  0.390363 -0.339098
  [8,] -0.832301  0.568822
  [9,] -0.422704 -0.294914
 [10,] -0.251847 -0.488568
 [11,]  0.930981  0.861191
 [12,]  0.318743 -0.424432
 [13,]  0.347757 -0.391939
 [14,]  0.142261 -0.561137
 [15,] -0.329897 -0.412275
 [16,]  1.329685  2.375679
 [17,]  0.416527 -0.303625
 [18,] -1.329276  2.373850
 [19,]  0.560688 -0.066915
 [20,] -0.271066 -0.471682
 [21,] -0.692580  0.210828
 [22,] -0.090556 -0.581364
 [23,] -0.662956  0.143353
 [24,] -0.452484 -0.251121
 [25,] -0.378916 -0.353893
 [26,] -1.130981  1.554120
 [27,]  0.657334  0.130882
 [28,]  0.172503 -0.545142
 [29,] -0.742389  0.330924
 [30,]  0.952044  0.927833
 [31,]  0.365957 -0.370113
 [32,] -0.145171 -0.559732
 [33,]  0.697952  0.223380
 [34,]  0.685915  0.195390
 [35,]  0.645854  0.105744
 [36,]  0.551680 -0.083751
 [37,]  0.456244 -0.245380
 [38,]  0.019997 -0.594471
 [39,] -0.152886 -0.555868
 [40,] -0.205667 -0.524069
 [41,] -0.428268 -0.286958
 [42,] -0.083432 -0.583446
 [43,] -0.832538  0.569486
 [44,]  1.600320  3.708069
 [45,]  0.919562  0.825684
 [46,] -0.731743  0.304555
 [47,] -0.221545 -0.512672
 [48,] -0.266719 -0.475610
 [49,]  0.616374  0.043220
 [50,]  0.004797 -0.595104
 [51,]  0.243303 -0.495677
 [52,]  0.043633 -0.591944
 [53,]  0.033486 -0.593258
 [54,]  1.033358  1.199098
 [55,] -0.096079 -0.579632
 [56,]  1.138106  1.581287
 [57,] -1.033265  1.198775
 [58,]  0.477989 -0.211246
 [59,]  0.151592 -0.556530
 [60,]  0.216825 -0.516148
 [61,]  0.332787 -0.409057
 [62,] -0.291986 -0.451890
 [63,] -0.172186 -0.545326
 [64,] -0.657693  0.131675
 [65,] -0.695391  0.217382
 [66,]  0.278871 -0.464469
 [67,]  0.381362 -0.350769
 [68,]  0.101402 -0.577865
 [69,]  0.717179  0.269097
 [70,]  1.516113  3.267122
 [71,] -0.283986 -0.459632
 [72,] -1.571936  3.556774
 [73,]  0.776309  0.417482
 [74,] -0.438535 -0.272004
 [75,] -0.423523 -0.293749
 [76,]  0.790359  0.454466
 [77,] -0.137875 -0.563201
 [78,] -0.800889  0.482620
 [79,]  0.192288 -0.533015
 [80,] -0.034534 -0.593139
 [81,]  0.067938 -0.587387
 [82,]  0.336783 -0.404561
 [83,] -0.198717 -0.528791
 [84,]  0.520324 -0.140231
 [85,] -0.092336 -0.580817
 [86,]  0.298886 -0.445040
 [87,]  0.840844  0.592839
 [88,]  0.372133 -0.362454
 [89,] -0.167032 -0.548264
 [90,]  0.877658  0.699141
 [91,]  0.767642  0.394998
 [92,]  0.452333 -0.251350
 [93,]  0.232970 -0.503946
 [94,] -0.380947 -0.351301
 [95,]  1.027726  1.179595
 [96,] -0.361363 -0.375728
 [97,]  1.613338  3.778364
 [98,]  1.149540  1.625236
 [99,] -0.103113 -0.577277
[100,] -0.663251  0.144011

> nObs( mlBfgsInEqInd )
[1] 100
> 
> # with analytical gradients
> mlgBfgsInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlBfgsInEq, mlgBfgsInEq )
[1] "Component 2: Mean relative difference: 2.7021e-08"              
[2] "Component 3: Mean relative difference: 1.3164e-07"              
[3] "Component 4: Mean relative difference: 0.00048736"              
[4] "Component 11: Component 2: Mean relative difference: 4.8053e-06"
> mlgBfgsInEqInd <- maxLik( llfInd, gfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEqInd[ -12 ], mlgBfgsInEq[ ] )
[1] TRUE
> mlgBfgsInEqInd[ 12 ]
$gradientObs
              mu     sigma
  [1,] -0.333180 -0.408617
  [2,] -0.099200 -0.578607
  [3,]  1.168027  1.697228
  [4,]  0.113802 -0.573381
  [5,]  0.155441 -0.554544
  [6,]  1.278789  2.152603
  [7,]  0.390363 -0.339098
  [8,] -0.832301  0.568822
  [9,] -0.422704 -0.294914
 [10,] -0.251847 -0.488568
 [11,]  0.930981  0.861191
 [12,]  0.318743 -0.424432
 [13,]  0.347757 -0.391939
 [14,]  0.142261 -0.561137
 [15,] -0.329897 -0.412275
 [16,]  1.329685  2.375679
 [17,]  0.416527 -0.303625
 [18,] -1.329276  2.373851
 [19,]  0.560688 -0.066915
 [20,] -0.271066 -0.471682
 [21,] -0.692580  0.210828
 [22,] -0.090556 -0.581364
 [23,] -0.662956  0.143353
 [24,] -0.452484 -0.251121
 [25,] -0.378916 -0.353893
 [26,] -1.130981  1.554120
 [27,]  0.657334  0.130882
 [28,]  0.172503 -0.545142
 [29,] -0.742389  0.330924
 [30,]  0.952044  0.927833
 [31,]  0.365957 -0.370113
 [32,] -0.145171 -0.559732
 [33,]  0.697952  0.223380
 [34,]  0.685915  0.195390
 [35,]  0.645854  0.105744
 [36,]  0.551680 -0.083751
 [37,]  0.456244 -0.245380
 [38,]  0.019997 -0.594471
 [39,] -0.152886 -0.555868
 [40,] -0.205667 -0.524069
 [41,] -0.428268 -0.286958
 [42,] -0.083432 -0.583446
 [43,] -0.832538  0.569487
 [44,]  1.600320  3.708069
 [45,]  0.919562  0.825684
 [46,] -0.731743  0.304555
 [47,] -0.221545 -0.512672
 [48,] -0.266719 -0.475610
 [49,]  0.616374  0.043220
 [50,]  0.004797 -0.595104
 [51,]  0.243303 -0.495677
 [52,]  0.043633 -0.591944
 [53,]  0.033486 -0.593258
 [54,]  1.033358  1.199098
 [55,] -0.096079 -0.579632
 [56,]  1.138106  1.581287
 [57,] -1.033265  1.198775
 [58,]  0.477989 -0.211246
 [59,]  0.151592 -0.556530
 [60,]  0.216825 -0.516148
 [61,]  0.332787 -0.409057
 [62,] -0.291986 -0.451890
 [63,] -0.172186 -0.545326
 [64,] -0.657693  0.131675
 [65,] -0.695391  0.217382
 [66,]  0.278871 -0.464469
 [67,]  0.381362 -0.350769
 [68,]  0.101402 -0.577865
 [69,]  0.717179  0.269097
 [70,]  1.516113  3.267123
 [71,] -0.283986 -0.459632
 [72,] -1.571936  3.556774
 [73,]  0.776309  0.417482
 [74,] -0.438535 -0.272004
 [75,] -0.423523 -0.293749
 [76,]  0.790359  0.454466
 [77,] -0.137875 -0.563201
 [78,] -0.800889  0.482620
 [79,]  0.192288 -0.533015
 [80,] -0.034534 -0.593139
 [81,]  0.067938 -0.587387
 [82,]  0.336783 -0.404561
 [83,] -0.198717 -0.528791
 [84,]  0.520324 -0.140231
 [85,] -0.092336 -0.580817
 [86,]  0.298886 -0.445040
 [87,]  0.840844  0.592839
 [88,]  0.372133 -0.362454
 [89,] -0.167032 -0.548264
 [90,]  0.877658  0.699141
 [91,]  0.767642  0.394998
 [92,]  0.452333 -0.251350
 [93,]  0.232970 -0.503946
 [94,] -0.380947 -0.351301
 [95,]  1.027726  1.179595
 [96,] -0.361363 -0.375728
 [97,]  1.613338  3.778364
 [98,]  1.149540  1.625236
 [99,] -0.103113 -0.577278
[100,] -0.663251  0.144011

> mlgBfgsInEqInd2 <- maxLik( llf, gfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEqInd, mlgBfgsInEqInd2 )
[1] TRUE
> 
> # with unused Hessian
> mlghBfgsInEq <- maxLik( llf, gf, hf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEq, mlghBfgsInEq )
[1] TRUE
> 
> ## NM method with inequality constraints
> mlNmInEq <- maxLik( llf, start = startVal, constraints = inEq, method = "NM" )
> print( mlNmInEq )
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.81971 1.6803 
> summary( mlNmInEq )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0014678 
--------------------------------------------
> activePar( mlNmInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNmInEq )
[1] 413.07
> coef( mlNmInEq )
     mu   sigma 
0.81971 1.68028 
> condiNumber( mlNmInEq )
mu 	 1 
sigma 	 3.61 
> hessian( mlNmInEq )
           mu   sigma
mu    -35.442 -15.234
sigma -15.234 -93.678
> logLik( mlNmInEq )
[1] -204.53
> maximType( mlNmInEq )
[1] "Nelder-Mead maximisation"
> nIter( mlNmInEq )
function 
     103 
> nParam( mlNmInEq )
[1] 2
> returnCode( mlNmInEq )
[1] 0
> returnMessage( mlNmInEq )
[1] "successful convergence "
> vcov( mlNmInEq )
              mu      sigma
mu     0.0303357 -0.0049332
sigma -0.0049332  0.0114771
> logLik( summary( mlNmInEq ) )
[1] -204.53
> all.equal( mlBfgsInEq, mlNmInEq )
[1] "Component 1: Mean relative difference: 8.099e-08"             
[2] "Component 2: Mean relative difference: 5.2841e-06"            
[3] "Component 3: Mean relative difference: 2.6948e-05"            
[4] "Component 4: Mean relative difference: 0.00030331"            
[5] "Component 9: Mean relative difference: 0.20769"               
[6] "Component 10: 1 string mismatch"                              
[7] "Component 11: Component 2: Mean relative difference: 0.011895"
> mlNmInEqInd <- maxLik( llfInd, start = startVal, constraints = inEq,
+    method = "NM" )
> summary( mlNmInEqInd )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0014678 
--------------------------------------------
> all.equal( mlNmInEq[ ], mlNmInEqInd[ -12 ] )
[1] "Component 4: Mean relative difference: 0.00091575"
> mlNmInEqInd[ 12 ]
$gradientObs
               mu     sigma
  [1,] -0.3331752 -0.408620
  [2,] -0.0991975 -0.578606
  [3,]  1.1680191  1.697209
  [4,]  0.1138033 -0.573378
  [5,]  0.1554416 -0.554541
  [6,]  1.2787796  2.152579
  [7,]  0.3903616 -0.339096
  [8,] -0.8322918  0.568804
  [9,] -0.4226987 -0.294918
 [10,] -0.2518431 -0.488569
 [11,]  0.9309753  0.861181
 [12,]  0.3187424 -0.424429
 [13,]  0.3477561 -0.391937
 [14,]  0.1422621 -0.561134
 [15,] -0.3298922 -0.412277
 [16,]  1.3296756  2.375652
 [17,]  0.4165253 -0.303623
 [18,] -1.3292622  2.373805
 [19,]  0.5606851 -0.066915
 [20,] -0.2710611 -0.471683
 [21,] -0.6925720  0.210815
 [22,] -0.0905534 -0.581362
 [23,] -0.6629479  0.143342
 [24,] -0.4524779 -0.251126
 [25,] -0.3789110 -0.353897
 [26,] -1.1309688  1.554086
 [27,]  0.6573306  0.130880
 [28,]  0.1725033 -0.545139
 [29,] -0.7423807  0.330910
 [30,]  0.9520378  0.927823
 [31,]  0.3659564 -0.370110
 [32,] -0.1451673 -0.559731
 [33,]  0.6979483  0.223376
 [34,]  0.6859114  0.195387
 [35,]  0.6458506  0.105742
 [36,]  0.5516775 -0.083751
 [37,]  0.4562423 -0.245378
 [38,]  0.0199991 -0.594468
 [39,] -0.1528825 -0.555867
 [40,] -0.2056629 -0.524069
 [41,] -0.4282624 -0.286963
 [42,] -0.0834287 -0.583445
 [43,] -0.8325291  0.569468
 [44,]  1.6003083  3.708027
 [45,]  0.9195563  0.825675
 [46,] -0.7317349  0.304541
 [47,] -0.2215405 -0.512672
 [48,] -0.2667145 -0.475611
 [49,]  0.6163705  0.043218
 [50,]  0.0047991 -0.595101
 [51,]  0.2433029 -0.495674
 [52,]  0.0436343 -0.591941
 [53,]  0.0334876 -0.593256
 [54,]  1.0333512  1.199084
 [55,] -0.0960760 -0.579630
 [56,]  1.1380986  1.581270
 [57,] -1.0332541  1.198747
 [58,]  0.4779869 -0.211245
 [59,]  0.1515926 -0.556527
 [60,]  0.2168257 -0.516144
 [61,]  0.3327866 -0.409054
 [62,] -0.2919811 -0.451891
 [63,] -0.1721822 -0.545325
 [64,] -0.6576853  0.131664
 [65,] -0.6953825  0.217369
 [66,]  0.2788709 -0.464467
 [67,]  0.3813606 -0.350767
 [68,]  0.1014037 -0.577862
 [69,]  0.7171751  0.269094
 [70,]  1.5161019  3.267086
 [71,] -0.2839819 -0.459633
 [72,] -1.5719200  3.556711
 [73,]  0.7763046  0.417477
 [74,] -0.4385295 -0.272009
 [75,] -0.4235174 -0.293754
 [76,]  0.7903539  0.454461
 [77,] -0.1378721 -0.563200
 [78,] -0.8008795  0.482603
 [79,]  0.1922887 -0.533012
 [80,] -0.0345320 -0.593136
 [81,]  0.0679396 -0.587384
 [82,]  0.3367825 -0.404559
 [83,] -0.1987130 -0.528791
 [84,]  0.5203219 -0.140230
 [85,] -0.0923326 -0.580815
 [86,]  0.2988851 -0.445037
 [87,]  0.8408387  0.592832
 [88,]  0.3721316 -0.362452
 [89,] -0.1670281 -0.548263
 [90,]  0.8776524  0.699133
 [91,]  0.7676378  0.394993
 [92,]  0.4523315 -0.251349
 [93,]  0.2329699 -0.503943
 [94,] -0.3809418 -0.351304
 [95,]  1.0277197  1.179582
 [96,] -0.3613574 -0.375731
 [97,]  1.6133263  3.778321
 [98,]  1.1495320  1.625218
 [99,] -0.1031098 -0.577276
[100,] -0.6632430  0.143999

> nObs( mlNmInEqInd )
[1] 100
> 
> # with unused analytical gradients
> mlgNmInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "NM" )
> all.equal( mlNmInEq, mlgNmInEq )
[1] "Component 4: Mean relative difference: 0.00032168"
> 
> # with unused analytical gradients and Hessians
> mlghNmInEq <- maxLik( llf, gf, hf, start = startVal, constraints = inEq,
+    method = "NM" )
> all.equal( mlgNmInEq, mlghNmInEq )
[1] TRUE
> 
> ## SANN method with inequality constraints
> mlSannInEq <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "SANN" )
> print( mlSannInEq )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.54 (2 free parameter(s))
Estimate(s): 0.82965 1.6702 
> summary( mlSannInEq )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.54 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.830      0.173     4.8 1.6e-06 ***
sigma    1.670      0.106    15.8 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0010429 
--------------------------------------------
> activePar( mlSannInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSannInEq )
[1] 413.08
> coef( mlSannInEq )
     mu   sigma 
0.82965 1.67017 
> condiNumber( mlSannInEq )
mu 	 1 
sigma 	 3.6012 
> hessian( mlSannInEq )
           mu   sigma
mu    -35.840 -15.064
sigma -15.064 -96.122
> logLik( mlSannInEq )
[1] -204.54
> maximType( mlSannInEq )
[1] "SANN maximisation"
> nIter( mlSannInEq )
function 
   10000 
> nParam( mlSannInEq )
[1] 2
> returnCode( mlSannInEq )
[1] 0
> returnMessage( mlSannInEq )
[1] "successful convergence "
> vcov( mlSannInEq )
              mu      sigma
mu     0.0298693 -0.0046809
sigma -0.0046809  0.0111370
> logLik( summary( mlSannInEq ) )
[1] -204.54
> all.equal( mlBfgsInEq, mlSannInEq )
[1] "Component 1: Mean relative difference: 3.5212e-05"           
[2] "Component 2: Mean relative difference: 0.0080159"            
[3] "Component 3: Mean relative difference: 0.039456"             
[4] "Component 4: Mean relative difference: 0.019765"             
[5] "Component 9: Mean relative difference: 75.923"               
[6] "Component 10: 1 string mismatch"                             
[7] "Component 11: Component 2: Mean relative difference: 0.28103"
> 
> # with unused analytical gradients
> mlgSannInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "SANN" )
> all.equal( mlSannInEq, mlgSannInEq )
[1] "Component 4: Mean relative difference: 0.00020137"
> 
> # with a user-specified function to generate a new candidate point
> mlSannInEqCand <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "SANN", cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
> summary( mlSannInEqCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.61 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.812      0.175    4.65 3.4e-06 ***
sigma    1.682      0.108   15.65 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.00051626 
--------------------------------------------
> all.equal( mlSannInEqCand, mlSannInEq )
[1] "Component 1: Mean relative difference: 0.00034901"        
[2] "Component 2: Mean relative difference: 0.012165"          
[3] "Component 3: Mean relative difference: 0.051956"          
[4] "Component 4: Mean relative difference: 0.026157"          
[5] "Component 11: Component 2: Mean relative difference: 1.02"
> 
> ############### equality constraints ###############
> eqCon <- list( eqA = A, eqB = 2.5 )
> 
> ## NR method with equality constraints
> mlCon <- maxLik( llf, start = startVal, constraints = eqCon )
> print( mlCon )
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.81975 1.6803 
> summary( mlCon )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.0699e-10 
--------------------------------------------
> activePar( mlCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlCon )
[1] 413.07
> coef( mlCon )
     mu   sigma 
0.81975 1.68026 
> condiNumber( mlCon )
mu 	 1 
sigma 	 3.6139 
> hessian( mlCon )
           mu   sigma
mu    -35.442 -15.262
sigma -15.262 -93.706
> logLik( mlCon )
[1] -204.53
> maximType( mlCon )
[1] "Newton-Raphson maximisation"
> nIter( mlCon )
[1] 2
> nParam( mlCon )
[1] 2
> returnCode( mlCon )
[1] 1
> returnMessage( mlCon )
[1] "gradient close to zero"
> vcov( mlCon )
              mu      sigma
mu     0.0303435 -0.0049422
sigma -0.0049422  0.0114766
> logLik( summary( mlCon ) )
[1] -204.53
> mlConInd <- maxLik( llfInd, start = startVal, constraints = eqCon )
> summary( mlConInd )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.0699e-10 
--------------------------------------------
> all.equal( mlCon[], mlConInd[-11] )
[1] "Component 4: Mean relative difference: 0.0018622"
> mlConInd[11]
$gradientObs
               mu     sigma
  [1,] -0.3331935 -0.408605
  [2,] -0.0992123 -0.578605
  [3,]  1.1680233  1.697204
  [4,]  0.1137917 -0.573387
  [5,]  0.1554306 -0.554551
  [6,]  1.2787854  2.152579
  [7,]  0.3903542 -0.339112
  [8,] -0.8323176  0.568863
  [9,] -0.4227183 -0.294897
 [10,] -0.2518602 -0.488559
 [11,]  0.9309760  0.861168
 [12,]  0.3187339 -0.424444
 [13,]  0.3477480 -0.391952
 [14,]  0.1422509 -0.561144
 [15,] -0.3299104 -0.412263
 [16,]  1.3296822  2.375655
 [17,]  0.4165182 -0.303640
 [18,] -1.3292954  2.373927
 [19,]  0.5606802 -0.066933
 [20,] -0.2710785 -0.471673
 [21,] -0.6925957  0.210860
 [22,] -0.0905681 -0.581362
 [23,] -0.6629712  0.143384
 [24,] -0.4524981 -0.251103
 [25,] -0.3789300 -0.353879
 [26,] -1.1309991  1.554181
 [27,]  0.6573271  0.130862
 [28,]  0.1724926 -0.545150
 [29,] -0.7424052  0.330959
 [30,]  0.9520387  0.927810
 [31,]  0.3659486 -0.370126
 [32,] -0.1451828 -0.559728
 [33,]  0.6979455  0.223359
 [34,]  0.6859083  0.195370
 [35,]  0.6458469  0.105725
 [36,]  0.5516725 -0.083769
 [37,]  0.4562358 -0.245396
 [38,]  0.0199861 -0.594473
 [39,] -0.1528981 -0.555864
 [40,] -0.2056793 -0.524063
 [41,] -0.4282821 -0.286941
 [42,] -0.0834433 -0.583445
 [43,] -0.8325550  0.569527
 [44,]  1.6003190  3.708048
 [45,]  0.9195568  0.825661
 [46,] -0.7317592  0.304589
 [47,] -0.2215571 -0.512664
 [48,] -0.2667318 -0.475601
 [49,]  0.6163664  0.043201
 [50,]  0.0047859 -0.595106
 [51,]  0.2432933 -0.495687
 [52,]  0.0436216 -0.591947
 [53,]  0.0334748 -0.593262
 [54,]  1.0333534  1.199074
 [55,] -0.0960908 -0.579630
 [56,]  1.1381024  1.581263
 [57,] -1.0332829  1.198829
 [58,]  0.4779807 -0.211262
 [59,]  0.1515816 -0.556537
 [60,]  0.2168157 -0.516157
 [61,]  0.3327782 -0.409070
 [62,] -0.2919988 -0.451880
 [63,] -0.1721981 -0.545321
 [64,] -0.6577085  0.131705
 [65,] -0.6954063  0.217414
 [66,]  0.2788618 -0.464481
 [67,]  0.3813530 -0.350783
 [68,]  0.1013919 -0.577871
 [69,]  0.7171726  0.269077
 [70,]  1.5161113  3.267100
 [71,] -0.2839995 -0.459622
 [72,] -1.5719570  3.556871
 [73,]  0.7763029  0.417461
 [74,] -0.4385494 -0.271987
 [75,] -0.4235371 -0.293732
 [76,]  0.7903524  0.454444
 [77,] -0.1378874 -0.563198
 [78,] -0.8009049  0.482659
 [79,]  0.1922782 -0.533024
 [80,] -0.0345458 -0.593139
 [81,]  0.0679273 -0.587392
 [82,]  0.3367742 -0.404574
 [83,] -0.1987293 -0.528785
 [84,]  0.5203163 -0.140248
 [85,] -0.0923473 -0.580815
 [86,]  0.2988763 -0.445051
 [87,]  0.8408380  0.592817
 [88,]  0.3721239 -0.362468
 [89,] -0.1670439 -0.548259
 [90,]  0.8776522  0.699118
 [91,]  0.7676360  0.394977
 [92,]  0.4523250 -0.251366
 [93,]  0.2329601 -0.503956
 [94,] -0.3809608 -0.351286
 [95,]  1.0277218  1.179571
 [96,] -0.3613762 -0.375714
 [97,]  1.6133371  3.778343
 [98,]  1.1495359  1.625212
 [99,] -0.1031247 -0.577275
[100,] -0.6632662  0.144041

> nObs( mlConInd )
[1] 100
> 
> # with analytical gradients
> mlgCon <- maxLik( llf, gf, start = startVal, constraints = eqCon )
> summary( mlgCon )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 1 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.46 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.842      0.172    4.88   1e-06 ***
sigma    1.670      0.105   15.84  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
7  outer iterations, barrier value 0.00012989 
--------------------------------------------
> all.equal( mlCon[ -c( 5, 6, 7, 9 ) ], mlgCon[ -c( 5, 6, 7, 9 ) ] )
[1] "Component 1: Mean relative difference: 0.00037966"             
[2] "Component 2: Mean relative difference: 0.012956"               
[3] "Component 3: Mean relative difference: 0.050559"               
[4] "Component 4: Mean relative difference: 0.025143"               
[5] "Component 7: Component 2: Mean absolute difference: 0.00012989"
[6] "Component 7: Component 3: Mean relative difference: 1"         
[7] "Component 7: Component 4: 1 string mismatch"                   
[8] "Component 7: Component 5: Mean relative difference: 0.3"       
> mlgConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon )
> all.equal( mlConInd, mlgConInd )
 [1] "Component 1: Mean relative difference: 0.00037966"              
 [2] "Component 2: Mean relative difference: 0.012956"                
 [3] "Component 3: Mean relative difference: 0.050559"                
 [4] "Component 4: Mean relative difference: 0.024796"                
 [5] "Component 5: Mean relative difference: 2"                       
 [6] "Component 6: 1 string mismatch"                                 
 [7] "Component 7: target is NULL, current is list"                   
 [8] "Component 9: Mean relative difference: 0.5"                     
 [9] "Component 11: Mean relative difference: 0.01789"                
[10] "Component 12: Component 2: Mean absolute difference: 0.00012989"
[11] "Component 12: Component 3: Mean relative difference: 1"         
[12] "Component 12: Component 4: 1 string mismatch"                   
[13] "Component 12: Component 5: Mean relative difference: 0.3"       
> all.equal( mlgCon[], mlgConInd[-11] )
[1] TRUE
> mlgConInd[11]
$gradientObs
               mu     sigma
  [1,] -0.3452491 -0.399858
  [2,] -0.1083147 -0.579299
  [3,]  1.1749153  1.706092
  [4,]  0.1073777 -0.579636
  [5,]  0.1495422 -0.561548
  [6,]  1.2870754  2.167174
  [7,]  0.3874308 -0.348253
  [8,] -0.8506728  0.609424
  [9,] -0.4359038 -0.281614
 [10,] -0.2628892 -0.483490
 [11,]  0.9348761  0.860470
 [12,]  0.3149066 -0.433305
 [13,]  0.3442869 -0.400966
 [14,]  0.1361962 -0.567915
 [15,] -0.3419246 -0.403673
 [16,]  1.3386145  2.393136
 [17,]  0.4139251 -0.312802
 [18,] -1.3539233  2.461962
 [19,]  0.5599066 -0.075426
 [20,] -0.2823501 -0.465773
 [21,] -0.7091875  0.240912
 [22,] -0.0995614 -0.582337
 [23,] -0.6791890  0.171368
 [24,] -0.4660594 -0.236198
 [25,] -0.3915628 -0.342878
 [26,] -1.1531241  1.621384
 [27,]  0.6577734  0.123560
 [28,]  0.1668195 -0.552421
 [29,] -0.7596256  0.364615
 [30,]  0.9562047  0.927819
 [31,]  0.3627172 -0.379209
 [32,] -0.1548654 -0.558842
 [33,]  0.6989044  0.216735
 [34,]  0.6867153  0.188533
 [35,]  0.6461483  0.098249
 [36,]  0.5507852 -0.092343
 [37,]  0.4541440 -0.254506
 [38,]  0.0123882 -0.598632
 [39,] -0.1626780 -0.554700
 [40,] -0.2161255 -0.520894
 [41,] -0.4415379 -0.273359
 [42,] -0.0923467 -0.584649
 [43,] -0.8509132  0.610107
 [44,]  1.6126671  3.743649
 [45,]  0.9233128  0.824593
 [46,] -0.7488452  0.337461
 [47,] -0.2322037 -0.508857
 [48,] -0.2779485 -0.469891
 [49,]  0.6162957  0.035320
 [50,] -0.0030039 -0.598873
 [51,]  0.2385138 -0.503898
 [52,]  0.0363220 -0.596686
 [53,]  0.0260471 -0.597756
 [54,]  1.0385456  1.202076
 [55,] -0.1051538 -0.580425
 [56,]  1.1446167  1.588743
 [57,] -1.0541746  1.256689
 [58,]  0.4761634 -0.220301
 [59,]  0.1456446 -0.563469
 [60,]  0.2117020 -0.524054
 [61,]  0.3291282 -0.418011
 [62,] -0.3035345 -0.445048
 [63,] -0.1822216 -0.543445
 [64,] -0.6738599  0.159328
 [65,] -0.7120335  0.247666
 [66,]  0.2745313 -0.473043
 [67,]  0.3783161 -0.359907
 [68,]  0.0948214 -0.583875
 [69,]  0.7183741  0.262810
 [70,]  1.5273966  3.296562
 [71,] -0.2954341 -0.453150
 [72,] -1.5996475  3.673814
 [73,]  0.7782508  0.412442
 [74,] -0.4519348 -0.257848
 [75,] -0.4367329 -0.280406
 [76,]  0.7924776  0.449756
 [77,] -0.1474780 -0.562572
 [78,] -0.8188636  0.520749
 [79,]  0.1868549 -0.540589
 [80,] -0.0428320 -0.595825
 [81,]  0.0609345 -0.592689
 [82,]  0.3331746 -0.413536
 [83,] -0.2090877 -0.525890
 [84,]  0.5190333 -0.149062
 [85,] -0.1013631 -0.581733
 [86,]  0.2947984 -0.453776
 [87,]  0.8436004  0.589416
 [88,]  0.3689704 -0.371569
 [89,] -0.1770024 -0.546575
 [90,]  0.8808793  0.696759
 [91,]  0.7694745  0.389761
 [92,]  0.4501838 -0.260486
 [93,]  0.2280502 -0.512049
 [94,] -0.3936192 -0.340182
 [95,]  1.0328429  1.182352
 [96,] -0.3737875 -0.365594
 [97,]  1.6258496  3.814933
 [98,]  1.1561945  1.633223
 [99,] -0.1122764 -0.577839
[100,] -0.6794878  0.172046

> 
> # with analytical gradients as attribute
> mlGCon <- maxLik( llfGrad, start = startVal, constraints = eqCon )
> all.equal( mlGCon, mlgCon )
[1] TRUE
> all.equal( mlGCon, mlCon )
 [1] "Component 1: Mean relative difference: 0.00037981"             
 [2] "Component 2: Mean relative difference: 0.012898"               
 [3] "Component 3: Mean relative difference: 0.050468"               
 [4] "Component 4: Mean relative difference: 0.024948"               
 [5] "Component 5: Mean relative difference: 0.66667"                
 [6] "Component 6: 1 string mismatch"                                
 [7] "Component 7: Modes: list, NULL"                                
 [8] "Component 7: names for target but not for current"             
 [9] "Component 7: Length mismatch: comparison on first 0 components"
[10] "Component 9: Mean relative difference: 1"                      
[11] "Component 11: Component 2: Mean relative difference: 1"        
[12] "Component 11: Component 3: Mean relative difference: 0.5"      
[13] "Component 11: Component 4: 1 string mismatch"                  
[14] "Component 11: Component 5: Mean relative difference: 0.42857"  
> 
> # with analytical gradients and Hessians
> mlghCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon )
> all.equal( mlgCon, mlghCon )
[1] "Component 7: Component 2: Attributes: < Component 2: Attributes: < Length mismatch: comparison on first 1 components > >"
[2] "Component 11: Component 2: Mean relative difference: 2.305e-08"                                                          
> 
> # with analytical gradients and Hessians as attributes
> mlGHCon <- maxLik( llfGradHess, start = startVal, constraints = eqCon )
> all.equal( mlGHCon, mlghCon )
[1] TRUE
> all.equal( mlGHCon, mlCon )
 [1] "Component 1: Mean relative difference: 0.00037981"             
 [2] "Component 2: Mean relative difference: 0.012898"               
 [3] "Component 3: Mean relative difference: 0.050468"               
 [4] "Component 4: Mean relative difference: 0.024948"               
 [5] "Component 5: Mean relative difference: 0.66667"                
 [6] "Component 6: 1 string mismatch"                                
 [7] "Component 7: Modes: list, NULL"                                
 [8] "Component 7: names for target but not for current"             
 [9] "Component 7: Length mismatch: comparison on first 0 components"
[10] "Component 9: Mean relative difference: 1"                      
[11] "Component 11: Component 2: Mean relative difference: 1"        
[12] "Component 11: Component 3: Mean relative difference: 0.5"      
[13] "Component 11: Component 4: 1 string mismatch"                  
[14] "Component 11: Component 5: Mean relative difference: 0.42857"  
> 
> 
> ## BHHH method with equality constraints
> mlBhhhCon <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> print( mlBhhhCon )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.8199 1.6801 
> summary( mlBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.0845e-10 
--------------------------------------------
> activePar( mlBhhhCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBhhhCon )
[1] 413.07
> coef( mlBhhhCon )
    mu  sigma 
0.8199 1.6801 
> condiNumber( mlBhhhCon )
mu 	 1 
sigma 	 3.6148 
> hessian( mlBhhhCon )
           mu   sigma
mu    -35.413 -15.234
sigma -15.234 -93.763
> logLik( mlBhhhCon )
[1] -204.53
> maximType( mlBhhhCon )
[1] "BHHH maximisation"
> nIter( mlBhhhCon )
[1] 8
> nParam( mlBhhhCon )
[1] 2
> returnCode( mlBhhhCon )
[1] 2
> returnMessage( mlBhhhCon )
[1] "successive function values within tolerance limit"
> vcov( mlBhhhCon )
              mu      sigma
mu     0.0303598 -0.0049327
sigma -0.0049327  0.0114666
> logLik( summary( mlBhhhCon ) )
[1] -204.53
> all.equal( mlCon[ -c( 5, 6, 7, 9, 10 ) ], mlBhhhCon[ -c( 5, 6, 7, 9, 10, 11 ) ] )
[1] "Component 2: Mean relative difference: 0.00012229"
[2] "Component 3: Mean relative difference: 0.00058963"
[3] "Component 4: Mean relative difference: 0.00089"   
> mlBhhhCon[11]
$gradientObs
               mu     sigma
  [1,] -0.3333083 -0.408548
  [2,] -0.0992845 -0.578637
  [3,]  1.1681817  1.697563
  [4,]  0.1137582 -0.573456
  [5,]  0.1554047 -0.554623
  [6,]  1.2789639  2.153042
  [7,]  0.3903710 -0.339167
  [8,] -0.8325232  0.569278
  [9,] -0.4228494 -0.294792
 [10,] -0.2519602 -0.488538
 [11,]  0.9310912  0.861342
 [12,]  0.3187377 -0.424510
 [13,]  0.3477571 -0.392014
 [14,]  0.1422227 -0.561214
 [15,] -0.3300246 -0.412207
 [16,]  1.3298700  2.376170
 [17,]  0.4165398 -0.303690
 [18,] -1.3295915  2.374925
 [19,]  0.5607280 -0.066945
 [20,] -0.2711820 -0.471644
 [21,] -0.6927759  0.211152
 [22,] -0.0906387 -0.581396
 [23,] -0.6631460  0.143652
 [24,] -0.4526345 -0.250981
 [25,] -0.3790531 -0.353798
 [26,] -1.1312591  1.554919
 [27,]  0.6573926  0.130887
 [28,]  0.1724698 -0.545222
 [29,] -0.7425944  0.331293
 [30,]  0.9521578  0.927998
 [31,]  0.3659610 -0.370185
 [32,] -0.1452634 -0.559746
 [33,]  0.6980183  0.223401
 [34,]  0.6859789  0.195407
 [35,]  0.6459103  0.105744
 [36,]  0.5517187 -0.083784
 [37,]  0.4562647 -0.245437
 [38,]  0.0199356 -0.594531
 [39,] -0.1529801 -0.555879
 [40,] -0.2057709 -0.524060
 [41,] -0.4284142 -0.286833
 [42,] -0.0835127 -0.583481
 [43,] -0.8327606  0.569942
 [44,]  1.6005560  3.708877
 [45,]  0.9196699  0.825828
 [46,] -0.7319465  0.304914
 [47,] -0.2216516 -0.512656
 [48,] -0.2668345 -0.475574
 [49,]  0.6164244  0.043209
 [50,]  0.0047326 -0.595161
 [51,]  0.2432834 -0.495758
 [52,]  0.0435754 -0.592008
 [53,]  0.0334267 -0.593321
 [54,]  1.0334872  1.199322
 [55,] -0.0961624 -0.579662
 [56,]  1.1382553  1.581596
 [57,] -1.0335251  1.199453
 [58,]  0.4780136 -0.211298
 [59,]  0.1515550 -0.556608
 [60,]  0.2168009 -0.516229
 [61,]  0.3327846 -0.409134
 [62,] -0.2921061 -0.451841
 [63,] -0.1722836 -0.545330
 [64,] -0.6578823  0.131969
 [65,] -0.6955870  0.217709
 [66,]  0.2788584 -0.464550
 [67,]  0.3813682 -0.350840
 [68,]  0.1013561 -0.577939
 [69,]  0.7172489  0.269128
 [70,]  1.5163330  3.267824
 [71,] -0.2841053 -0.459587
 [72,] -1.5722971  3.558236
 [73,]  0.7763900  0.417541
 [74,] -0.4386834 -0.271873
 [75,] -0.4236683 -0.293627
 [76,]  0.7904420  0.454533
 [77,] -0.1379667 -0.563218
 [78,] -0.8011048  0.483045
 [79,]  0.1922591 -0.533096
 [80,] -0.0346062 -0.593186
 [81,]  0.0678855 -0.587456
 [82,]  0.3367814 -0.404638
 [83,] -0.1988196 -0.528785
 [84,]  0.5203569 -0.140273
 [85,] -0.0924183 -0.580849
 [86,]  0.2988765 -0.445119
 [87,]  0.8409368  0.592934
 [88,]  0.3721374 -0.362526
 [89,] -0.1671285 -0.548270
 [90,]  0.8777577  0.699258
 [91,]  0.7677215  0.395053
 [92,]  0.4523531 -0.251409
 [93,]  0.2329483 -0.504027
 [94,] -0.3810843 -0.351204
 [95,]  1.0278546  1.179814
 [96,] -0.3614961 -0.375643
 [97,]  1.6135765  3.779189
 [98,]  1.1496909  1.625554
 [99,] -0.1031976 -0.577306
[100,] -0.6634411  0.144309

> nObs( mlBhhhCon )
[1] 100
> 
> # with analytical gradients
> mlgBhhhCon <- maxLik( llf, gfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> summary( mlgBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 7 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.54 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.834      0.172    4.84 1.3e-06 ***
sigma    1.666      0.105   15.88 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.1783e-08 
--------------------------------------------
> all.equal( mlBhhhCon, mlgBhhhCon )
 [1] "Component 1: Mean relative difference: 4.5167e-05"       
 [2] "Component 2: Mean relative difference: 0.011213"         
 [3] "Component 3: Mean relative difference: 0.055164"         
 [4] "Component 4: Mean relative difference: 0.027743"         
 [5] "Component 5: Mean relative difference: 0.5"              
 [6] "Component 6: 1 string mismatch"                          
 [7] "Component 7: target is NULL, current is list"            
 [8] "Component 9: Mean relative difference: 0.125"            
 [9] "Component 11: Mean relative difference: 0.020157"        
[10] "Component 12: Component 5: Mean relative difference: 0.1"
> mlgBhhhConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlgBhhhCon, mlgBhhhConInd )
[1] TRUE
> 
> # with analytical gradients as attribute
> mlGBhhhCon <- maxLik( llfGradInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> summary( mlGBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 7 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.54 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.834      0.172    4.84 1.3e-06 ***
sigma    1.666      0.105   15.88 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.1783e-08 
--------------------------------------------
> all.equal( mlGBhhhCon, mlgBhhhCon )
[1] TRUE
> all.equal( mlGBhhhCon, mlBhhhCon )
 [1] "Component 1: Mean relative difference: 4.5165e-05"             
 [2] "Component 2: Mean relative difference: 0.011213"               
 [3] "Component 3: Mean relative difference: 0.053433"               
 [4] "Component 4: Mean relative difference: 0.02715"                
 [5] "Component 5: Mean relative difference: 0.33333"                
 [6] "Component 6: 1 string mismatch"                                
 [7] "Component 7: Modes: list, NULL"                                
 [8] "Component 7: names for target but not for current"             
 [9] "Component 7: Length mismatch: comparison on first 0 components"
[10] "Component 9: Mean relative difference: 0.14286"                
[11] "Component 11: Mean relative difference: 0.019806"              
[12] "Component 12: Component 5: Mean relative difference: 0.11111"  
> 
> # with analytical gradients and unused Hessians
> mlghBhhhCon <- maxLik( llf, gfInd, hf, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlgBhhhCon, mlghBhhhCon )
[1] TRUE
> 
> # with analytical gradients and unused Hessians as attributes
> mlGHBhhhCon <- maxLik( llfGradHessInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlGHBhhhCon, mlghBhhhCon )
[1] TRUE
> all.equal( mlGHBhhhCon, mlGBhhhCon )
[1] TRUE
> 
> 
> ## BFGS method with equality constraints
> mlBfgsCon <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> print( mlBfgsCon )
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.81975 1.6803 
> summary( mlBfgsCon )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> activePar( mlBfgsCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBfgsCon )
[1] 413.07
> coef( mlBfgsCon )
     mu   sigma 
0.81975 1.68026 
> condiNumber( mlBfgsCon )
mu 	 1 
sigma 	 3.6092 
> hessian( mlBfgsCon )
           mu   sigma
mu    -35.413 -15.206
sigma -15.206 -93.650
> logLik( mlBfgsCon )
[1] -204.53
> maximType( mlBfgsCon )
[1] "BFGS maximisation"
> nIter( mlBfgsCon )
function 
      31 
> nParam( mlBfgsCon )
[1] 2
> returnCode( mlBfgsCon )
[1] 0
> returnMessage( mlBfgsCon )
[1] "successful convergence "
> vcov( mlBfgsCon )
              mu      sigma
mu     0.0303540 -0.0049285
sigma -0.0049285  0.0114783
> logLik( summary( mlBfgsCon ) )
[1] -204.53
> all.equal( mlBfgsCon[ -c( 5, 6, 9, 10 ) ], mlCon[ -c( 5, 6, 9, 10 ) ] )
[1] "Component 4: Mean relative difference: 0.0012475"
> mlBfgsConInd <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> summary( mlBfgsConInd )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> all.equal( mlBfgsCon[], mlBfgsConInd[-12] )
[1] "Component 4: Mean relative difference: 0.00068729"
> mlBfgsConInd[12]
$gradientObs
               mu     sigma
  [1,] -0.3331935 -0.408605
  [2,] -0.0992123 -0.578605
  [3,]  1.1680233  1.697204
  [4,]  0.1137917 -0.573387
  [5,]  0.1554306 -0.554551
  [6,]  1.2787854  2.152579
  [7,]  0.3903542 -0.339112
  [8,] -0.8323176  0.568863
  [9,] -0.4227183 -0.294897
 [10,] -0.2518602 -0.488559
 [11,]  0.9309760  0.861168
 [12,]  0.3187339 -0.424444
 [13,]  0.3477480 -0.391952
 [14,]  0.1422509 -0.561144
 [15,] -0.3299104 -0.412263
 [16,]  1.3296822  2.375655
 [17,]  0.4165182 -0.303640
 [18,] -1.3292954  2.373927
 [19,]  0.5606802 -0.066933
 [20,] -0.2710785 -0.471673
 [21,] -0.6925957  0.210860
 [22,] -0.0905681 -0.581362
 [23,] -0.6629712  0.143384
 [24,] -0.4524981 -0.251103
 [25,] -0.3789300 -0.353879
 [26,] -1.1309991  1.554181
 [27,]  0.6573271  0.130862
 [28,]  0.1724926 -0.545150
 [29,] -0.7424052  0.330959
 [30,]  0.9520387  0.927810
 [31,]  0.3659486 -0.370126
 [32,] -0.1451828 -0.559728
 [33,]  0.6979455  0.223359
 [34,]  0.6859083  0.195370
 [35,]  0.6458469  0.105725
 [36,]  0.5516725 -0.083769
 [37,]  0.4562358 -0.245396
 [38,]  0.0199861 -0.594473
 [39,] -0.1528981 -0.555864
 [40,] -0.2056793 -0.524063
 [41,] -0.4282821 -0.286941
 [42,] -0.0834433 -0.583445
 [43,] -0.8325550  0.569527
 [44,]  1.6003190  3.708048
 [45,]  0.9195568  0.825661
 [46,] -0.7317592  0.304589
 [47,] -0.2215571 -0.512664
 [48,] -0.2667318 -0.475601
 [49,]  0.6163665  0.043201
 [50,]  0.0047859 -0.595106
 [51,]  0.2432933 -0.495687
 [52,]  0.0436216 -0.591947
 [53,]  0.0334748 -0.593262
 [54,]  1.0333534  1.199074
 [55,] -0.0960908 -0.579630
 [56,]  1.1381024  1.581263
 [57,] -1.0332829  1.198829
 [58,]  0.4779807 -0.211262
 [59,]  0.1515816 -0.556537
 [60,]  0.2168157 -0.516157
 [61,]  0.3327782 -0.409070
 [62,] -0.2919988 -0.451880
 [63,] -0.1721981 -0.545321
 [64,] -0.6577085  0.131705
 [65,] -0.6954063  0.217414
 [66,]  0.2788618 -0.464481
 [67,]  0.3813530 -0.350783
 [68,]  0.1013919 -0.577871
 [69,]  0.7171726  0.269077
 [70,]  1.5161113  3.267100
 [71,] -0.2839995 -0.459622
 [72,] -1.5719570  3.556871
 [73,]  0.7763029  0.417461
 [74,] -0.4385494 -0.271987
 [75,] -0.4235371 -0.293732
 [76,]  0.7903524  0.454444
 [77,] -0.1378875 -0.563198
 [78,] -0.8009049  0.482659
 [79,]  0.1922782 -0.533024
 [80,] -0.0345458 -0.593139
 [81,]  0.0679273 -0.587392
 [82,]  0.3367742 -0.404574
 [83,] -0.1987293 -0.528785
 [84,]  0.5203163 -0.140248
 [85,] -0.0923473 -0.580815
 [86,]  0.2988763 -0.445051
 [87,]  0.8408380  0.592817
 [88,]  0.3721239 -0.362468
 [89,] -0.1670439 -0.548259
 [90,]  0.8776522  0.699118
 [91,]  0.7676360  0.394977
 [92,]  0.4523250 -0.251366
 [93,]  0.2329601 -0.503956
 [94,] -0.3809608 -0.351286
 [95,]  1.0277218  1.179571
 [96,] -0.3613762 -0.375714
 [97,]  1.6133371  3.778343
 [98,]  1.1495359  1.625212
 [99,] -0.1031247 -0.577275
[100,] -0.6632662  0.144041

> nObs( mlBfgsConInd )
[1] 100
> 
> # with analytical gradients
> mlgBfgsCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> summary( mlgBfgsCon )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 30 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.85 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.814      0.173     4.7 2.7e-06 ***
sigma    1.670      0.106    15.8 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
7  outer iterations, barrier value 0.00024806 
--------------------------------------------
> all.equal( mlBfgsCon, mlgBfgsCon )
[1] "Component 1: Mean relative difference: 0.0015544"               
[2] "Component 2: Mean relative difference: 0.0063057"               
[3] "Component 3: Mean relative difference: 0.054634"                
[4] "Component 4: Mean relative difference: 0.027441"                
[5] "Component 9: Mean relative difference: 0.032258"                
[6] "Component 11: Component 2: Mean absolute difference: 0.00024806"
[7] "Component 11: Component 3: Mean relative difference: 1"         
[8] "Component 11: Component 4: 1 string mismatch"                   
[9] "Component 11: Component 5: Mean relative difference: 0.3"       
> mlgBfgsConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> all.equal( mlgBfgsCon[], mlgBfgsConInd[-12] )
[1] TRUE
> mlgBfgsConInd[12]
$gradientObs
               mu     sigma
  [1,] -0.3350917 -0.411137
  [2,] -0.0983143 -0.582545
  [3,]  1.1840655  1.743108
  [4,]  0.1172352 -0.575733
  [5,]  0.1593718 -0.556265
  [6,]  1.2961512  2.207450
  [7,]  0.3971028 -0.335297
  [8,] -0.8401805  0.580390
  [9,] -0.4256864 -0.296014
 [10,] -0.2527864 -0.491955
 [11,]  0.9441853  0.890371
 [12,]  0.3246266 -0.422668
 [13,]  0.3539874 -0.389388
 [14,]  0.1460346 -0.563069
 [15,] -0.3317694 -0.414837
 [16,]  1.3476563  2.434896
 [17,]  0.4235795 -0.299003
 [18,] -1.3430975  2.414407
 [19,]  0.5694643 -0.057025
 [20,] -0.2722344 -0.474900
 [21,] -0.6987889  0.216934
 [22,] -0.0895668 -0.585290
 [23,] -0.6688104  0.148453
 [24,] -0.4558220 -0.251643
 [25,] -0.3813747 -0.355749
 [26,] -1.1424315  1.581319
 [27,]  0.6672662  0.145007
 [28,]  0.1766376 -0.546575
 [29,] -0.7491936  0.338842
 [30,]  0.9654998  0.958359
 [31,]  0.3724056 -0.367041
 [32,] -0.1448342 -0.563652
 [33,]  0.7083700  0.239453
 [34,]  0.6961890  0.210876
 [35,]  0.6556488  0.119337
 [36,]  0.5603489 -0.074227
 [37,]  0.4637718 -0.239432
 [38,]  0.0223086 -0.597859
 [39,] -0.1526416 -0.559773
 [40,] -0.2060536 -0.527772
 [41,] -0.4313167 -0.287955
 [42,] -0.0823568 -0.587361
 [43,] -0.8404208  0.581064
 [44,]  1.6215273  3.793150
 [45,]  0.9326297  0.854145
 [46,] -0.7384204  0.312073
 [47,] -0.2221212 -0.516280
 [48,] -0.2678357 -0.478868
 [49,]  0.6258160  0.055481
 [50,]  0.0069267 -0.598610
 [51,]  0.2482844 -0.495723
 [52,]  0.0462266 -0.595121
 [53,]  0.0359585 -0.596530
 [54,]  1.0477862  1.235073
 [55,] -0.0951554 -0.583566
 [56,]  1.1537870  1.624872
 [57,] -1.0435475  1.220267
 [58,]  0.4857765 -0.204531
 [59,]  0.1554767 -0.558314
 [60,]  0.2214904 -0.516748
 [61,]  0.3388388 -0.406918
 [62,] -0.2934047 -0.454899
 [63,] -0.1721722 -0.549176
 [64,] -0.6634848  0.136602
 [65,] -0.7016331  0.223587
 [66,]  0.2842780 -0.463705
 [67,]  0.3879941 -0.347242
 [68,]  0.1046872 -0.580384
 [69,]  0.7278268  0.286128
 [70,]  1.5363133  3.343682
 [71,] -0.2853097 -0.462724
 [72,] -1.5886590  3.616910
 [73,]  0.7876638  0.437596
 [74,] -0.4417067 -0.272804
 [75,] -0.4265149 -0.294835
 [76,]  0.8018812  0.475344
 [77,] -0.1374516 -0.567133
 [78,] -0.8083924  0.492857
 [79,]  0.1966598 -0.534091
 [80,] -0.0328750 -0.596885
 [81,]  0.0708227 -0.590312
 [82,]  0.3428825 -0.402314
 [83,] -0.1990205 -0.532530
 [84,]  0.5286181 -0.131943
 [85,] -0.0913673 -0.584746
 [86,]  0.3045317 -0.443786
 [87,]  0.8529701  0.616560
 [88,]  0.3786546 -0.359202
 [89,] -0.1669565 -0.552131
 [90,]  0.8902243  0.725032
 [91,]  0.7788933  0.414647
 [92,]  0.4598142 -0.245537
 [93,]  0.2378277 -0.504214
 [94,] -0.3834298 -0.353123
 [95,]  1.0420873  1.215180
 [96,] -0.3636111 -0.377853
 [97,]  1.6347010  3.864801
 [98,]  1.1653571  1.669691
 [99,] -0.1022734 -0.581219
[100,] -0.6691089  0.149121

> 
> # with analytical gradients and unused Hessians
> mlghBfgsCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> all.equal( mlgBfgsCon, mlghBfgsCon )
[1] TRUE
> 
> ## NM method with equality constraints
> mlNmCon <- maxLik( llf, start = startVal, constraints = eqCon, method = "NM", SUMTTol=0)
> print( mlNmCon )
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.8197 1.6803 
> summary( mlNmCon )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.4176e-10 
--------------------------------------------
> activePar( mlNmCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNmCon )
[1] 413.07
> coef( mlNmCon )
    mu  sigma 
0.8197 1.6803 
> condiNumber( mlNmCon )
mu 	 1 
sigma 	 3.6092 
> hessian( mlNmCon )
           mu   sigma
mu    -35.413 -15.206
sigma -15.206 -93.650
> logLik( mlNmCon )
[1] -204.53
> maximType( mlNmCon )
[1] "Nelder-Mead maximisation"
> nIter( mlNmCon )
function 
      57 
> nParam( mlNmCon )
[1] 2
> returnCode( mlNmCon )
[1] 0
> returnMessage( mlNmCon )
[1] "successful convergence "
> vcov( mlNmCon )
              mu      sigma
mu     0.0303540 -0.0049285
sigma -0.0049285  0.0114783
> logLik( summary( mlNmCon ) )
[1] -204.53
> all.equal( mlNmCon[ -c( 5, 6, 9, 10 ) ], mlCon[ -c( 5, 6, 9, 10 ) ] )
[1] "Component 2: Mean relative difference: 4.2987e-05"
[2] "Component 3: Mean relative difference: 0.00020857"
[3] "Component 4: Mean relative difference: 0.0012475" 
> mlNmConInd <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> summary( mlNmConInd )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.4176e-10 
--------------------------------------------
> all.equal( mlNmCon[], mlNmConInd[-12] )
[1] "Component 4: Mean relative difference: 0.00091638"
> mlNmConInd[12]
$gradientObs
               mu     sigma
  [1,] -0.3331531 -0.408625
  [2,] -0.0991871 -0.578594
  [3,]  1.1679666  1.697075
  [4,]  0.1138032 -0.573363
  [5,]  0.1554394 -0.554526
  [6,]  1.2787216  2.152412
  [7,]  0.3903478 -0.339093
  [8,] -0.8322449  0.568717
  [9,] -0.4226722 -0.294933
 [10,] -0.2518251 -0.488566
 [11,]  0.9309346  0.861105
 [12,]  0.3187321 -0.424421
 [13,]  0.3477443 -0.391931
 [14,]  0.1422606 -0.561119
 [15,] -0.3298703 -0.412282
 [16,]  1.3296151  2.375470
 [17,]  0.4165101 -0.303622
 [18,] -1.3291907  2.373574
 [19,]  0.5606627 -0.066929
 [20,] -0.2710422 -0.471683
 [21,] -0.6925321  0.210757
 [22,] -0.0905434 -0.581350
 [23,] -0.6629095  0.143289
 [24,] -0.4524500 -0.251146
 [25,] -0.3788866 -0.353907
 [26,] -1.1309072  1.553920
 [27,]  0.6573035  0.130853
 [28,]  0.1725002 -0.545125
 [29,] -0.7423384  0.330842
 [30,]  0.9519960  0.927742
 [31,]  0.3659438 -0.370106
 [32,] -0.1451546 -0.559721
 [33,]  0.6979192  0.223343
 [34,]  0.6858828  0.195356
 [35,]  0.6458240  0.105717
 [36,]  0.5516556 -0.083764
 [37,]  0.4562252 -0.245381
 [38,]  0.0200036 -0.594453
 [39,] -0.1528694 -0.555858
 [40,] -0.2056472 -0.524063
 [41,] -0.4282356 -0.286979
 [42,] -0.0834191 -0.583432
 [43,] -0.8324823  0.569381
 [44,]  1.6002343  3.707751
 [45,]  0.9195162  0.825601
 [46,] -0.7316931  0.304475
 [47,] -0.2215240 -0.512667
 [48,] -0.2666957 -0.475610
 [49,]  0.6163454  0.043197
 [50,]  0.0048044 -0.595086
 [51,]  0.2432964 -0.495662
 [52,]  0.0436376 -0.591925
 [53,]  0.0334915 -0.593240
 [54,]  1.0333054  1.198985
 [55,] -0.0960657 -0.579618
 [56,]  1.1380476  1.581144
 [57,] -1.0331973  1.198609
 [58,]  0.4779687 -0.211250
 [59,]  0.1515906 -0.556512
 [60,]  0.2168205 -0.516132
 [61,]  0.3327756 -0.409047
 [62,] -0.2919611 -0.451893
 [63,] -0.1721681 -0.545317
 [64,] -0.6576472  0.131612
 [65,] -0.6953425  0.217311
 [66,]  0.2788626 -0.464456
 [67,]  0.3813472 -0.350764
 [68,]  0.1014041 -0.577847
 [69,]  0.7171450  0.269058
 [70,]  1.5160321  3.266841
 [71,] -0.2839623 -0.459633
 [72,] -1.5718365  3.556388
 [73,]  0.7762716  0.417431
 [74,] -0.4385023 -0.272026
 [75,] -0.4234909 -0.293769
 [76,]  0.7903201  0.454412
 [77,] -0.1378597 -0.563190
 [78,] -0.8008343  0.482523
 [79,]  0.1922846 -0.532998
 [80,] -0.0345247 -0.593122
 [81,]  0.0679417 -0.587369
 [82,]  0.3367713 -0.404552
 [83,] -0.1986976 -0.528785
 [84,]  0.5203015 -0.140240
 [85,] -0.0923225 -0.580803
 [86,]  0.2988758 -0.445028
 [87,]  0.8408024  0.592774
 [88,]  0.3721186 -0.362448
 [89,] -0.1670143 -0.548255
 [90,]  0.8776143  0.699068
 [91,]  0.7676052  0.394948
 [92,]  0.4523146 -0.251351
 [93,]  0.2329638 -0.503931
 [94,] -0.3809173 -0.351314
 [95,]  1.0276741  1.179483
 [96,] -0.3613340 -0.375739
 [97,]  1.6132517  3.778040
 [98,]  1.1494804  1.625089
 [99,] -0.1030992 -0.577264
[100,] -0.6632045  0.143947

> nObs( mlNmConInd )
[1] 100
> 
> # with unused analytical gradients
> mlgNmCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlNmCon, mlgNmCon )
[1] "Component 4: Mean relative difference: 0.00030725"
> mlgNmConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlgNmCon[], mlgNmConInd[-12] )
[1] TRUE
> mlgNmConInd[12]
$gradientObs
               mu     sigma
  [1,] -0.3331531 -0.408625
  [2,] -0.0991871 -0.578594
  [3,]  1.1679666  1.697075
  [4,]  0.1138032 -0.573363
  [5,]  0.1554394 -0.554526
  [6,]  1.2787216  2.152412
  [7,]  0.3903478 -0.339093
  [8,] -0.8322449  0.568717
  [9,] -0.4226722 -0.294933
 [10,] -0.2518251 -0.488566
 [11,]  0.9309346  0.861105
 [12,]  0.3187321 -0.424421
 [13,]  0.3477443 -0.391931
 [14,]  0.1422606 -0.561119
 [15,] -0.3298703 -0.412282
 [16,]  1.3296151  2.375470
 [17,]  0.4165101 -0.303622
 [18,] -1.3291907  2.373574
 [19,]  0.5606627 -0.066929
 [20,] -0.2710422 -0.471683
 [21,] -0.6925321  0.210757
 [22,] -0.0905434 -0.581350
 [23,] -0.6629095  0.143289
 [24,] -0.4524500 -0.251146
 [25,] -0.3788866 -0.353907
 [26,] -1.1309072  1.553920
 [27,]  0.6573035  0.130853
 [28,]  0.1725002 -0.545125
 [29,] -0.7423384  0.330842
 [30,]  0.9519960  0.927742
 [31,]  0.3659438 -0.370106
 [32,] -0.1451546 -0.559721
 [33,]  0.6979192  0.223343
 [34,]  0.6858828  0.195356
 [35,]  0.6458240  0.105717
 [36,]  0.5516556 -0.083764
 [37,]  0.4562252 -0.245381
 [38,]  0.0200036 -0.594453
 [39,] -0.1528694 -0.555858
 [40,] -0.2056472 -0.524063
 [41,] -0.4282356 -0.286979
 [42,] -0.0834191 -0.583432
 [43,] -0.8324823  0.569381
 [44,]  1.6002343  3.707751
 [45,]  0.9195162  0.825601
 [46,] -0.7316931  0.304475
 [47,] -0.2215240 -0.512667
 [48,] -0.2666957 -0.475610
 [49,]  0.6163454  0.043197
 [50,]  0.0048044 -0.595086
 [51,]  0.2432964 -0.495662
 [52,]  0.0436376 -0.591925
 [53,]  0.0334915 -0.593240
 [54,]  1.0333054  1.198985
 [55,] -0.0960657 -0.579618
 [56,]  1.1380476  1.581144
 [57,] -1.0331973  1.198609
 [58,]  0.4779687 -0.211250
 [59,]  0.1515906 -0.556512
 [60,]  0.2168205 -0.516132
 [61,]  0.3327756 -0.409047
 [62,] -0.2919611 -0.451893
 [63,] -0.1721681 -0.545317
 [64,] -0.6576472  0.131612
 [65,] -0.6953425  0.217311
 [66,]  0.2788626 -0.464456
 [67,]  0.3813472 -0.350764
 [68,]  0.1014041 -0.577847
 [69,]  0.7171450  0.269058
 [70,]  1.5160321  3.266841
 [71,] -0.2839623 -0.459633
 [72,] -1.5718365  3.556388
 [73,]  0.7762716  0.417431
 [74,] -0.4385023 -0.272026
 [75,] -0.4234909 -0.293769
 [76,]  0.7903201  0.454412
 [77,] -0.1378597 -0.563190
 [78,] -0.8008343  0.482523
 [79,]  0.1922846 -0.532998
 [80,] -0.0345247 -0.593122
 [81,]  0.0679417 -0.587369
 [82,]  0.3367713 -0.404552
 [83,] -0.1986976 -0.528785
 [84,]  0.5203015 -0.140240
 [85,] -0.0923225 -0.580803
 [86,]  0.2988758 -0.445028
 [87,]  0.8408024  0.592774
 [88,]  0.3721186 -0.362448
 [89,] -0.1670143 -0.548255
 [90,]  0.8776143  0.699068
 [91,]  0.7676052  0.394948
 [92,]  0.4523146 -0.251351
 [93,]  0.2329638 -0.503931
 [94,] -0.3809173 -0.351314
 [95,]  1.0276741  1.179483
 [96,] -0.3613340 -0.375739
 [97,]  1.6132517  3.778040
 [98,]  1.1494804  1.625089
 [99,] -0.1030992 -0.577264
[100,] -0.6632045  0.143947

> 
> # with unused analytical gradients and Hessians
> mlghNmCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlgNmCon, mlghNmCon )
[1] TRUE
> 
> ## SANN method with equality constraints
> mlSannCon <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "SANN", SUMTTol=0)
> print( mlSannCon )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 (2 free parameter(s))
Estimate(s): 0.81596 1.684 
> summary( mlSannCon )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.53 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.816      0.175    4.67   3e-06 ***
sigma    1.684      0.108   15.63  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.234e-09 
--------------------------------------------
> activePar( mlSannCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSannCon )
[1] 413.07
> coef( mlSannCon )
     mu   sigma 
0.81596 1.68401 
> condiNumber( mlSannCon )
mu 	 1 
sigma 	 3.6159 
> hessian( mlSannCon )
           mu   sigma
mu    -35.271 -15.291
sigma -15.291 -92.797
> logLik( mlSannCon )
[1] -204.53
> maximType( mlSannCon )
[1] "SANN maximisation"
> nIter( mlSannCon )
function 
   10000 
> nParam( mlSannCon )
[1] 2
> returnCode( mlSannCon )
[1] 0
> returnMessage( mlSannCon )
[1] "successful convergence "
> vcov( mlSannCon )
              mu      sigma
mu     0.0305327 -0.0050311
sigma -0.0050311  0.0116052
> logLik( summary( mlSannCon ) )
[1] -204.53
> all.equal( mlSannCon[ -c( 5, 6, 9, 10 ) ], mlBfgsCon[ -c( 5, 6, 9, 10 ) ] )
[1] "Component 1: Mean relative difference: 6.296e-06"           
[2] "Component 2: Mean relative difference: 0.0030133"           
[3] "Component 3: Mean relative difference: 0.014507"            
[4] "Component 4: Mean relative difference: 0.007345"            
[5] "Component 7: Component 5: Mean relative difference: 0.11111"
> 
> # with unused analytical gradients
> mlgSannCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "SANN", SUMTTol=0)
> all.equal( mlSannCon, mlgSannCon )
[1] "Component 4: Mean relative difference: 0.00024494"
> 
> # with a user-specified function to generate a new candidate point
> mlSannConCand <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "SANN", cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
Warning message:
In function (fn, grad = NULL, hess = NULL, start, maxRoutine, constraints,  :
  problem in imposing equality constraints: the constraints are not satisfied (barrier value = 0.254780368286163). Try setting 'SUMTTol' to 0
> summary( mlSannConCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.59 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.183      0.182     6.5 8.2e-11 ***
sigma    1.822      0.129    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
2  outer iterations, barrier value 0.25478 
--------------------------------------------
> all.equal( mlSannConCand, mlSannCon )
[1] "Component 1: Mean relative difference: 0.014627"         
[2] "Component 2: Mean relative difference: 0.168"            
[3] "Component 3: Mean relative difference: 68.17"            
[4] "Component 4: Mean relative difference: 0.76467"          
[5] "Component 11: Component 2: Mean relative difference: 1"  
[6] "Component 11: Component 3: Mean relative difference: 0.5"
[7] "Component 11: Component 4: 1 string mismatch"            
[8] "Component 11: Component 5: Mean relative difference: 3.5"
> 
> 
> ## test for method "estfun"
> library( sandwich )
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date

> try( estfun( ml ) )
Error in estfun.maxLik(ml) : 
  cannot return the gradients of the log-likelihood function evaluated at each observation: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> estfun( mlInd )[ 1:5, ]
            mu    sigma
[1,] -0.394521 -0.26779
[2,] -0.194316 -0.48193
[3,]  0.889988  0.88828
[4,] -0.012061 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlgInd )[ 1:5, ]
            mu    sigma
[1,] -0.394521 -0.26779
[2,] -0.194316 -0.48193
[3,]  0.889988  0.88828
[4,] -0.012061 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlBHHH )[ 1:5, ]
            mu    sigma
[1,] -0.394522 -0.26779
[2,] -0.194317 -0.48193
[3,]  0.889988  0.88828
[4,] -0.012061 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlgBHHH )[ 1:5, ]
            mu    sigma
[1,] -0.394522 -0.26779
[2,] -0.194317 -0.48193
[3,]  0.889988  0.88828
[4,] -0.012061 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlIndBFGS )[ 1:5, ]
            mu    sigma
[1,] -0.394521 -0.26779
[2,] -0.194316 -0.48193
[3,]  0.889987  0.88828
[4,] -0.012060 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlgIndBFGS )[ 1:5, ]
            mu    sigma
[1,] -0.394521 -0.26779
[2,] -0.194316 -0.48193
[3,]  0.889987  0.88828
[4,] -0.012060 -0.55025
[5,]  0.023568 -0.54951
> estfun( mlIndNM )[ 1:5, ]
            mu    sigma
[1,] -0.394392 -0.26790
[2,] -0.194221 -0.48194
[3,]  0.889897  0.88816
[4,] -0.011997 -0.55021
[5,]  0.023625 -0.54945
> estfun( mlgIndNM )[ 1:5, ]
            mu    sigma
[1,] -0.394392 -0.26790
[2,] -0.194221 -0.48194
[3,]  0.889897  0.88816
[4,] -0.011997 -0.55021
[5,]  0.023625 -0.54945
> estfun( mlIndSANN )[ 1:5, ]
            mu    sigma
[1,] -0.394797 -0.26737
[2,] -0.194601 -0.48171
[3,]  0.889657  0.88725
[4,] -0.012353 -0.55023
[5,]  0.023274 -0.54952
> estfun( mlgIndSANN )[ 1:5, ]
            mu    sigma
[1,] -0.394797 -0.26737
[2,] -0.194601 -0.48171
[3,]  0.889657  0.88725
[4,] -0.012353 -0.55023
[5,]  0.023274 -0.54952
> estfun( mlIndFix )[ 1:5, ]
     mu    sigma
[1,] NA -0.34124
[2,] NA -0.51297
[3,] NA  1.04982
[4,] NA -0.54454
[5,] NA -0.53682
> estfun( mlgIndFix )[ 1:5, ]
     mu    sigma
[1,] NA -0.34124
[2,] NA -0.51297
[3,] NA  1.04982
[4,] NA -0.54454
[5,] NA -0.53682
> estfun( mlFixBHHH )[ 1:5, ]
     mu    sigma
[1,] NA -0.34124
[2,] NA -0.51297
[3,] NA  1.04982
[4,] NA -0.54454
[5,] NA -0.53682
> estfun( mlgFixBHHH )[ 1:5, ]
     mu    sigma
[1,] NA -0.34124
[2,] NA -0.51297
[3,] NA  1.04982
[4,] NA -0.54454
[5,] NA -0.53682
> estfun( mlIndFixBfgs )[ 1:5, ]
            mu    sigma
[1,] -0.336390 -0.34124
[2,] -0.138150 -0.51297
[3,]  0.935516  1.04982
[4,]  0.042318 -0.54454
[5,]  0.077597 -0.53682
> estfun( mlgIndFixBfgs )[ 1:5, ]
            mu    sigma
[1,] -0.336390 -0.34124
[2,] -0.138150 -0.51297
[3,]  0.935516  1.04982
[4,]  0.042318 -0.54454
[5,]  0.077597 -0.53682
> estfun( mlIndFixNm )[ 1:5, ]
            mu    sigma
[1,] -0.336415 -0.34124
[2,] -0.138160 -0.51298
[3,]  0.935585  1.04997
[4,]  0.042321 -0.54456
[5,]  0.077602 -0.53684
> estfun( mlgIndFixNm )[ 1:5, ]
            mu    sigma
[1,] -0.336415 -0.34124
[2,] -0.138160 -0.51298
[3,]  0.935585  1.04997
[4,]  0.042321 -0.54456
[5,]  0.077602 -0.53684
> estfun( mlIndFixSann )[ 1:5, ]
            mu    sigma
[1,] -0.336396 -0.34124
[2,] -0.138152 -0.51297
[3,]  0.935533  1.04985
[4,]  0.042319 -0.54454
[5,]  0.077598 -0.53682
> estfun( mlgIndFixSann )[ 1:5, ]
            mu    sigma
[1,] -0.336396 -0.34124
[2,] -0.138152 -0.51297
[3,]  0.935533  1.04985
[4,]  0.042319 -0.54454
[5,]  0.077598 -0.53682
> estfun( mlBfgsInEqInd )[ 1:5, ]
           mu    sigma
[1,] -0.33318 -0.40862
[2,] -0.09920 -0.57861
[3,]  1.16803  1.69723
[4,]  0.11380 -0.57338
[5,]  0.15544 -0.55454
> estfun( mlgBfgsInEqInd )[ 1:5, ]
           mu    sigma
[1,] -0.33318 -0.40862
[2,] -0.09920 -0.57861
[3,]  1.16803  1.69723
[4,]  0.11380 -0.57338
[5,]  0.15544 -0.55454
> estfun( mlNmInEqInd )[ 1:5, ]
            mu    sigma
[1,] -0.333175 -0.40862
[2,] -0.099198 -0.57861
[3,]  1.168019  1.69721
[4,]  0.113803 -0.57338
[5,]  0.155442 -0.55454
> estfun( mlConInd )[ 1:5, ]
            mu    sigma
[1,] -0.333193 -0.40861
[2,] -0.099212 -0.57861
[3,]  1.168023  1.69720
[4,]  0.113792 -0.57339
[5,]  0.155431 -0.55455
> estfun( mlgConInd )[ 1:5, ]
           mu    sigma
[1,] -0.34525 -0.39986
[2,] -0.10831 -0.57930
[3,]  1.17492  1.70609
[4,]  0.10738 -0.57964
[5,]  0.14954 -0.56155
> estfun( mlBhhhCon )[ 1:5, ]
            mu    sigma
[1,] -0.333308 -0.40855
[2,] -0.099285 -0.57864
[3,]  1.168182  1.69756
[4,]  0.113758 -0.57346
[5,]  0.155405 -0.55462
> estfun( mlgBhhhCon )[ 1:5, ]
           mu    sigma
[1,] -0.34399 -0.40304
[2,] -0.10602 -0.58146
[3,]  1.18279  1.73072
[4,]  0.11061 -0.57981
[5,]  0.15296 -0.56121
> estfun( mlBfgsConInd )[ 1:5, ]
            mu    sigma
[1,] -0.333193 -0.40861
[2,] -0.099212 -0.57861
[3,]  1.168023  1.69720
[4,]  0.113792 -0.57339
[5,]  0.155431 -0.55455
> estfun( mlgBfgsConInd )[ 1:5, ]
            mu    sigma
[1,] -0.335092 -0.41114
[2,] -0.098314 -0.58255
[3,]  1.184065  1.74311
[4,]  0.117235 -0.57573
[5,]  0.159372 -0.55627
> estfun( mlNmConInd )[ 1:5, ]
            mu    sigma
[1,] -0.333153 -0.40862
[2,] -0.099187 -0.57859
[3,]  1.167967  1.69707
[4,]  0.113803 -0.57336
[5,]  0.155439 -0.55453
> estfun( mlgNmConInd )[ 1:5, ]
            mu    sigma
[1,] -0.333153 -0.40862
[2,] -0.099187 -0.57859
[3,]  1.167967  1.69707
[4,]  0.113803 -0.57336
[5,]  0.155439 -0.55453
> 
> 
> ## test for method "bread"
> try( bread( ml ) )
Error in nObs.maxLik(x) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> bread( mlInd )
          mu  sigma
mu    3.3006 0.0000
sigma 0.0000 1.6488
> bread( mlgInd )
               mu       sigma
mu     3.2996e+00 -8.4565e-11
sigma -8.4565e-11  1.6498e+00
> bread( mlBHHH )
            mu    sigma
mu     3.30618 -0.10877
sigma -0.10877  1.79786
> bread( mlgBHHH )
            mu    sigma
mu     3.30618 -0.10877
sigma -0.10877  1.79786
> bread( mlIndBFGS )
          mu  sigma
mu    3.3006 0.0000
sigma 0.0000 1.6488
> bread( mlgIndBFGS )
               mu       sigma
mu     3.2996e+00 -2.2354e-06
sigma -2.2354e-06  1.6498e+00
> bread( mlIndNM )
              mu      sigma
mu     3.2975059 -0.0015467
sigma -0.0015467  1.6502996
> bread( mlgIndNM )
               mu       sigma
mu     3.30016691 -0.00037019
sigma -0.00037019  1.65050714
> bread( mlIndSANN )
          mu  sigma
mu    3.2975 0.0000
sigma 0.0000 1.6488
> bread( mlgIndSANN )
             mu     sigma
mu    3.2997434 0.0017539
sigma 0.0017539 1.6499756
> bread( mlIndFix )
      mu  sigma
mu     0 0.0000
sigma  0 1.6667
> bread( mlgIndFix )
      mu  sigma
mu     0 0.0000
sigma  0 1.6661
> bread( mlFixBHHH )
      mu  sigma
mu     0 0.0000
sigma  0 1.7863
> bread( mlgFixBHHH )
      mu  sigma
mu     0 0.0000
sigma  0 1.7863
> bread( mlIndFixBfgs )
      mu  sigma
mu     0 0.0000
sigma  0 1.6667
> bread( mlgIndFixBfgs )
      mu  sigma
mu     0 0.0000
sigma  0 1.6661
> bread( mlIndFixNm )
      mu  sigma
mu     0 0.0000
sigma  0 1.6651
> bread( mlgIndFixNm )
      mu  sigma
mu     0 0.0000
sigma  0 1.6658
> bread( mlIndFixSann )
      mu  sigma
mu     0 0.0000
sigma  0 1.6667
> bread( mlgIndFixSann )
      mu  sigma
mu     0 0.0000
sigma  0 1.6661
> bread( mlBfgsInEqInd )
            mu    sigma
mu     3.03533 -0.49269
sigma -0.49269  1.14746
> bread( mlgBfgsInEqInd )
           mu   sigma
mu     3.0353 -0.4933
sigma -0.4933  1.1477
> bread( mlNmInEqInd )
            mu    sigma
mu     3.03428 -0.49406
sigma -0.49406  1.14729
> bread( mlConInd )
            mu    sigma
mu     3.03350 -0.49316
sigma -0.49316  1.14734
> bread( mlgConInd )
            mu    sigma
mu     2.97149 -0.45143
sigma -0.45143  1.11119
> bread( mlBhhhCon )
            mu    sigma
mu     3.03598 -0.49327
sigma -0.49327  1.14666
> bread( mlgBhhhCon )
           mu   sigma
mu     2.9668 -0.4582
sigma -0.4582  1.1005
> bread( mlBfgsConInd )
            mu    sigma
mu     3.03618 -0.49375
sigma -0.49375  1.14778
> bread( mlgBfgsConInd )
            mu    sigma
mu     3.00532 -0.49028
sigma -0.49028  1.11608
> bread( mlNmConInd )
            mu    sigma
mu     3.03612 -0.49359
sigma -0.49359  1.14741
> bread( mlgNmConInd )
            mu    sigma
mu     3.03553 -0.49338
sigma -0.49338  1.14789
> 
> 
> ## test for method "sandwich"
> try( sandwich( ml ) )
Error in nObs.maxLik(x) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> printSandwich <- function( x ) {
+    print( sandwich( x ) )
+    print( all.equal( sandwich( x ), vcov( x ) ) )
+ }
> printSandwich( mlInd )
              mu      sigma
mu    0.03301594 0.00099779
sigma 0.00099779 0.01515020
[1] "Mean relative difference: 0.066642"
> printSandwich( mlgInd )
              mu      sigma
mu    0.03299602 0.00099812
sigma 0.00099812 0.01516948
[1] "Mean relative difference: 0.066281"
> printSandwich( mlBHHH )
              mu      sigma
mu     0.0330618 -0.0010877
sigma -0.0010877  0.0179786
[1] TRUE
> printSandwich( mlgBHHH )
              mu      sigma
mu     0.0330618 -0.0010877
sigma -0.0010877  0.0179786
[1] TRUE
> printSandwich( mlIndBFGS )
              mu      sigma
mu    0.03301589 0.00099781
sigma 0.00099781 0.01515017
[1] "Mean relative difference: 0.066642"
> printSandwich( mlgIndBFGS )
             mu     sigma
mu    0.0329960 0.0009981
sigma 0.0009981 0.0151695
[1] "Mean relative difference: 0.066282"
> printSandwich( mlIndNM )
              mu      sigma
mu    0.03294097 0.00097139
sigma 0.00097139 0.01517015
[1] "Mean relative difference: 0.066741"
> printSandwich( mlgIndNM )
              mu      sigma
mu    0.03299557 0.00099489
sigma 0.00099489 0.01517468
[1] "Mean relative difference: 0.066461"
> printSandwich( mlIndSANN )
              mu      sigma
mu    0.03295130 0.00097923
sigma 0.00097923 0.01514723
[1] "Mean relative difference: 0.066374"
> printSandwich( mlgIndSANN )
             mu     sigma
mu    0.0329982 0.0010143
sigma 0.0010143 0.0151708
[1] "Mean relative difference: 0.066203"
> printSandwich( mlIndFix )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlgIndFix )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlFixBHHH )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlgFixBHHH )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlIndFixBfgs )
      mu    sigma
mu     0 0.000000
sigma  0 0.015552
[1] "Mean relative difference: 0.071723"
> printSandwich( mlgIndFixBfgs )
      mu    sigma
mu     0 0.000000
sigma  0 0.015541
[1] "Mean relative difference: 0.072089"
> printSandwich( mlIndFixNm )
      mu    sigma
mu     0 0.000000
sigma  0 0.015526
[1] "Mean relative difference: 0.072503"
> printSandwich( mlgIndFixNm )
      mu    sigma
mu     0 0.000000
sigma  0 0.015539
[1] "Mean relative difference: 0.072049"
> printSandwich( mlIndFixSann )
      mu    sigma
mu     0 0.000000
sigma  0 0.015553
[1] "Mean relative difference: 0.071666"
> printSandwich( mlgIndFixSann )
      mu    sigma
mu     0 0.000000
sigma  0 0.015541
[1] "Mean relative difference: 0.072079"
> printSandwich( mlBfgsInEqInd )
              mu      sigma
mu     0.0354661 -0.0038744
sigma -0.0038744  0.0117841
[1] "Mean relative difference: 0.13686"
> printSandwich( mlgBfgsInEqInd )
              mu      sigma
mu     0.0354638 -0.0038875
sigma -0.0038875  0.0117891
[1] "Mean relative difference: 0.13654"
> printSandwich( mlNmInEqInd )
              mu      sigma
mu     0.0354355 -0.0039057
sigma -0.0039057  0.0117790
[1] "Mean relative difference: 0.13573"
> printSandwich( mlConInd )
              mu      sigma
mu     0.0354212 -0.0038865
sigma -0.0038865  0.0117814
[1] "Mean relative difference: 0.13614"
> printSandwich( mlgConInd )
              mu      sigma
mu     0.0350797 -0.0034838
sigma -0.0034838  0.0114958
[1] "Mean relative difference: 0.14586"
> printSandwich( mlBhhhCon )
              mu      sigma
mu     0.0354936 -0.0038929
sigma -0.0038929  0.0117736
[1] "Mean relative difference: 0.13661"
> printSandwich( mlgBhhhCon )
              mu      sigma
mu     0.0351842 -0.0035619
sigma -0.0035619  0.0114269
[1] "Mean relative difference: 0.14847"
> printSandwich( mlBfgsConInd )
              mu      sigma
mu     0.0354834 -0.0038978
sigma -0.0038978  0.0117901
[1] "Mean relative difference: 0.13643"
> printSandwich( mlgBfgsConInd )
              mu      sigma
mu     0.0355211 -0.0038822
sigma -0.0038822  0.0115646
[1] "Mean relative difference: 0.14426"
> printSandwich( mlNmConInd )
              mu      sigma
mu     0.0354776 -0.0038935
sigma -0.0038935  0.0117801
[1] "Mean relative difference: 0.13638"
> printSandwich( mlgNmConInd )
              mu      sigma
mu     0.0354644 -0.0038883
sigma -0.0038883  0.0117903
[1] "Mean relative difference: 0.1365"
> 
