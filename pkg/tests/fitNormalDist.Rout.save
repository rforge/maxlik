
R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # load the 'maxLik' package
> library(maxLik)
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/
> options(digits = 4)
>                            # just to avoid so many differences when comparing these output files
> ## data to fit a normal distribution
> # set seed for pseudo random numbers
> set.seed( 123 )
> # generate a variable from normally distributed random numbers
> x <- rnorm( 100, 1, 2 )
> xSaved <- x
> 
> ## log likelihood function
> llf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    return( llValue )
+ }
> 
> ## log likelihood function (individual observations)
> llfInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    return( llValues )
+ }
> 
> ## function to calculate analytical gradients
> gf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    N <- length( x )
+    llGrad <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    return( llGrad )
+ }
> 
> ## function to calculate analytical gradients (individual observations)
> gfInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    llGrads <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    return( llGrads )
+ }
> 
> ## log likelihood function with gradients as attributes
> llfGrad <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    attributes( llValue )$gradient <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    return( llValue )
+ }
> 
> ## log likelihood function with gradients as attributes (individual observations)
> llfGradInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    attributes( llValues )$gradient <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    return( llValues )
+ }
> 
> ## function to calculate analytical Hessians
> hf <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    N <- length( x )
+    llHess <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llHess )
+ }
> 
> ## log likelihood function with gradients and Hessian as attributes
> llfGradHess <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
+       0.5 * sum( ( x - mu )^2 / sigma^2 )
+    attributes( llValue )$gradient <- c( sum( ( x - mu ) / sigma^2 ),
+       - N / sigma + sum( ( x - mu )^2 / sigma^3 ) )
+    attributes( llValue )$hessian <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llValue )
+ }
> 
> ## log likelihood function with gradients as attributes (individual observations)
> llfGradHessInd <- function( param ) {
+    mu <- param[ 1 ]
+    sigma <- param[ 2 ]
+    if(!(sigma > 0))
+        return(NA)
+                            # to avoid warnings in the output
+    N <- length( x )
+    llValues <- -0.5 * log( 2 * pi ) - log( sigma ) -
+       0.5 * ( x - mu )^2 / sigma^2
+    attributes( llValues )$gradient <- cbind( ( x - mu ) / sigma^2,
+       - 1 / sigma + ( x - mu )^2 / sigma^3 )
+    attributes( llValues )$hessian <- matrix( c(
+       N * ( - 1 / sigma^2 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       sum( - 2 * ( x - mu ) / sigma^3 ),
+       N / sigma^2 + sum( - 3 * ( x - mu )^2 / sigma^4 ) ),
+       nrow = 2, ncol = 2 )
+    return( llValues )
+ }
> 
> 
> # start values
> startVal <- c( mu = 0, sigma = 1 )
> 
> ## NR method
> ml <- maxLik( llf, start = startVal )
> print( ml )
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.181 1.816 
> summary( ml )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( ml )
   mu sigma 
 TRUE  TRUE 
> AIC( ml )
[1] 407.2
> coef( ml )
   mu sigma 
1.181 1.816 
> condiNumber( ml )
mu 	 1 
sigma 	 1.669 
> hessian( ml )
             mu     sigma
mu    -30.32596  -0.02842
sigma  -0.02842 -60.62351
> logLik( ml )
[1] -201.6
> maximType( ml )
[1] "Newton-Raphson maximisation"
> nIter( ml )
[1] 7
> try( nObs( ml ) )
Error in nObs.maxLik(ml) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> nParam( ml )
[1] 2
> returnCode( ml )
[1] 2
> returnMessage( ml )
[1] "successive function values within tolerance limit"
> vcov( ml )
              mu      sigma
mu     3.298e-02 -1.546e-05
sigma -1.546e-05  1.650e-02
> logLik( summary( ml ) )
[1] -201.6
> mlInd <- maxLik( llfInd, start = startVal )
> summary( mlInd )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( ml[-3], mlInd[ c(-3,-11) ], tolerance = 1e-3 )
[1] "Component 3: Mean relative difference: 0.001249"
[2] "Component 4: Mean relative difference: 0.5"     
[3] "Component 5: 1 string mismatch"                 
>                            # 3  gradient, should be close to 0, but may vary enormously in relative terms
> mlInd[[11]][sample(nrow(mlInd[[11]]), 10),]
            mu   sigma
 [1,] -0.49660 -0.1025
 [2,] -0.41864 -0.2322
 [3,]  0.02027 -0.5498
 [4,] -0.10533 -0.5304
 [5,] -0.24025 -0.4457
 [6,]  0.33578 -0.3457
 [7,]  0.44319 -0.1937
 [8,]  0.45301 -0.1777
 [9,]  1.02831  1.3703
[10,]  0.27760 -0.4105
>                            # just print a sample of 10
> nObs( mlInd )
[1] 100
> 
> # with analytical gradients
> mlg <- maxLik( llf, gf, start = startVal )
> summary( mlg )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( ml, mlg, tolerance = 1e-3 )
[1] "Component 5: Mean relative difference: 0.5"
[2] "Component 6: 1 string mismatch"            
> mlgInd <- maxLik( llfInd, gfInd, start = startVal )
> all.equal( mlInd, mlgInd, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlg[ ], mlgInd[ -11 ], tolerance = 1e-3 )
[1] TRUE
> mlgInd[ 11 ]
$gradientObs
             mu     sigma
  [1,] -0.39452 -0.267785
  [2,] -0.19432 -0.481927
  [3,]  0.88999  0.888279
  [4,] -0.01206 -0.550251
  [5,]  0.02357 -0.549506
  [6,]  0.98476  1.211023
  [7,]  0.22458 -0.458900
  [8,] -0.82159  0.675641
  [9,] -0.47112 -0.147335
 [10,] -0.32493 -0.358733
 [11,]  0.68716  0.307205
 [12,]  0.16330 -0.502077
 [13,]  0.18812 -0.486229
 [14,]  0.01229 -0.550241
 [15,] -0.39171 -0.271797
 [16,]  1.02831  1.370271
 [17,]  0.24697 -0.439724
 [18,] -1.24683  2.273363
 [19,]  0.37032 -0.301412
 [20,] -0.34137 -0.338831
 [21,] -0.70204  0.344761
 [22,] -0.18692 -0.487049
 [23,] -0.67669  0.281278
 [24,] -0.49660 -0.102543
 [25,] -0.43366 -0.208913
 [26,] -1.07716  1.557099
 [27,]  0.45301 -0.177736
 [28,]  0.03817 -0.547869
 [29,] -0.74466  0.456760
 [30,]  0.70518  0.352786
 [31,]  0.20370 -0.475145
 [32,] -0.23365 -0.451348
 [33,]  0.48777 -0.118343
 [34,]  0.47747 -0.136401
 [35,]  0.44319 -0.193727
 [36,]  0.36261 -0.311673
 [37,]  0.28095 -0.407135
 [38,] -0.09232 -0.535032
 [39,] -0.24025 -0.445666
 [40,] -0.28541 -0.402542
 [41,] -0.47588 -0.139146
 [42,] -0.18082 -0.491121
 [43,] -0.82180  0.676247
 [44,]  1.25988  2.332777
 [45,]  0.67739  0.282986
 [46,] -0.73555  0.432268
 [47,] -0.29900 -0.388120
 [48,] -0.33765 -0.343418
 [49,]  0.41797 -0.233185
 [50,] -0.10533 -0.530362
 [51,]  0.09875 -0.532803
 [52,] -0.07210 -0.541072
 [53,] -0.08078 -0.538661
 [54,]  0.77476  0.539827
 [55,] -0.19165 -0.483799
 [56,]  0.86439  0.806692
 [57,] -0.99355  1.242606
 [58,]  0.29956 -0.387515
 [59,]  0.02027 -0.549768
 [60,]  0.07609 -0.539998
 [61,]  0.17531 -0.494685
 [62,] -0.35927 -0.316049
 [63,] -0.25677 -0.430756
 [64,] -0.67219  0.270245
 [65,] -0.70445  0.350905
 [66,]  0.12918 -0.520202
 [67,]  0.21688 -0.465076
 [68,] -0.02267 -0.549582
 [69,]  0.50422 -0.088698
 [70,]  1.18783  2.012419
 [71,] -0.35243 -0.324897
 [72,] -1.45446  3.292183
 [73,]  0.55481  0.008631
 [74,] -0.48467 -0.123817
 [75,] -0.47182 -0.146135
 [76,]  0.56684  0.033124
 [77,] -0.22741 -0.456576
 [78,] -0.79472  0.596727
 [79,]  0.05510 -0.545001
 [80,] -0.13898 -0.515427
 [81,] -0.05130 -0.545734
 [82,]  0.17873 -0.492486
 [83,] -0.27947 -0.408644
 [84,]  0.33578 -0.345710
 [85,] -0.18844 -0.486011
 [86,]  0.14631 -0.511632
 [87,]  0.61003  0.125471
 [88,]  0.20898 -0.471184
 [89,] -0.25236 -0.434835
 [90,]  0.64153  0.197084
 [91,]  0.54740 -0.006216
 [92,]  0.27760 -0.410530
 [93,]  0.08991 -0.535833
 [94,] -0.43539 -0.206170
 [95,]  0.76994  0.526306
 [96,] -0.41864 -0.232166
 [97,]  1.27102  2.383986
 [98,]  0.87417  0.837587
 [99,] -0.19766 -0.479543
[100,] -0.67695  0.281899

> 
> # with analytical gradients as attribute
> mlG <- maxLik( llfGrad, start = startVal )
> all.equal( mlG, mlg, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlG$gradient, gf( coef( mlG ) ), check.attributes = FALSE,
+    tolerance = 1e-3 )
[1] TRUE
> mlGInd <- maxLik( llfGradInd, start = startVal )
> all.equal( mlGInd, mlgInd, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGInd$gradient, colSums( gfInd( coef( mlGInd ) ) ),
+    check.attributes = FALSE, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGInd$gradientObs, gfInd( coef( mlGInd ) ),
+    check.attributes = FALSE, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgG <- maxLik( llfGrad, gf, start = startVal )
Warning message:
In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgG, mlg, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgG, mlG, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessians
> mlgh <- maxLik( llf, gf, hf, start = startVal )
> all.equal( mlg, mlgh, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGH <- maxLik( llfGradHess, start = startVal )
> all.equal( mlGH, mlgh, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhH <- maxLik( llfGradHess, gf, hf, start = startVal )
Warning messages:
1: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhH, mlgh, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGhH, mlGH, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ## BHHH method
> mlBHHH <- try( maxLik( llf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  if the gradients (argument 'grad') are not provided by the user, the BHHH method requires that the log-likelihood function (argument 'fn') returns a numeric vector, where each element must be the log-likelihood value corresponding to an individual (independent) observation
> x <- xSaved[1]
> try( maxLik( llfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  if the gradients (argument 'grad') are not provided by the user, the BHHH method requires that the log-likelihood function (argument 'fn') returns a numeric vector, where each element must be the log-likelihood value corresponding to an individual (independent) observation
> x <- xSaved[1:2]
> try( maxLik( llfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.6227 (2 free parameter(s))
Estimate(s): 0.2158 0.3302 
> x <- xSaved
> mlBHHH <- maxLik( llfInd, start = startVal, method = "BHHH" )
> print( mlBHHH )
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.181 1.816 
> summary( mlBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182    6.49 8.4e-11 ***
sigma    1.816      0.134   13.55 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlBHHH )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBHHH )
[1] 407.2
> coef( mlBHHH )
   mu sigma 
1.181 1.816 
> condiNumber( mlBHHH )
mu 	 1 
sigma 	 1.719 
> hessian( mlBHHH )
           mu   sigma
mu    -30.307  -1.834
sigma  -1.834 -55.732
attr(,"type")
[1] "BHHH"
> logLik( mlBHHH )
[1] -201.6
> maximType( mlBHHH )
[1] "BHHH maximisation"
> nIter( mlBHHH )
[1] 13
> nParam( mlBHHH )
[1] 2
> returnCode( mlBHHH )
[1] 2
> returnMessage( mlBHHH )
[1] "successive function values within tolerance limit"
> vcov( mlBHHH )
             mu     sigma
mu     0.033062 -0.001088
sigma -0.001088  0.017979
> logLik( summary( mlBHHH ) )
[1] -201.6
> all.equal( ml[ ], mlBHHH[ -11 ], tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.09363"                                
[3] "Component 9: Mean relative difference: 0.8571"                                 
[4] "Component 10: 1 string mismatch"                                               
> mlBHHH[ 11 ]
$gradientObs
             mu     sigma
  [1,] -0.39452 -0.267785
  [2,] -0.19432 -0.481927
  [3,]  0.88999  0.888280
  [4,] -0.01206 -0.550251
  [5,]  0.02357 -0.549506
  [6,]  0.98476  1.211024
  [7,]  0.22458 -0.458900
  [8,] -0.82159  0.675642
  [9,] -0.47112 -0.147335
 [10,] -0.32493 -0.358733
 [11,]  0.68716  0.307205
 [12,]  0.16330 -0.502077
 [13,]  0.18812 -0.486229
 [14,]  0.01229 -0.550241
 [15,] -0.39171 -0.271797
 [16,]  1.02831  1.370272
 [17,]  0.24697 -0.439724
 [18,] -1.24683  2.273366
 [19,]  0.37032 -0.301412
 [20,] -0.34137 -0.338831
 [21,] -0.70204  0.344762
 [22,] -0.18692 -0.487049
 [23,] -0.67669  0.281279
 [24,] -0.49660 -0.102543
 [25,] -0.43366 -0.208913
 [26,] -1.07716  1.557100
 [27,]  0.45301 -0.177736
 [28,]  0.03817 -0.547869
 [29,] -0.74466  0.456761
 [30,]  0.70518  0.352786
 [31,]  0.20370 -0.475146
 [32,] -0.23365 -0.451348
 [33,]  0.48777 -0.118343
 [34,]  0.47747 -0.136401
 [35,]  0.44319 -0.193727
 [36,]  0.36261 -0.311673
 [37,]  0.28095 -0.407135
 [38,] -0.09232 -0.535032
 [39,] -0.24025 -0.445666
 [40,] -0.28541 -0.402542
 [41,] -0.47588 -0.139145
 [42,] -0.18082 -0.491121
 [43,] -0.82180  0.676248
 [44,]  1.25988  2.332779
 [45,]  0.67739  0.282987
 [46,] -0.73555  0.432269
 [47,] -0.29900 -0.388120
 [48,] -0.33765 -0.343418
 [49,]  0.41797 -0.233185
 [50,] -0.10533 -0.530362
 [51,]  0.09875 -0.532803
 [52,] -0.07210 -0.541072
 [53,] -0.08078 -0.538661
 [54,]  0.77476  0.539828
 [55,] -0.19165 -0.483799
 [56,]  0.86439  0.806693
 [57,] -0.99355  1.242608
 [58,]  0.29956 -0.387515
 [59,]  0.02027 -0.549769
 [60,]  0.07609 -0.539998
 [61,]  0.17531 -0.494686
 [62,] -0.35927 -0.316049
 [63,] -0.25677 -0.430756
 [64,] -0.67219  0.270245
 [65,] -0.70445  0.350906
 [66,]  0.12918 -0.520202
 [67,]  0.21688 -0.465076
 [68,] -0.02267 -0.549582
 [69,]  0.50422 -0.088698
 [70,]  1.18783  2.012421
 [71,] -0.35243 -0.324897
 [72,] -1.45446  3.292186
 [73,]  0.55481  0.008631
 [74,] -0.48467 -0.123817
 [75,] -0.47182 -0.146135
 [76,]  0.56684  0.033124
 [77,] -0.22741 -0.456576
 [78,] -0.79472  0.596728
 [79,]  0.05510 -0.545001
 [80,] -0.13898 -0.515427
 [81,] -0.05130 -0.545734
 [82,]  0.17873 -0.492487
 [83,] -0.27947 -0.408644
 [84,]  0.33578 -0.345710
 [85,] -0.18844 -0.486011
 [86,]  0.14631 -0.511633
 [87,]  0.61003  0.125471
 [88,]  0.20898 -0.471185
 [89,] -0.25236 -0.434835
 [90,]  0.64153  0.197084
 [91,]  0.54740 -0.006216
 [92,]  0.27760 -0.410530
 [93,]  0.08991 -0.535833
 [94,] -0.43539 -0.206170
 [95,]  0.76994  0.526307
 [96,] -0.41864 -0.232166
 [97,]  1.27102  2.383988
 [98,]  0.87417  0.837588
 [99,] -0.19766 -0.479543
[100,] -0.67695  0.281900

> nObs( mlBHHH )
[1] 100
> # final Hessian = usual Hessian
> mlBhhhH <- maxLik( llfInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlBhhhH, mlBHHH, tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.09431"                                
> hessian( mlBhhhH ) 
          mu  sigma
mu    -30.33   0.00
sigma   0.00 -60.62
> summary( mlBhhhH ) 
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> 
> # with analytical gradients
> mlgBHHH <- try( maxLik( llf, gf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> mlgBHHH <- try( maxLik( llfInd, gf, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> x <- xSaved[1]
> try( maxLik( llf, gfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> try( maxLik( llfInd, gfInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> x <- xSaved[1:2]
> try( maxLik( llf, gfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.6227 (2 free parameter(s))
Estimate(s): 0.2158 0.3302 
> try( maxLik( llfInd, gfInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.6227 (2 free parameter(s))
Estimate(s): 0.2158 0.3302 
> x <- xSaved
> mlgBHHH <- maxLik( llfInd, gfInd, start = startVal, method = "BHHH" )
> summary( mlgBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 13 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182    6.49 8.4e-11 ***
sigma    1.816      0.134   13.55 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlBHHH, mlgBHHH, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlg[ ], mlgBHHH[ -11 ], tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.09402"                                
[3] "Component 5: Mean relative difference: 1"                                      
[4] "Component 6: 1 string mismatch"                                                
[5] "Component 9: Mean relative difference: 0.8571"                                 
[6] "Component 10: 1 string mismatch"                                               
> mlgBHHH[ 11 ]
$gradientObs
             mu     sigma
  [1,] -0.39452 -0.267785
  [2,] -0.19432 -0.481927
  [3,]  0.88999  0.888280
  [4,] -0.01206 -0.550251
  [5,]  0.02357 -0.549506
  [6,]  0.98476  1.211024
  [7,]  0.22458 -0.458900
  [8,] -0.82159  0.675642
  [9,] -0.47112 -0.147335
 [10,] -0.32493 -0.358733
 [11,]  0.68716  0.307205
 [12,]  0.16330 -0.502077
 [13,]  0.18812 -0.486229
 [14,]  0.01229 -0.550241
 [15,] -0.39171 -0.271797
 [16,]  1.02831  1.370272
 [17,]  0.24697 -0.439724
 [18,] -1.24683  2.273366
 [19,]  0.37032 -0.301412
 [20,] -0.34137 -0.338831
 [21,] -0.70204  0.344762
 [22,] -0.18692 -0.487049
 [23,] -0.67669  0.281279
 [24,] -0.49660 -0.102543
 [25,] -0.43366 -0.208913
 [26,] -1.07716  1.557100
 [27,]  0.45301 -0.177736
 [28,]  0.03817 -0.547869
 [29,] -0.74466  0.456761
 [30,]  0.70518  0.352786
 [31,]  0.20370 -0.475146
 [32,] -0.23365 -0.451348
 [33,]  0.48777 -0.118343
 [34,]  0.47747 -0.136401
 [35,]  0.44319 -0.193727
 [36,]  0.36261 -0.311673
 [37,]  0.28095 -0.407135
 [38,] -0.09232 -0.535032
 [39,] -0.24025 -0.445666
 [40,] -0.28541 -0.402542
 [41,] -0.47588 -0.139145
 [42,] -0.18082 -0.491121
 [43,] -0.82180  0.676248
 [44,]  1.25988  2.332779
 [45,]  0.67739  0.282987
 [46,] -0.73555  0.432269
 [47,] -0.29900 -0.388120
 [48,] -0.33765 -0.343418
 [49,]  0.41797 -0.233185
 [50,] -0.10533 -0.530362
 [51,]  0.09875 -0.532803
 [52,] -0.07210 -0.541072
 [53,] -0.08078 -0.538661
 [54,]  0.77476  0.539828
 [55,] -0.19165 -0.483799
 [56,]  0.86439  0.806693
 [57,] -0.99355  1.242608
 [58,]  0.29956 -0.387515
 [59,]  0.02027 -0.549769
 [60,]  0.07609 -0.539998
 [61,]  0.17531 -0.494686
 [62,] -0.35927 -0.316049
 [63,] -0.25677 -0.430756
 [64,] -0.67219  0.270245
 [65,] -0.70445  0.350906
 [66,]  0.12918 -0.520202
 [67,]  0.21688 -0.465076
 [68,] -0.02267 -0.549582
 [69,]  0.50422 -0.088698
 [70,]  1.18783  2.012421
 [71,] -0.35243 -0.324897
 [72,] -1.45446  3.292186
 [73,]  0.55481  0.008631
 [74,] -0.48467 -0.123817
 [75,] -0.47182 -0.146135
 [76,]  0.56684  0.033124
 [77,] -0.22741 -0.456576
 [78,] -0.79472  0.596728
 [79,]  0.05510 -0.545001
 [80,] -0.13898 -0.515427
 [81,] -0.05130 -0.545734
 [82,]  0.17873 -0.492487
 [83,] -0.27947 -0.408644
 [84,]  0.33578 -0.345710
 [85,] -0.18844 -0.486011
 [86,]  0.14631 -0.511633
 [87,]  0.61003  0.125471
 [88,]  0.20898 -0.471185
 [89,] -0.25236 -0.434835
 [90,]  0.64153  0.197084
 [91,]  0.54740 -0.006216
 [92,]  0.27760 -0.410530
 [93,]  0.08991 -0.535833
 [94,] -0.43539 -0.206170
 [95,]  0.76994  0.526307
 [96,] -0.41864 -0.232166
 [97,]  1.27102  2.383988
 [98,]  0.87417  0.837588
 [99,] -0.19766 -0.479543
[100,] -0.67695  0.281900

> mlgBHHH2 <- maxLik( llf, gfInd, start = startVal, method = "BHHH" )
> all.equal( mlgBHHH, mlgBHHH2, tolerance = 1e-3 )
[1] TRUE
> # final Hessian = usual Hessian
> mlgBhhhH <- maxLik( llf, gfInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlgBhhhH, mlBhhhH, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgBhhhH, mlgBHHH, tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.09402"                                
> hessian( mlgBhhhH ) 
              mu      sigma
mu    -3.031e+01  9.273e-06
sigma  9.273e-06 -6.061e+01
> 
> # with analytical gradients as attribute
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> x <- xSaved[1]
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> try( maxLik( llfGradInd, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  the matrix returned by the gradient function (argument 'grad') must have at least as many rows as the number of parameters (2), where each row must correspond to the gradients of the log-likelihood function of an individual (independent) observation:
 currently, there are (is) 2 parameter(s) but the gradient matrix has only 1 row(s)
> x <- xSaved[1:2]
> try( maxLik( llfGrad, start = startVal, method = "BHHH" ) )
Error in checkBhhhGrad(g = gr, theta = theta, analytic = (!is.null(attr(f,  : 
  gradient is not a matrix but of class 'numeric';
the BHHH method requires that the gradient function
(argument 'grad') returns a numeric matrix,
where each row must correspond to the gradient(s)
of the log-likelihood function at an individual
(independent) observation and each column must
correspond to a parameter
> try( maxLik( llfGradInd, start = startVal, method = "BHHH" ) )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -0.6227 (2 free parameter(s))
Estimate(s): 0.2158 0.3302 
> x <- xSaved
> mlGBHHH <- maxLik( llfGradInd, start = startVal, method = "BHHH" )
> all.equal( mlGBHHH, mlgBHHH, tolerance = 1e-3 )
[1] TRUE
> # final Hessian = usual Hessian
> mlGBhhhH <- maxLik( llfGradInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlGBhhhH, mlgBhhhH, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBHHH <- maxLik( llfGradInd, gfInd, start = startVal, method = "BHHH" )
Warning message:
In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBHHH, mlgBHHH, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGBHHH, mlGBHHH, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessian
> mlghBHHH <- maxLik( llfInd, gfInd, hf, start = startVal, method = "BHHH" )
> all.equal( mlgBHHH, mlghBHHH, tolerance = 1e-3 )
[1] TRUE
> # final Hessian = usual Hessian
> mlghBhhhH <- maxLik( llfInd, gfInd, hf, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlghBhhhH, mlghBHHH, tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.09402"                                
> all.equal( mlghBhhhH, mlgBhhhH, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessian as attribute
> mlGHBHHH <- maxLik( llfGradHessInd, start = startVal, method = "BHHH" )
> all.equal( mlGHBHHH, mlghBHHH, tolerance = 1e-3 )
[1] TRUE
> # final Hessian = usual Hessian
> mlGHBhhhH <- maxLik( llfGradHessInd, start = startVal, method = "BHHH", 
+    finalHessian = TRUE )
> all.equal( mlGHBhhhH, mlghBhhhH, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBHHH <- maxLik( llfGradHessInd, gfInd, hf, start = startVal, method = "BHHH" )
Warning messages:
1: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad, hessOrig = hess,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBHHH, mlghBHHH, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGhHBHHH, mlGHBHHH, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ### BFGS-YC method
> mlBFGSYC <- maxLik( llf, start = startVal, method = "bfgsr" )
> print( mlBFGSYC )
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.181 1.816 
> summary( mlBFGSYC )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlBFGSYC )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBFGSYC )
[1] 407.2
> coef( mlBFGSYC )
   mu sigma 
1.181 1.816 
> condiNumber( mlBFGSYC )
mu 	 1 
sigma 	 1.668 
> hessian( mlBFGSYC )
             mu     sigma
mu    -30.29754   0.02842
sigma   0.02842 -60.53824
> logLik( mlBFGSYC )
[1] -201.6
> maximType( mlBFGSYC )
[1] "BFGSR maximization"
> nIter( mlBFGSYC )
[1] 15
> try( nObs( mlBFGSYC ) )
Error in nObs.maxLik(mlBFGSYC) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> nParam( mlBFGSYC )
[1] 2
> returnCode( mlBFGSYC )
[1] 2
> returnMessage( mlBFGSYC )
[1] "successive function values within tolerance limit"
> vcov( mlBFGSYC )
             mu     sigma
mu    0.0330060 0.0000155
sigma 0.0000155 0.0165185
> logLik( summary( mlBFGSYC ) )
[1] -201.6
> all.equal( ml[-c(5,6,9,10)], mlBFGSYC[-c(5,6,9,10)], tolerance = 1e-3 )
[1] "Component 3: Mean absolute difference: 0.003471"
[2] "Component 4: Mean relative difference: 0.002498"
> mlIndBFGSYC <- maxLik( llfInd, start = startVal, method = "BFGSR" )
> summary( mlIndBFGSYC )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 34 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlBFGSYC[ -9 ], mlIndBFGSYC[ -c(9,11) ], tolerance = 1e-3 )
[1] "Component 3: Mean relative difference: 1.662"   
[2] "Component 4: Mean relative difference: 0.002502"
> mlIndBFGSYC[ 11 ]
$gradientObs
             mu     sigma
  [1,] -0.39458 -0.267765
  [2,] -0.19434 -0.481951
  [3,]  0.89011  0.888540
  [4,] -0.01206 -0.550289
  [5,]  0.02357 -0.549544
  [6,]  0.98490  1.211351
  [7,]  0.22461 -0.458919
  [8,] -0.82171  0.675856
  [9,] -0.47119 -0.147290
 [10,] -0.32497 -0.358732
 [11,]  0.68725  0.307345
 [12,]  0.16332 -0.502105
 [13,]  0.18815 -0.486254
 [14,]  0.01229 -0.550279
 [15,] -0.39177 -0.271778
 [16,]  1.02845  1.370632
 [17,]  0.24700 -0.439739
 [18,] -1.24700  2.273909
 [19,]  0.37037 -0.301398
 [20,] -0.34142 -0.338825
 [21,] -0.70214  0.344908
 [22,] -0.18695 -0.487074
 [23,] -0.67679  0.281412
 [24,] -0.49667 -0.102489
 [25,] -0.43372 -0.208881
 [26,] -1.07731  1.557496
 [27,]  0.45308 -0.177696
 [28,]  0.03817 -0.547906
 [29,] -0.74476  0.456930
 [30,]  0.70528  0.352936
 [31,]  0.20372 -0.475168
 [32,] -0.23368 -0.451366
 [33,]  0.48784 -0.118291
 [34,]  0.47753 -0.136353
 [35,]  0.44325 -0.193691
 [36,]  0.36266 -0.311661
 [37,]  0.28099 -0.407143
 [38,] -0.09234 -0.535067
 [39,] -0.24029 -0.445682
 [40,] -0.28545 -0.402550
 [41,] -0.47595 -0.139099
 [42,] -0.18085 -0.491147
 [43,] -0.82191  0.676462
 [44,]  1.26005  2.333338
 [45,]  0.67748  0.283122
 [46,] -0.73565  0.432433
 [47,] -0.29904 -0.388124
 [48,] -0.33770 -0.343414
 [49,]  0.41802 -0.233157
 [50,] -0.10535 -0.530396
 [51,]  0.09876 -0.532837
 [52,] -0.07211 -0.541108
 [53,] -0.08079 -0.538696
 [54,]  0.77487  0.540016
 [55,] -0.19167 -0.483824
 [56,]  0.86451  0.806936
 [57,] -0.99369  1.242939
 [58,]  0.29960 -0.387519
 [59,]  0.02028 -0.549806
 [60,]  0.07610 -0.540034
 [61,]  0.17534 -0.494712
 [62,] -0.35932 -0.316038
 [63,] -0.25680 -0.430770
 [64,] -0.67228  0.270376
 [65,] -0.70454  0.351053
 [66,]  0.12920 -0.520234
 [67,]  0.21691 -0.465096
 [68,] -0.02267 -0.549619
 [69,]  0.50429 -0.088640
 [70,]  1.18799  2.012913
 [71,] -0.35248 -0.324889
 [72,] -1.45466  3.292940
 [73,]  0.55489  0.008710
 [74,] -0.48474 -0.123767
 [75,] -0.47189 -0.146090
 [76,]  0.56691  0.033208
 [77,] -0.22744 -0.456595
 [78,] -0.79483  0.596926
 [79,]  0.05510 -0.545038
 [80,] -0.13900 -0.515457
 [81,] -0.05131 -0.545771
 [82,]  0.17876 -0.492512
 [83,] -0.27951 -0.408653
 [84,]  0.33583 -0.345705
 [85,] -0.18847 -0.486036
 [86,]  0.14633 -0.511662
 [87,]  0.61012  0.125573
 [88,]  0.20901 -0.471206
 [89,] -0.25239 -0.434849
 [90,]  0.64162  0.197201
 [91,]  0.54747 -0.006141
 [92,]  0.27764 -0.410539
 [93,]  0.08992 -0.535867
 [94,] -0.43545 -0.206137
 [95,]  0.77005  0.526492
 [96,] -0.41869 -0.232139
 [97,]  1.27119  2.384558
 [98,]  0.87429  0.837838
 [99,] -0.19769 -0.479567
[100,] -0.67704  0.282033

> nObs( mlIndBFGSYC )
[1] 100
> 
> # with analytical gradients
> mlgBFGSYC <- maxLik( llf, gf, start = startVal, method = "BFGSR" , print.level=1)
Initial value of the function : -326.589781090132 
Iteration  1 
step = 1, lnL = -325.1, chi2 = 1.504, function increment = 1.494
Iteration  2 
step = 1, lnL = -254.9, chi2 = 107.8, function increment = 70.19
Iteration  3 
step = 1, lnL = -254.8, chi2 = 0.147, function increment = 0.1464
Iteration  4 
step = 1, lnL = -250, chi2 = 18.76, function increment = 4.778
Iteration  5 
step = 0.25, lnL = -218.8, chi2 = 1496, function increment = 31.18
Iteration  6 
step = 1, lnL = -201.7, chi2 = 22.41, function increment = 17.06
Iteration  7 
step = 0.25, lnL = -201.7, chi2 = 0.7577, function increment = 0.08696
Iteration  8 
step = 1, lnL = -201.6, chi2 = 0.07892, function increment = 0.05362
Iteration  9 
step = 0.25, lnL = -201.6, chi2 = 0.07185, function increment = 0.004091
Iteration  10 
step = 0.125, lnL = -201.6, chi2 = 0.223, function increment = 0.01277
Iteration  11 
step = 0.0625, lnL = -201.6, chi2 = 0.002795, function increment = 6.314e-05
Iteration  12 
step = 0.5, lnL = -201.6, chi2 = 0.0001251, function increment = 2.456e-05
Iteration  13 
step = 0.0625, lnL = -201.6, chi2 = 6.645e-05, function increment = 4.239e-07
Iteration  14 
step = 0.03125, lnL = -201.6, chi2 = 1.782e-05, function increment = 2.54e-07
Iteration  15 
step = 0.01562, lnL = -201.6, chi2 = 5.203e-08, function increment = 2.604e-10
--------------
successive function values within tolerance limit 
15  iterations
estimate: 1.181 1.816 
Function value: -201.6 
> summary(mlgBFGSYC)
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 15 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 7.9e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlBFGSYC, mlgBFGSYC, tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001476"
> mlgIndBFGSYC <- maxLik( llfInd, gfInd, start = startVal,
+    method = "BFGSR" )
> all.equal( mlIndBFGSYC, mlgIndBFGSYC, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgBFGSYC[ -9 ], mlgIndBFGSYC[ -c(9,11) ], tolerance = 1e-3 )
[1] "Component 3: Mean relative difference: 1.662"
> mlgIndBFGSYC[ 11 ]
$gradientObs
             mu     sigma
  [1,] -0.39458 -0.267765
  [2,] -0.19434 -0.481951
  [3,]  0.89011  0.888540
  [4,] -0.01206 -0.550289
  [5,]  0.02357 -0.549544
  [6,]  0.98490  1.211351
  [7,]  0.22461 -0.458919
  [8,] -0.82171  0.675856
  [9,] -0.47119 -0.147290
 [10,] -0.32497 -0.358732
 [11,]  0.68725  0.307345
 [12,]  0.16332 -0.502105
 [13,]  0.18815 -0.486254
 [14,]  0.01229 -0.550279
 [15,] -0.39177 -0.271778
 [16,]  1.02845  1.370632
 [17,]  0.24700 -0.439739
 [18,] -1.24700  2.273909
 [19,]  0.37037 -0.301398
 [20,] -0.34142 -0.338825
 [21,] -0.70214  0.344908
 [22,] -0.18695 -0.487074
 [23,] -0.67679  0.281412
 [24,] -0.49667 -0.102489
 [25,] -0.43372 -0.208881
 [26,] -1.07731  1.557496
 [27,]  0.45308 -0.177696
 [28,]  0.03817 -0.547906
 [29,] -0.74476  0.456930
 [30,]  0.70528  0.352936
 [31,]  0.20372 -0.475168
 [32,] -0.23368 -0.451366
 [33,]  0.48784 -0.118291
 [34,]  0.47753 -0.136353
 [35,]  0.44325 -0.193691
 [36,]  0.36266 -0.311661
 [37,]  0.28099 -0.407143
 [38,] -0.09234 -0.535067
 [39,] -0.24029 -0.445682
 [40,] -0.28545 -0.402550
 [41,] -0.47595 -0.139099
 [42,] -0.18085 -0.491147
 [43,] -0.82191  0.676462
 [44,]  1.26005  2.333338
 [45,]  0.67748  0.283122
 [46,] -0.73565  0.432433
 [47,] -0.29904 -0.388124
 [48,] -0.33770 -0.343414
 [49,]  0.41802 -0.233157
 [50,] -0.10535 -0.530396
 [51,]  0.09876 -0.532837
 [52,] -0.07211 -0.541108
 [53,] -0.08079 -0.538696
 [54,]  0.77487  0.540016
 [55,] -0.19167 -0.483824
 [56,]  0.86451  0.806936
 [57,] -0.99369  1.242939
 [58,]  0.29960 -0.387519
 [59,]  0.02028 -0.549806
 [60,]  0.07610 -0.540034
 [61,]  0.17534 -0.494712
 [62,] -0.35932 -0.316038
 [63,] -0.25680 -0.430770
 [64,] -0.67228  0.270376
 [65,] -0.70454  0.351053
 [66,]  0.12920 -0.520234
 [67,]  0.21691 -0.465096
 [68,] -0.02267 -0.549619
 [69,]  0.50429 -0.088640
 [70,]  1.18799  2.012913
 [71,] -0.35248 -0.324889
 [72,] -1.45466  3.292940
 [73,]  0.55489  0.008710
 [74,] -0.48474 -0.123767
 [75,] -0.47189 -0.146090
 [76,]  0.56691  0.033208
 [77,] -0.22744 -0.456595
 [78,] -0.79483  0.596926
 [79,]  0.05510 -0.545038
 [80,] -0.13900 -0.515457
 [81,] -0.05131 -0.545771
 [82,]  0.17876 -0.492512
 [83,] -0.27951 -0.408653
 [84,]  0.33583 -0.345705
 [85,] -0.18847 -0.486036
 [86,]  0.14633 -0.511662
 [87,]  0.61012  0.125573
 [88,]  0.20901 -0.471206
 [89,] -0.25239 -0.434849
 [90,]  0.64162  0.197201
 [91,]  0.54747 -0.006141
 [92,]  0.27764 -0.410539
 [93,]  0.08992 -0.535867
 [94,] -0.43545 -0.206137
 [95,]  0.77005  0.526492
 [96,] -0.41869 -0.232139
 [97,]  1.27119  2.384558
 [98,]  0.87429  0.837838
 [99,] -0.19769 -0.479567
[100,] -0.67704  0.282033

> 
> # with analytical gradients as attribute
> mlGBFGSYC <- maxLik( llfGrad, start = startVal, method = "BFGSR" , print.level=1)
Initial value of the function : -326.589781090132 
Iteration  1 
step = 1, lnL = -325.1, chi2 = 1.504, function increment = 1.494
Iteration  2 
step = 1, lnL = -254.9, chi2 = 107.8, function increment = 70.19
Iteration  3 
step = 1, lnL = -254.8, chi2 = 0.147, function increment = 0.1464
Iteration  4 
step = 1, lnL = -250, chi2 = 18.76, function increment = 4.778
Iteration  5 
step = 0.25, lnL = -218.8, chi2 = 1496, function increment = 31.18
Iteration  6 
step = 1, lnL = -201.7, chi2 = 22.41, function increment = 17.06
Iteration  7 
step = 0.25, lnL = -201.7, chi2 = 0.7577, function increment = 0.08696
Iteration  8 
step = 1, lnL = -201.6, chi2 = 0.07892, function increment = 0.05362
Iteration  9 
step = 0.25, lnL = -201.6, chi2 = 0.07185, function increment = 0.004091
Iteration  10 
step = 0.125, lnL = -201.6, chi2 = 0.223, function increment = 0.01277
Iteration  11 
step = 0.0625, lnL = -201.6, chi2 = 0.002795, function increment = 6.314e-05
Iteration  12 
step = 0.5, lnL = -201.6, chi2 = 0.0001251, function increment = 2.456e-05
Iteration  13 
step = 0.0625, lnL = -201.6, chi2 = 6.645e-05, function increment = 4.239e-07
Iteration  14 
step = 0.03125, lnL = -201.6, chi2 = 1.782e-05, function increment = 2.54e-07
Iteration  15 
step = 0.01562, lnL = -201.6, chi2 = 5.203e-08, function increment = 2.604e-10
--------------
successive function values within tolerance limit 
15  iterations
estimate: 1.181 1.816 
Function value: -201.6 
> all.equal( mlGBFGSYC, mlgBFGSYC, tolerance = 1e-3 )
[1] TRUE
> mlGIndBFGSYC <- maxLik( llfGradInd, start = startVal, method = "BFGSR" )
> all.equal( mlGIndBFGSYC, mlgIndBFGSYC, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBFGSYC <- maxLik( llfGrad, gf, start = startVal, method = "BFGSR" )
Warning message:
In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBFGSYC, mlgBFGSYC, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGBFGSYC, mlGBFGSYC, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessians
> mlghBFGSYC <- maxLik( llf, gf, hf, start = startVal, method = "BFGSR" )
> all.equal( mlgBFGSYC, mlghBFGSYC, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGHBFGSYC <- maxLik( llfGradHess, start = startVal, method = "BFGSR" )
> all.equal( mlGHBFGSYC, mlghBFGSYC, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBFGSYC <- maxLik( llfGradHess, gf, hf, start = startVal, method = "BFGSR" )
Warning messages:
1: In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxBFGSRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBFGSYC, mlghBFGSYC, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGhHBFGSYC, mlGHBFGSYC, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ## BFGS method
> mlBFGS <- maxLik( llf, start = startVal, method = "BFGS" )
> print( mlBFGS )
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.181 1.816 
> summary( mlBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.2e-11 ***
sigma    1.816      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlBFGS )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBFGS )
[1] 407.2
> coef( mlBFGS )
   mu sigma 
1.181 1.816 
> condiNumber( mlBFGS )
mu 	 1 
sigma 	 1.672 
> hessian( mlBFGS )
             mu     sigma
mu    -30.26912   0.02842
sigma   0.02842 -60.62351
> logLik( mlBFGS )
[1] -201.6
> maximType( mlBFGS )
[1] "BFGS maximisation"
> nIter( mlBFGS )
function 
      36 
> nParam( mlBFGS )
[1] 2
> returnCode( mlBFGS )
[1] 0
> returnMessage( mlBFGS )
[1] "successful convergence "
> vcov( mlBFGS )
             mu     sigma
mu    3.304e-02 1.549e-05
sigma 1.549e-05 1.650e-02
> logLik( summary( mlBFGS ) )
[1] -201.6
> all.equal( ml, mlBFGS, tolerance = 1e-3 )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 4: Mean relative difference: 0.005613"   
[3] "Component 5: Mean relative difference: 1"          
[4] "Component 6: 1 string mismatch"                    
[5] "Component 9: names for current but not for target" 
[6] "Component 9: Mean relative difference: 4.143"      
[7] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndBFGS <- maxLik( llfInd, start = startVal, method = "BFGS" )
> summary( mlIndBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.816      0.128    14.2 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlBFGS[], mlIndBFGS[-12], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.00125"
> mlIndBFGS[12]
$gradientObs
             mu     sigma
  [1,] -0.39452 -0.267786
  [2,] -0.19432 -0.481927
  [3,]  0.88999  0.888279
  [4,] -0.01206 -0.550251
  [5,]  0.02357 -0.549506
  [6,]  0.98476  1.211023
  [7,]  0.22458 -0.458899
  [8,] -0.82159  0.675638
  [9,] -0.47112 -0.147336
 [10,] -0.32493 -0.358734
 [11,]  0.68716  0.307205
 [12,]  0.16330 -0.502076
 [13,]  0.18812 -0.486229
 [14,]  0.01229 -0.550240
 [15,] -0.39171 -0.271798
 [16,]  1.02831  1.370271
 [17,]  0.24697 -0.439724
 [18,] -1.24683  2.273358
 [19,]  0.37032 -0.301412
 [20,] -0.34137 -0.338831
 [21,] -0.70204  0.344759
 [22,] -0.18692 -0.487049
 [23,] -0.67669  0.281276
 [24,] -0.49660 -0.102544
 [25,] -0.43365 -0.208914
 [26,] -1.07716  1.557095
 [27,]  0.45301 -0.177735
 [28,]  0.03817 -0.547869
 [29,] -0.74466  0.456758
 [30,]  0.70518  0.352786
 [31,]  0.20370 -0.475145
 [32,] -0.23365 -0.451349
 [33,]  0.48777 -0.118342
 [34,]  0.47747 -0.136401
 [35,]  0.44319 -0.193726
 [36,]  0.36261 -0.311673
 [37,]  0.28095 -0.407134
 [38,] -0.09232 -0.535032
 [39,] -0.24025 -0.445666
 [40,] -0.28541 -0.402542
 [41,] -0.47588 -0.139147
 [42,] -0.18082 -0.491121
 [43,] -0.82180  0.676245
 [44,]  1.25988  2.332775
 [45,]  0.67739  0.282986
 [46,] -0.73555  0.432266
 [47,] -0.29900 -0.388120
 [48,] -0.33765 -0.343419
 [49,]  0.41797 -0.233185
 [50,] -0.10533 -0.530362
 [51,]  0.09875 -0.532802
 [52,] -0.07210 -0.541072
 [53,] -0.08078 -0.538661
 [54,]  0.77476  0.539827
 [55,] -0.19164 -0.483800
 [56,]  0.86439  0.806692
 [57,] -0.99355  1.242603
 [58,]  0.29956 -0.387515
 [59,]  0.02027 -0.549768
 [60,]  0.07609 -0.539998
 [61,]  0.17531 -0.494685
 [62,] -0.35927 -0.316049
 [63,] -0.25677 -0.430757
 [64,] -0.67219  0.270243
 [65,] -0.70445  0.350903
 [66,]  0.12918 -0.520202
 [67,]  0.21688 -0.465075
 [68,] -0.02267 -0.549581
 [69,]  0.50422 -0.088698
 [70,]  1.18783  2.012418
 [71,] -0.35243 -0.324898
 [72,] -1.45446  3.292176
 [73,]  0.55481  0.008632
 [74,] -0.48467 -0.123818
 [75,] -0.47182 -0.146136
 [76,]  0.56684  0.033125
 [77,] -0.22741 -0.456577
 [78,] -0.79472  0.596724
 [79,]  0.05510 -0.545001
 [80,] -0.13898 -0.515427
 [81,] -0.05130 -0.545734
 [82,]  0.17873 -0.492486
 [83,] -0.27947 -0.408644
 [84,]  0.33578 -0.345709
 [85,] -0.18844 -0.486011
 [86,]  0.14631 -0.511632
 [87,]  0.61003  0.125471
 [88,]  0.20898 -0.471184
 [89,] -0.25236 -0.434835
 [90,]  0.64153  0.197084
 [91,]  0.54740 -0.006216
 [92,]  0.27760 -0.410530
 [93,]  0.08991 -0.535832
 [94,] -0.43539 -0.206171
 [95,]  0.76994  0.526306
 [96,] -0.41863 -0.232167
 [97,]  1.27102  2.383985
 [98,]  0.87417  0.837587
 [99,] -0.19766 -0.479543
[100,] -0.67695  0.281897

> nObs( mlIndBFGS )
[1] 100
> 
> # with analytical gradients
> mlgBFGS <- maxLik( llf, gf, start = startVal, method = "BFGS" )
> summary( mlgBFGS )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 36 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.816      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlBFGS, mlgBFGS, tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001151"
> all.equal( mlg, mlgBFGS, tolerance = 1e-3 )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 5: Mean relative difference: 1"          
[3] "Component 6: 1 string mismatch"                    
[4] "Component 9: names for current but not for target" 
[5] "Component 9: Mean relative difference: 4.143"      
[6] "Component 10: 1 string mismatch"                   
> mlgIndBFGS <- maxLik( llfInd, gfInd, start = startVal, method = "BFGS" )
> all.equal( mlgBFGS[], mlgIndBFGS[-12], tolerance = 1e-3 )
[1] TRUE
> mlgIndBFGS[12]
$gradientObs
             mu     sigma
  [1,] -0.39452 -0.267786
  [2,] -0.19432 -0.481927
  [3,]  0.88999  0.888279
  [4,] -0.01206 -0.550251
  [5,]  0.02357 -0.549506
  [6,]  0.98476  1.211023
  [7,]  0.22458 -0.458899
  [8,] -0.82159  0.675638
  [9,] -0.47112 -0.147336
 [10,] -0.32493 -0.358734
 [11,]  0.68716  0.307205
 [12,]  0.16330 -0.502076
 [13,]  0.18812 -0.486229
 [14,]  0.01229 -0.550240
 [15,] -0.39171 -0.271798
 [16,]  1.02831  1.370271
 [17,]  0.24697 -0.439724
 [18,] -1.24683  2.273358
 [19,]  0.37032 -0.301412
 [20,] -0.34137 -0.338831
 [21,] -0.70204  0.344759
 [22,] -0.18692 -0.487049
 [23,] -0.67669  0.281276
 [24,] -0.49660 -0.102544
 [25,] -0.43365 -0.208914
 [26,] -1.07716  1.557095
 [27,]  0.45301 -0.177735
 [28,]  0.03817 -0.547869
 [29,] -0.74466  0.456758
 [30,]  0.70518  0.352786
 [31,]  0.20370 -0.475145
 [32,] -0.23365 -0.451349
 [33,]  0.48777 -0.118342
 [34,]  0.47747 -0.136401
 [35,]  0.44319 -0.193726
 [36,]  0.36261 -0.311673
 [37,]  0.28095 -0.407134
 [38,] -0.09232 -0.535032
 [39,] -0.24025 -0.445666
 [40,] -0.28541 -0.402542
 [41,] -0.47588 -0.139147
 [42,] -0.18082 -0.491121
 [43,] -0.82180  0.676245
 [44,]  1.25988  2.332775
 [45,]  0.67739  0.282986
 [46,] -0.73555  0.432266
 [47,] -0.29900 -0.388120
 [48,] -0.33765 -0.343419
 [49,]  0.41797 -0.233185
 [50,] -0.10533 -0.530362
 [51,]  0.09875 -0.532802
 [52,] -0.07210 -0.541072
 [53,] -0.08078 -0.538661
 [54,]  0.77476  0.539827
 [55,] -0.19164 -0.483800
 [56,]  0.86439  0.806692
 [57,] -0.99355  1.242603
 [58,]  0.29956 -0.387515
 [59,]  0.02027 -0.549768
 [60,]  0.07609 -0.539998
 [61,]  0.17531 -0.494685
 [62,] -0.35927 -0.316049
 [63,] -0.25677 -0.430757
 [64,] -0.67219  0.270243
 [65,] -0.70445  0.350903
 [66,]  0.12918 -0.520202
 [67,]  0.21688 -0.465075
 [68,] -0.02267 -0.549581
 [69,]  0.50422 -0.088698
 [70,]  1.18783  2.012418
 [71,] -0.35243 -0.324898
 [72,] -1.45446  3.292176
 [73,]  0.55481  0.008632
 [74,] -0.48467 -0.123818
 [75,] -0.47182 -0.146136
 [76,]  0.56684  0.033125
 [77,] -0.22741 -0.456577
 [78,] -0.79472  0.596724
 [79,]  0.05510 -0.545001
 [80,] -0.13898 -0.515427
 [81,] -0.05130 -0.545734
 [82,]  0.17873 -0.492486
 [83,] -0.27947 -0.408644
 [84,]  0.33578 -0.345709
 [85,] -0.18844 -0.486011
 [86,]  0.14631 -0.511632
 [87,]  0.61003  0.125471
 [88,]  0.20898 -0.471184
 [89,] -0.25236 -0.434835
 [90,]  0.64153  0.197084
 [91,]  0.54740 -0.006216
 [92,]  0.27760 -0.410530
 [93,]  0.08991 -0.535832
 [94,] -0.43539 -0.206171
 [95,]  0.76994  0.526306
 [96,] -0.41863 -0.232167
 [97,]  1.27102  2.383985
 [98,]  0.87417  0.837587
 [99,] -0.19766 -0.479543
[100,] -0.67695  0.281897

> 
> # with analytical gradients as attribute
> mlGBFGS <- maxLik( llfGrad, start = startVal, method = "BFGS" )
> all.equal( mlGBFGS, mlgBFGS, tolerance = 1e-3 )
[1] TRUE
> mlGIndBFGS <- maxLik( llfGradInd, start = startVal, method = "BFGS" )
> all.equal( mlGIndBFGS, mlgIndBFGS, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGBFGS <- maxLik( llfGrad, gf, start = startVal, method = "BFGS" )
Warning message:
In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGBFGS, mlgBFGS, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGBFGS, mlGBFGS, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessian
> mlghBFGS <- maxLik( llf, gf, hf, start = startVal, method = "BFGS" )
> all.equal( mlgBFGS, mlghBFGS, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as attribute
> mlGHBFGS <- maxLik( llfGradHess, start = startVal, method = "BFGS" )
> all.equal( mlGHBFGS, mlghBFGS, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and Hessian as argument and attribute
> mlgGhHBFGS <- maxLik( llfGradHess, gf, hf, start = startVal, method = "BFGS" )
Warning messages:
1: In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
2: In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "BFGS",  :
  the Hessian is provided both as attribute 'hessian' and as argument 'hess': ignoring argument 'hess'
> all.equal( mlgGhHBFGS, mlghBFGS, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGhHBFGS, mlGHBFGS, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ## NM method
> mlNM <- maxLik( llf, start = startVal, method = "NM" )
> print( mlNM )
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.181 1.817 
> summary( mlNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.3e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlNM )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNM )
[1] 407.2
> coef( mlNM )
   mu sigma 
1.181 1.817 
> condiNumber( mlNM )
mu 	 1 
sigma 	 1.668 
> hessian( mlNM )
          mu sigma
mu    -30.27   0.0
sigma   0.00 -60.6
> logLik( mlNM )
[1] -201.6
> maximType( mlNM )
[1] "Nelder-Mead maximisation"
> nIter( mlNM )
function 
      63 
> nParam( mlNM )
[1] 2
> returnCode( mlNM )
[1] 0
> returnMessage( mlNM )
[1] "successful convergence "
> vcov( mlNM )
           mu  sigma
mu    0.03304 0.0000
sigma 0.00000 0.0165
> logLik( summary( mlNM ) )
[1] -201.6
> all.equal( ml, mlNM, tolerance = 1e-3 )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 3: Mean absolute difference: 0.007797"   
[3] "Component 4: Mean relative difference: 0.001562"   
[4] "Component 5: Mean relative difference: 1"          
[5] "Component 6: 1 string mismatch"                    
[6] "Component 9: names for current but not for target" 
[7] "Component 9: Mean relative difference: 8"          
[8] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndNM <- maxLik( llfInd, start = startVal, method = "NM" )
> summary( mlIndNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5   8e-11 ***
sigma    1.817      0.128    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlNM[], mlIndNM[-12], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.003756"
> mlIndNM[12]
$gradientObs
             mu     sigma
  [1,] -0.39439 -0.267899
  [2,] -0.19422 -0.481941
  [3,]  0.88990  0.888156
  [4,] -0.01200 -0.550207
  [5,]  0.02363 -0.549454
  [6,]  0.98465  1.210839
  [7,]  0.22460 -0.458826
  [8,] -0.82139  0.675189
  [9,] -0.47098 -0.147497
 [10,] -0.32481 -0.358808
 [11,]  0.68710  0.307186
 [12,]  0.16333 -0.502006
 [13,]  0.18815 -0.486157
 [14,]  0.01235 -0.550191
 [15,] -0.39158 -0.271909
 [16,]  1.02820  1.370056
 [17,]  0.24699 -0.439650
 [18,] -1.24656  2.272406
 [19,]  0.37032 -0.301346
 [20,] -0.34125 -0.338914
 [21,] -0.70186  0.344421
 [22,] -0.18683 -0.487060
 [23,] -0.67652  0.280960
 [24,] -0.49646 -0.102723
 [25,] -0.43352 -0.209051
 [26,] -1.07691  1.556363
 [27,]  0.45300 -0.177683
 [28,]  0.03822 -0.547814
 [29,] -0.74447  0.456382
 [30,]  0.70512  0.352759
 [31,]  0.20372 -0.475072
 [32,] -0.23355 -0.451379
 [33,]  0.48775 -0.118297
 [34,]  0.47745 -0.136353
 [35,]  0.44318 -0.193672
 [36,]  0.36261 -0.311606
 [37,]  0.28096 -0.407062
 [38,] -0.09225 -0.535009
 [39,] -0.24015 -0.445699
 [40,] -0.28530 -0.402597
 [41,] -0.47574 -0.139311
 [42,] -0.18073 -0.491130
 [43,] -0.82160  0.675795
 [44,]  1.25973  2.332366
 [45,]  0.67733  0.282971
 [46,] -0.73536  0.431898
 [47,] -0.29889 -0.388181
 [48,] -0.33753 -0.343500
 [49,]  0.41796 -0.233126
 [50,] -0.10525 -0.530344
 [51,]  0.09879 -0.532738
 [52,] -0.07203 -0.541043
 [53,] -0.08071 -0.538635
 [54,]  0.77469  0.539768
 [55,] -0.19155 -0.483812
 [56,]  0.86430  0.806585
 [57,] -0.99332  1.241970
 [58,]  0.29957 -0.387443
 [59,]  0.02033 -0.549717
 [60,]  0.07614 -0.539936
 [61,]  0.17535 -0.494613
 [62,] -0.35915 -0.316142
 [63,] -0.25666 -0.430798
 [64,] -0.67201  0.269930
 [65,] -0.70426  0.350563
 [66,]  0.12922 -0.520134
 [67,]  0.21690 -0.465002
 [68,] -0.02260 -0.549540
 [69,]  0.50419 -0.088657
 [70,]  1.18769  2.012075
 [71,] -0.35231 -0.324987
 [72,] -1.45415  3.290917
 [73,]  0.55478  0.008659
 [74,] -0.48452 -0.123988
 [75,] -0.47168 -0.146298
 [76,]  0.56680  0.033149
 [77,] -0.22731 -0.456604
 [78,] -0.79452  0.596301
 [79,]  0.05515 -0.544943
 [80,] -0.13890 -0.515420
 [81,] -0.05123 -0.545699
 [82,]  0.17876 -0.492414
 [83,] -0.27936 -0.408696
 [84,]  0.33578 -0.345640
 [85,] -0.18835 -0.486023
 [86,]  0.14634 -0.511562
 [87,]  0.60999  0.125481
 [88,]  0.20901 -0.471111
 [89,] -0.25225 -0.434874
 [90,]  0.64148  0.197083
 [91,]  0.54737 -0.006186
 [92,]  0.27762 -0.410457
 [93,]  0.08995 -0.535769
 [94,] -0.43526 -0.206309
 [95,]  0.76987  0.526250
 [96,] -0.41850 -0.232295
 [97,]  1.27086  2.383565
 [98,]  0.87408  0.837474
 [99,] -0.19757 -0.479559
[100,] -0.67677  0.281580

> nObs( mlIndNM )
[1] 100
> 
> # with unused analytical gradients
> mlgNM <- maxLik( llf, gf, start = startVal, method = "NM" )
> summary( mlgNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlNM, mlgNM, tolerance = 1e-3 )
[1] TRUE
> # with individual log likelihood values and gradients
> mlgIndNM <- maxLik( llfInd, gfInd, start = startVal, method = "NM" )
> summary( mlgIndNM )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 63 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.181      0.182     6.5 8.1e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlgNM[], mlgIndNM[-12], tolerance = 1e-3 )
[1] TRUE
> mlgIndNM[12]
$gradientObs
             mu     sigma
  [1,] -0.39439 -0.267899
  [2,] -0.19422 -0.481941
  [3,]  0.88990  0.888156
  [4,] -0.01200 -0.550207
  [5,]  0.02363 -0.549454
  [6,]  0.98465  1.210839
  [7,]  0.22460 -0.458826
  [8,] -0.82139  0.675189
  [9,] -0.47098 -0.147497
 [10,] -0.32481 -0.358808
 [11,]  0.68710  0.307186
 [12,]  0.16333 -0.502006
 [13,]  0.18815 -0.486157
 [14,]  0.01235 -0.550191
 [15,] -0.39158 -0.271909
 [16,]  1.02820  1.370056
 [17,]  0.24699 -0.439650
 [18,] -1.24656  2.272406
 [19,]  0.37032 -0.301346
 [20,] -0.34125 -0.338914
 [21,] -0.70186  0.344421
 [22,] -0.18683 -0.487060
 [23,] -0.67652  0.280960
 [24,] -0.49646 -0.102723
 [25,] -0.43352 -0.209051
 [26,] -1.07691  1.556363
 [27,]  0.45300 -0.177683
 [28,]  0.03822 -0.547814
 [29,] -0.74447  0.456382
 [30,]  0.70512  0.352759
 [31,]  0.20372 -0.475072
 [32,] -0.23355 -0.451379
 [33,]  0.48775 -0.118297
 [34,]  0.47745 -0.136353
 [35,]  0.44318 -0.193672
 [36,]  0.36261 -0.311606
 [37,]  0.28096 -0.407062
 [38,] -0.09225 -0.535009
 [39,] -0.24015 -0.445699
 [40,] -0.28530 -0.402597
 [41,] -0.47574 -0.139311
 [42,] -0.18073 -0.491130
 [43,] -0.82160  0.675795
 [44,]  1.25973  2.332366
 [45,]  0.67733  0.282971
 [46,] -0.73536  0.431898
 [47,] -0.29889 -0.388181
 [48,] -0.33753 -0.343500
 [49,]  0.41796 -0.233126
 [50,] -0.10525 -0.530344
 [51,]  0.09879 -0.532738
 [52,] -0.07203 -0.541043
 [53,] -0.08071 -0.538635
 [54,]  0.77469  0.539768
 [55,] -0.19155 -0.483812
 [56,]  0.86430  0.806585
 [57,] -0.99332  1.241970
 [58,]  0.29957 -0.387443
 [59,]  0.02033 -0.549717
 [60,]  0.07614 -0.539936
 [61,]  0.17535 -0.494613
 [62,] -0.35915 -0.316142
 [63,] -0.25666 -0.430798
 [64,] -0.67201  0.269930
 [65,] -0.70426  0.350563
 [66,]  0.12922 -0.520134
 [67,]  0.21690 -0.465002
 [68,] -0.02260 -0.549540
 [69,]  0.50419 -0.088657
 [70,]  1.18769  2.012075
 [71,] -0.35231 -0.324987
 [72,] -1.45415  3.290917
 [73,]  0.55478  0.008659
 [74,] -0.48452 -0.123988
 [75,] -0.47168 -0.146298
 [76,]  0.56680  0.033149
 [77,] -0.22731 -0.456604
 [78,] -0.79452  0.596301
 [79,]  0.05515 -0.544943
 [80,] -0.13890 -0.515420
 [81,] -0.05123 -0.545699
 [82,]  0.17876 -0.492414
 [83,] -0.27936 -0.408696
 [84,]  0.33578 -0.345640
 [85,] -0.18835 -0.486023
 [86,]  0.14634 -0.511562
 [87,]  0.60999  0.125481
 [88,]  0.20901 -0.471111
 [89,] -0.25225 -0.434874
 [90,]  0.64148  0.197083
 [91,]  0.54737 -0.006186
 [92,]  0.27762 -0.410457
 [93,]  0.08995 -0.535769
 [94,] -0.43526 -0.206309
 [95,]  0.76987  0.526250
 [96,] -0.41850 -0.232295
 [97,]  1.27086  2.383565
 [98,]  0.87408  0.837474
 [99,] -0.19757 -0.479559
[100,] -0.67677  0.281580

> 
> # with (unused) analytical gradients as attribute
> mlGNM <- maxLik( llfGrad, start = startVal, method = "NM" )
> all.equal( mlGNM, mlgNM, tolerance = 1e-3 )
[1] TRUE
> mlGIndNM <- maxLik( llfGradInd, start = startVal, method = "NM" )
> all.equal( mlGIndNM, mlgIndNM, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as argument and attribute
> mlgGNM <- maxLik( llfGrad, gf, start = startVal, method = "NM" )
Warning message:
In maxOptim(fn = fn, grad = grad, hess = hess, start = start, method = "Nelder-Mead",  :
  the gradient is provided both as attribute 'gradient' and as argument 'grad': ignoring argument 'grad'
> all.equal( mlgGNM, mlgNM, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlgGNM, mlGNM, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused analytical gradients and Hessian
> mlghNM <- maxLik( llf, gf, hf, start = startVal, method = "NM" )
> all.equal( mlgNM, mlghNM, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ## SANN method
> mlSANN <- maxLik( llf, start = startVal, method = "SANN" )
> print( mlSANN )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 (2 free parameter(s))
Estimate(s): 1.182 1.817 
> summary( mlSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182     6.5 7.9e-11 ***
sigma    1.817      0.128    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlSANN )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSANN )
[1] 407.2
> coef( mlSANN )
   mu sigma 
1.182 1.817 
> condiNumber( mlSANN )
mu 	 1 
sigma 	 1.673 
> hessian( mlSANN )
             mu     sigma
mu    -30.26912   0.05684
sigma   0.05684 -60.59508
> logLik( mlSANN )
[1] -201.6
> maximType( mlSANN )
[1] "SANN maximisation"
> nIter( mlSANN )
function 
   10000 
> nParam( mlSANN )
[1] 2
> returnCode( mlSANN )
[1] 0
> returnMessage( mlSANN )
[1] "successful convergence "
> vcov( mlSANN )
             mu     sigma
mu    3.304e-02 3.099e-05
sigma 3.099e-05 1.650e-02
> logLik( summary( mlSANN ) )
[1] -201.6
> all.equal( ml, mlSANN, tolerance = 1e-3 )
[1] "Length mismatch: comparison on first 10 components"
[2] "Component 3: Mean absolute difference: 0.01578"    
[3] "Component 4: Mean relative difference: 0.002811"   
[4] "Component 5: Mean relative difference: 1"          
[5] "Component 6: 1 string mismatch"                    
[6] "Component 9: names for current but not for target" 
[7] "Component 9: Mean relative difference: 1428"       
[8] "Component 10: 1 string mismatch"                   
> # with individual log likelihood values
> mlIndSANN <- maxLik( llfInd, start = startVal, method = "SANN" )
> summary( mlIndSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.6e-11 ***
sigma    1.817      0.128   14.15 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlSANN[], mlIndSANN[-12], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.002499"
> mlIndSANN[12]
$gradientObs
             mu     sigma
  [1,] -0.39480 -0.267372
  [2,] -0.19460 -0.481713
  [3,]  0.88966  0.887254
  [4,] -0.01235 -0.550226
  [5,]  0.02327 -0.549519
  [6,]  0.98443  1.209877
  [7,]  0.22428 -0.459132
  [8,] -0.82185  0.676448
  [9,] -0.47140 -0.146848
 [10,] -0.32521 -0.358388
 [11,]  0.68684  0.306432
 [12,]  0.16300 -0.502242
 [13,]  0.18782 -0.486422
 [14,]  0.01200 -0.550242
 [15,] -0.39199 -0.271387
 [16,]  1.02797  1.369068
 [17,]  0.24666 -0.439982
 [18,] -1.24707  2.274521
 [19,]  0.37001 -0.301810
 [20,] -0.34165 -0.338469
 [21,] -0.70230  0.345462
 [22,] -0.18720 -0.486842
 [23,] -0.67696  0.281956
 [24,] -0.49688 -0.102032
 [25,] -0.43393 -0.208462
 [26,] -1.07741  1.558122
 [27,]  0.45270 -0.178229
 [28,]  0.03787 -0.547898
 [29,] -0.74492  0.457500
 [30,]  0.70486  0.351991
 [31,]  0.20340 -0.475355
 [32,] -0.23393 -0.451095
 [33,]  0.48745 -0.118877
 [34,]  0.47716 -0.136923
 [35,]  0.44288 -0.194209
 [36,]  0.36230 -0.312062
 [37,]  0.28065 -0.407431
 [38,] -0.09261 -0.534923
 [39,] -0.24053 -0.445405
 [40,] -0.28569 -0.402236
 [41,] -0.47616 -0.138654
 [42,] -0.18111 -0.490921
 [43,] -0.82206  0.677055
 [44,]  1.25953  2.331267
 [45,]  0.67707  0.282225
 [46,] -0.73581  0.432999
 [47,] -0.29928 -0.387800
 [48,] -0.33793 -0.343061
 [49,]  0.41765 -0.233638
 [50,] -0.10562 -0.530239
 [51,]  0.09845 -0.532897
 [52,] -0.07239 -0.540984
 [53,] -0.08107 -0.538564
 [54,]  0.77443  0.538946
 [55,] -0.19193 -0.483588
 [56,]  0.86406  0.805699
 [57,] -0.99380  1.243560
 [58,]  0.29925 -0.387832
 [59,]  0.01998 -0.549778
 [60,]  0.07580 -0.540068
 [61,]  0.17501 -0.494864
 [62,] -0.35955 -0.315670
 [63,] -0.25705 -0.430479
 [64,] -0.67246  0.270919
 [65,] -0.70471  0.351608
 [66,]  0.12888 -0.520330
 [67,]  0.21658 -0.465300
 [68,] -0.02296 -0.549546
 [69,]  0.50391 -0.089252
 [70,]  1.18748  2.011006
 [71,] -0.35271 -0.324525
 [72,] -1.45469  3.293497
 [73,]  0.55450  0.008018
 [74,] -0.48494 -0.123317
 [75,] -0.47210 -0.145648
 [76,]  0.56652  0.032497
 [77,] -0.22769 -0.456329
 [78,] -0.79498  0.597510
 [79,]  0.05480 -0.545048
 [80,] -0.13927 -0.515269
 [81,] -0.05159 -0.545668
 [82,]  0.17843 -0.492668
 [83,] -0.27975 -0.408344
 [84,]  0.33547 -0.346068
 [85,] -0.18873 -0.485803
 [86,]  0.14601 -0.511779
 [87,]  0.60971  0.124791
 [88,]  0.20868 -0.471400
 [89,] -0.25264 -0.434562
 [90,]  0.64121  0.196366
 [91,]  0.54708 -0.006821
 [92,]  0.27730 -0.410822
 [93,]  0.08961 -0.535917
 [94,] -0.43567 -0.205717
 [95,]  0.76961  0.525431
 [96,] -0.41891 -0.231730
 [97,]  1.27067  2.382461
 [98,]  0.87384  0.836582
 [99,] -0.19795 -0.479326
[100,] -0.67721  0.282577

> nObs( mlIndSANN )
[1] 100
> 
> # with unused analytical gradients
> mlgSANN <- maxLik( llf, gf, start = startVal, method = "SANN" )
> summary( mlgSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.7e-11 ***
sigma    1.817      0.128   14.14 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlSANN, mlgSANN, tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001071"
> # with individual log likelihood values and gradients
> mlgIndSANN <- maxLik( llfInd, gfInd, start = startVal, method = "SANN" )
> summary( mlgIndSANN )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.182      0.182    6.51 7.7e-11 ***
sigma    1.817      0.128   14.14 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlgSANN[], mlgIndSANN[-12], tolerance = 1e-3 )
[1] TRUE
> mlgIndSANN[12]
$gradientObs
             mu     sigma
  [1,] -0.39480 -0.267372
  [2,] -0.19460 -0.481713
  [3,]  0.88966  0.887254
  [4,] -0.01235 -0.550226
  [5,]  0.02327 -0.549519
  [6,]  0.98443  1.209877
  [7,]  0.22428 -0.459132
  [8,] -0.82185  0.676448
  [9,] -0.47140 -0.146848
 [10,] -0.32521 -0.358388
 [11,]  0.68684  0.306432
 [12,]  0.16300 -0.502242
 [13,]  0.18782 -0.486422
 [14,]  0.01200 -0.550242
 [15,] -0.39199 -0.271387
 [16,]  1.02797  1.369068
 [17,]  0.24666 -0.439982
 [18,] -1.24707  2.274521
 [19,]  0.37001 -0.301810
 [20,] -0.34165 -0.338469
 [21,] -0.70230  0.345462
 [22,] -0.18720 -0.486842
 [23,] -0.67696  0.281956
 [24,] -0.49688 -0.102032
 [25,] -0.43393 -0.208462
 [26,] -1.07741  1.558122
 [27,]  0.45270 -0.178229
 [28,]  0.03787 -0.547898
 [29,] -0.74492  0.457500
 [30,]  0.70486  0.351991
 [31,]  0.20340 -0.475355
 [32,] -0.23393 -0.451095
 [33,]  0.48745 -0.118877
 [34,]  0.47716 -0.136923
 [35,]  0.44288 -0.194209
 [36,]  0.36230 -0.312062
 [37,]  0.28065 -0.407431
 [38,] -0.09261 -0.534923
 [39,] -0.24053 -0.445405
 [40,] -0.28569 -0.402236
 [41,] -0.47616 -0.138654
 [42,] -0.18111 -0.490921
 [43,] -0.82206  0.677055
 [44,]  1.25953  2.331267
 [45,]  0.67707  0.282225
 [46,] -0.73581  0.432999
 [47,] -0.29928 -0.387800
 [48,] -0.33793 -0.343061
 [49,]  0.41765 -0.233638
 [50,] -0.10562 -0.530239
 [51,]  0.09845 -0.532897
 [52,] -0.07239 -0.540984
 [53,] -0.08107 -0.538564
 [54,]  0.77443  0.538946
 [55,] -0.19193 -0.483588
 [56,]  0.86406  0.805699
 [57,] -0.99380  1.243560
 [58,]  0.29925 -0.387832
 [59,]  0.01998 -0.549778
 [60,]  0.07580 -0.540068
 [61,]  0.17501 -0.494864
 [62,] -0.35955 -0.315670
 [63,] -0.25705 -0.430479
 [64,] -0.67246  0.270919
 [65,] -0.70471  0.351608
 [66,]  0.12888 -0.520330
 [67,]  0.21658 -0.465300
 [68,] -0.02296 -0.549546
 [69,]  0.50391 -0.089252
 [70,]  1.18748  2.011006
 [71,] -0.35271 -0.324525
 [72,] -1.45469  3.293497
 [73,]  0.55450  0.008018
 [74,] -0.48494 -0.123317
 [75,] -0.47210 -0.145648
 [76,]  0.56652  0.032497
 [77,] -0.22769 -0.456329
 [78,] -0.79498  0.597510
 [79,]  0.05480 -0.545048
 [80,] -0.13927 -0.515269
 [81,] -0.05159 -0.545668
 [82,]  0.17843 -0.492668
 [83,] -0.27975 -0.408344
 [84,]  0.33547 -0.346068
 [85,] -0.18873 -0.485803
 [86,]  0.14601 -0.511779
 [87,]  0.60971  0.124791
 [88,]  0.20868 -0.471400
 [89,] -0.25264 -0.434562
 [90,]  0.64121  0.196366
 [91,]  0.54708 -0.006821
 [92,]  0.27730 -0.410822
 [93,]  0.08961 -0.535917
 [94,] -0.43567 -0.205717
 [95,]  0.76961  0.525431
 [96,] -0.41891 -0.231730
 [97,]  1.27067  2.382461
 [98,]  0.87384  0.836582
 [99,] -0.19795 -0.479326
[100,] -0.67721  0.282577

> 
> # with unused analytical gradients and Hessian
> mlghSANN <- maxLik( llf, gf, hf, start = startVal, method = "SANN" )
> all.equal( mlgSANN, mlghSANN, tolerance = 1e-3 )
[1] TRUE
> 
> # with a user-specified function to generate a new candidate point
> mlSANNCand <- maxLik( llf, start = startVal, method = "SANN",
+    cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
> summary( mlSANNCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.200      0.181    6.62 3.5e-11 ***
sigma    1.813      0.128   14.18 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlSANNCand, mlSANN, tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.007475"
[2] "Component 3: Mean relative difference: 0.9679"  
[3] "Component 4: Mean relative difference: 0.0214"  
> 
> ############### with fixed parameters ###############
> # start values
> startValFix <- c( mu = 1, sigma = 1 )
> 
> # fix mu (the mean ) at its start value
> isFixed <- c( TRUE, FALSE )
> 
> ## NR method with fixed parameters
> mlFix <- maxLik( llf, start = startValFix, activePar = !isFixed )
> mlFix1 <- maxLik( llf, start = startValFix, activePar = 2 )
> all.equal( mlFix, mlFix1, tolerance = 1e-3 )
[1] TRUE
> mlFix2 <- maxLik( llf, start = startValFix, fixed = isFixed )
> all.equal( mlFix, mlFix2, tolerance = 1e-3 )
[1] TRUE
> mlFix3 <- maxLik( llf, start = startValFix, fixed = "mu" )
> all.equal( mlFix, mlFix3, tolerance = 1e-3 )
[1] TRUE
> mlFix4 <- maxLik( llf, start = startValFix, fixed = 1 )
> all.equal( mlFix, mlFix4, tolerance = 1e-3 )
[1] TRUE
> print( mlFix )
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.1 (1 free parameter(s))
Estimate(s): 1 1.825 
> summary( mlFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlFix )
   mu sigma 
FALSE  TRUE 
> AIC( mlFix )
[1] 406.2
> coef( mlFix )
   mu sigma 
1.000 1.825 
> condiNumber( mlFix )
sigma 	 1 
> hessian( mlFix )
      mu  sigma
mu    NA     NA
sigma NA -59.97
> logLik( mlFix )
[1] -202.1
> maximType( mlFix )
[1] "Newton-Raphson maximisation"
> nIter( mlFix )
[1] 7
> nParam( mlFix )
[1] 2
> returnCode( mlFix )
[1] 1
> returnMessage( mlFix )
[1] "gradient close to zero"
> vcov( mlFix )
      mu   sigma
mu     0 0.00000
sigma  0 0.01668
> logLik( summary( mlFix ) )
[1] -202.1
> mlIndFix <- maxLik( llfInd, start = startValFix, activePar = !isFixed )
> mlIndFix1 <- maxLik( llfInd, start = startValFix, activePar = 2 )
> all.equal( mlIndFix, mlIndFix1, tolerance = 1e-3 )
[1] TRUE
> mlIndFix2 <- maxLik( llfInd, start = startValFix, fixed = isFixed )
> all.equal( mlIndFix, mlIndFix2, tolerance = 1e-3 )
[1] TRUE
> mlIndFix3 <- maxLik( llfInd, start = startValFix, fixed = "mu" )
> all.equal( mlIndFix, mlIndFix3, tolerance = 1e-3 )
[1] TRUE
> mlIndFix4 <- maxLik( llfInd, start = startValFix, fixed = 1 )
> all.equal( mlIndFix, mlIndFix4, tolerance = 1e-3 )
[1] TRUE
> summary( mlIndFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFix[ ], mlIndFix[ -11 ], tolerance = 1e-3 )
[1] TRUE
> mlFix[[3]]
       mu     sigma 
       NA 2.842e-08 
> mlIndFix[[3]]
       mu     sigma 
       NA 2.465e-08 
> mlIndFix[ 11 ]
$gradientObs
       mu    sigma
  [1,] NA -0.34124
  [2,] NA -0.51297
  [3,] NA  1.04982
  [4,] NA -0.54454
  [5,] NA -0.53682
  [6,] NA  1.38641
  [7,] NA -0.40811
  [8,] NA  0.50456
  [9,] NA -0.23759
 [10,] NA -0.41720
 [11,] NA  0.43749
 [12,] NA -0.46267
 [13,] NA -0.44219
 [14,] NA -0.53975
 [15,] NA -0.34464
 [16,] NA  1.55187
 [17,] NA -0.38482
 [18,] NA  1.99542
 [19,] NA -0.22435
 [20,] NA -0.40082
 [21,] NA  0.20199
 [22,] NA -0.51656
 [23,] NA  0.14441
 [24,] NA -0.19845
 [25,] NA -0.29091
 [26,] NA  1.32295
 [27,] NA -0.08626
 [28,] NA -0.53234
 [29,] NA  0.30398
 [30,] NA  0.48593
 [31,] NA -0.42821
 [32,] NA -0.49055
 [33,] NA -0.02093
 [34,] NA -0.04074
 [35,] NA -0.10395
 [36,] NA -0.23597
 [37,] NA -0.34605
 [38,] NA -0.54529
 [39,] NA -0.48625
 [40,] NA -0.45262
 [41,] NA -0.23045
 [42,] NA -0.51938
 [43,] NA  0.50512
 [44,] NA  2.54567
 [45,] NA  0.41171
 [46,] NA  0.28164
 [47,] NA -0.44107
 [48,] NA -0.40461
 [49,] NA -0.14778
 [50,] NA -0.54324
 [51,] NA -0.50561
 [52,] NA -0.54727
 [53,] NA -0.54660
 [54,] NA  0.68388
 [55,] NA -0.51429
 [56,] NA  0.96440
 [57,] NA  1.02947
 [58,] NA -0.32307
 [59,] NA -0.53772
 [60,] NA -0.51714
 [61,] NA -0.45303
 [62,] NA -0.38188
 [63,] NA -0.47480
 [64,] NA  0.13442
 [65,] NA  0.20757
 [66,] NA -0.48723
 [67,] NA -0.41571
 [68,] NA -0.54596
 [69,] NA  0.01151
 [70,] NA  2.21588
 [71,] NA -0.38926
 [72,] NA  2.95855
 [73,] NA  0.11734
 [74,] NA -0.21707
 [75,] NA -0.23654
 [76,] NA  0.14383
 [77,] NA -0.49448
 [78,] NA  0.43208
 [79,] NA -0.52619
 [80,] NA -0.53512
 [81,] NA -0.54779
 [82,] NA -0.45020
 [83,] NA -0.45746
 [84,] NA -0.27477
 [85,] NA -0.51584
 [86,] NA -0.47542
 [87,] NA  0.24329
 [88,] NA -0.42327
 [89,] NA -0.47795
 [90,] NA  0.32003
 [91,] NA  0.10125
 [92,] NA -0.35005
 [93,] NA -0.51033
 [94,] NA -0.28855
 [95,] NA  0.66961
 [96,] NA -0.31088
 [97,] NA  2.59831
 [98,] NA  0.99677
 [99,] NA -0.51128
[100,] NA  0.14497

> nObs( mlIndFix )
[1] 100
> 
> # with analytical gradients
> mlgFix <- maxLik( llf, gf, start = startValFix, activePar = !isFixed )
> mlgFix1 <- maxLik( llf, gf, start = startValFix, activePar = 2 )
> all.equal( mlgFix, mlgFix1, tolerance = 1e-3 )
[1] TRUE
> mlgFix2 <- maxLik( llf, gf, start = startValFix, fixed = isFixed )
> all.equal( mlgFix, mlgFix2, tolerance = 1e-3 )
[1] TRUE
> summary( mlgFix )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 7 iterations
Return code 1: gradient close to zero
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFix, mlgFix, tolerance = 1e-3 )
[1] TRUE
> mlFix[[3]]
       mu     sigma 
       NA 2.842e-08 
> mlgFix[[3]]
       mu     sigma 
       NA 5.471e-13 
> mlFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -59.97
> mlgFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -60.02
> mlgIndFix <- maxLik( llfInd, gfInd, start = startValFix, activePar = !isFixed )
> all.equal( mlIndFix, mlgIndFix, tolerance = 1e-3 )
[1] TRUE
> mlIndFix[[3]]
       mu     sigma 
       NA 2.465e-08 
> mlgIndFix[[3]]
       mu     sigma 
       NA 5.484e-13 
> mlIndFix[[4]]
      mu sigma
mu    NA    NA
sigma NA   -60
> mlgIndFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -60.02
> all.equal( mlgFix[ ], mlgIndFix[ -11 ], tolerance = 1e-3 )
[1] TRUE
> mlgIndFix[ 11 ]
$gradientObs
       mu    sigma
  [1,] NA -0.34124
  [2,] NA -0.51297
  [3,] NA  1.04982
  [4,] NA -0.54454
  [5,] NA -0.53682
  [6,] NA  1.38641
  [7,] NA -0.40811
  [8,] NA  0.50456
  [9,] NA -0.23759
 [10,] NA -0.41720
 [11,] NA  0.43749
 [12,] NA -0.46267
 [13,] NA -0.44219
 [14,] NA -0.53975
 [15,] NA -0.34464
 [16,] NA  1.55187
 [17,] NA -0.38482
 [18,] NA  1.99542
 [19,] NA -0.22435
 [20,] NA -0.40082
 [21,] NA  0.20199
 [22,] NA -0.51656
 [23,] NA  0.14441
 [24,] NA -0.19845
 [25,] NA -0.29091
 [26,] NA  1.32295
 [27,] NA -0.08626
 [28,] NA -0.53234
 [29,] NA  0.30398
 [30,] NA  0.48593
 [31,] NA -0.42821
 [32,] NA -0.49055
 [33,] NA -0.02093
 [34,] NA -0.04074
 [35,] NA -0.10395
 [36,] NA -0.23597
 [37,] NA -0.34605
 [38,] NA -0.54529
 [39,] NA -0.48625
 [40,] NA -0.45262
 [41,] NA -0.23045
 [42,] NA -0.51938
 [43,] NA  0.50512
 [44,] NA  2.54566
 [45,] NA  0.41171
 [46,] NA  0.28164
 [47,] NA -0.44107
 [48,] NA -0.40461
 [49,] NA -0.14778
 [50,] NA -0.54324
 [51,] NA -0.50561
 [52,] NA -0.54727
 [53,] NA -0.54660
 [54,] NA  0.68388
 [55,] NA -0.51429
 [56,] NA  0.96440
 [57,] NA  1.02947
 [58,] NA -0.32307
 [59,] NA -0.53772
 [60,] NA -0.51714
 [61,] NA -0.45303
 [62,] NA -0.38188
 [63,] NA -0.47480
 [64,] NA  0.13442
 [65,] NA  0.20757
 [66,] NA -0.48723
 [67,] NA -0.41571
 [68,] NA -0.54596
 [69,] NA  0.01151
 [70,] NA  2.21588
 [71,] NA -0.38926
 [72,] NA  2.95855
 [73,] NA  0.11734
 [74,] NA -0.21707
 [75,] NA -0.23654
 [76,] NA  0.14383
 [77,] NA -0.49448
 [78,] NA  0.43208
 [79,] NA -0.52619
 [80,] NA -0.53512
 [81,] NA -0.54779
 [82,] NA -0.45020
 [83,] NA -0.45746
 [84,] NA -0.27477
 [85,] NA -0.51584
 [86,] NA -0.47542
 [87,] NA  0.24329
 [88,] NA -0.42327
 [89,] NA -0.47795
 [90,] NA  0.32003
 [91,] NA  0.10125
 [92,] NA -0.35005
 [93,] NA -0.51033
 [94,] NA -0.28855
 [95,] NA  0.66961
 [96,] NA -0.31088
 [97,] NA  2.59831
 [98,] NA  0.99677
 [99,] NA -0.51128
[100,] NA  0.14497

> 
> # with analytical gradients and Hessians
> mlghFix <- maxLik( llf, gf, hf, start = startValFix, activePar = !isFixed )
> all.equal( mlgFix, mlghFix, tolerance = 1e-3 )
[1] TRUE
> mlgFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -60.02
> mlghFix[[4]]
      mu  sigma
mu    NA     NA
sigma NA -60.02
> 
> ## BHHH method with fixed parameters
> mlFixBHHH <- maxLik( llfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> mlFixBHHH1 <- maxLik( llfInd, start = startValFix, activePar = 2,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH1, tolerance = 1e-3 )
[1] TRUE
> mlFixBHHH2 <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH2, tolerance = 1e-3 )
[1] TRUE
> mlFixBHHH3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH3, tolerance = 1e-3 )
[1] TRUE
> mlFixBHHH4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "BHHH" )
> all.equal( mlFixBHHH, mlFixBHHH4, tolerance = 1e-3 )
[1] TRUE
> print( mlFixBHHH )
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.1 (1 free parameter(s))
Estimate(s): 1 1.825 
> summary( mlFixBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.134    13.7  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlFixBHHH )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixBHHH )
[1] 406.2
> coef( mlFixBHHH )
   mu sigma 
1.000 1.825 
> condiNumber( mlFixBHHH )
sigma 	 1 
> hessian( mlFixBHHH )
      mu  sigma
mu    NA     NA
sigma NA -55.98
attr(,"type")
[1] "BHHH"
> logLik( mlFixBHHH )
[1] -202.1
> maximType( mlFixBHHH )
[1] "BHHH maximisation"
> nIter( mlFixBHHH )
[1] 10
> nParam( mlFixBHHH )
[1] 2
> returnCode( mlFixBHHH )
[1] 2
> returnMessage( mlFixBHHH )
[1] "successive function values within tolerance limit"
> vcov( mlFixBHHH )
      mu   sigma
mu     0 0.00000
sigma  0 0.01786
> logLik( summary( mlFixBHHH ) )
[1] -202.1
> all.equal( mlFix[ -c( 5, 6, 9, 10 ) ], mlFixBHHH[ -c( 5, 6, 9, 10, 11 ) ],
+    tolerance = 1e-3 )
[1] "Component 4: Attributes: < Length mismatch: comparison on first 2 components >"
[2] "Component 4: Mean relative difference: 0.06648"                                
> mlFix[[ 3 ]]
       mu     sigma 
       NA 2.842e-08 
> mlFixBHHH[[ 3 ]]
        mu      sigma 
        NA -8.457e-06 
> mlFix[[ 4 ]]
      mu  sigma
mu    NA     NA
sigma NA -59.97
> mlFixBHHH[[ 4 ]]
      mu  sigma
mu    NA     NA
sigma NA -55.98
attr(,"type")
[1] "BHHH"
> mlFixBHHH[ 11 ]
$gradientObs
       mu    sigma
  [1,] NA -0.34124
  [2,] NA -0.51297
  [3,] NA  1.04982
  [4,] NA -0.54454
  [5,] NA -0.53682
  [6,] NA  1.38641
  [7,] NA -0.40811
  [8,] NA  0.50456
  [9,] NA -0.23759
 [10,] NA -0.41720
 [11,] NA  0.43749
 [12,] NA -0.46267
 [13,] NA -0.44219
 [14,] NA -0.53975
 [15,] NA -0.34464
 [16,] NA  1.55186
 [17,] NA -0.38482
 [18,] NA  1.99541
 [19,] NA -0.22435
 [20,] NA -0.40082
 [21,] NA  0.20199
 [22,] NA -0.51656
 [23,] NA  0.14441
 [24,] NA -0.19845
 [25,] NA -0.29091
 [26,] NA  1.32295
 [27,] NA -0.08627
 [28,] NA -0.53234
 [29,] NA  0.30398
 [30,] NA  0.48593
 [31,] NA -0.42821
 [32,] NA -0.49055
 [33,] NA -0.02093
 [34,] NA -0.04074
 [35,] NA -0.10395
 [36,] NA -0.23597
 [37,] NA -0.34605
 [38,] NA -0.54529
 [39,] NA -0.48625
 [40,] NA -0.45262
 [41,] NA -0.23045
 [42,] NA -0.51938
 [43,] NA  0.50512
 [44,] NA  2.54566
 [45,] NA  0.41171
 [46,] NA  0.28164
 [47,] NA -0.44107
 [48,] NA -0.40461
 [49,] NA -0.14778
 [50,] NA -0.54324
 [51,] NA -0.50561
 [52,] NA -0.54727
 [53,] NA -0.54660
 [54,] NA  0.68388
 [55,] NA -0.51429
 [56,] NA  0.96440
 [57,] NA  1.02947
 [58,] NA -0.32307
 [59,] NA -0.53772
 [60,] NA -0.51714
 [61,] NA -0.45303
 [62,] NA -0.38188
 [63,] NA -0.47480
 [64,] NA  0.13442
 [65,] NA  0.20757
 [66,] NA -0.48723
 [67,] NA -0.41571
 [68,] NA -0.54596
 [69,] NA  0.01151
 [70,] NA  2.21588
 [71,] NA -0.38926
 [72,] NA  2.95855
 [73,] NA  0.11733
 [74,] NA -0.21707
 [75,] NA -0.23654
 [76,] NA  0.14383
 [77,] NA -0.49448
 [78,] NA  0.43208
 [79,] NA -0.52619
 [80,] NA -0.53512
 [81,] NA -0.54779
 [82,] NA -0.45020
 [83,] NA -0.45746
 [84,] NA -0.27477
 [85,] NA -0.51584
 [86,] NA -0.47542
 [87,] NA  0.24329
 [88,] NA -0.42327
 [89,] NA -0.47795
 [90,] NA  0.32003
 [91,] NA  0.10125
 [92,] NA -0.35005
 [93,] NA -0.51033
 [94,] NA -0.28855
 [95,] NA  0.66961
 [96,] NA -0.31088
 [97,] NA  2.59831
 [98,] NA  0.99677
 [99,] NA -0.51128
[100,] NA  0.14497

> nObs( mlFixBHHH )
[1] 100
> 
> # with analytical gradients
> mlgFixBHHH <- maxLik( llfInd, gfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> mlgFixBHHH1 <- maxLik( llfInd, gfInd, start = startValFix, activePar = 2,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH1, tolerance = 1e-3 )
[1] TRUE
> mlgFixBHHH2 <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH2, tolerance = 1e-3 )
[1] TRUE
> mlgFixBHHH3 <- maxLik( llfInd, gfInd, start = startValFix, fixed = "mu",
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH3, tolerance = 1e-3 )
[1] TRUE
> mlgFixBHHH4 <- maxLik( llfInd, gfInd, start = startValFix, fixed = 1,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlgFixBHHH4, tolerance = 1e-3 )
[1] TRUE
> summary( mlgFixBHHH )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.134    13.7  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFixBHHH, mlgFixBHHH, tolerance = 1e-3 )
[1] TRUE
> mlgFixBHHH2 <- maxLik( llf, gfInd, start = startValFix, activePar = !isFixed,
+    method = "BHHH")
> all.equal( mlgFixBHHH, mlgFixBHHH2, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessians
> mlghFixBHHH <- maxLik( llfInd, gfInd, hf, start = startValFix, activePar = !isFixed,
+    method = "BHHH" )
> all.equal( mlgFixBHHH, mlghFixBHHH, tolerance = 1e-3 )
[1] TRUE
> 
> ## BFGS method with fixed parameters
> mlFixBfgs <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> mlFixBfgs3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlFixBfgs, mlFixBfgs3, tolerance = 1e-3 )
[1] TRUE
> mlFixBfgs4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlFixBfgs, mlFixBfgs4, tolerance = 1e-3 )
[1] TRUE
> print( mlFixBfgs )
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 (1 free parameter(s))
Estimate(s): 1 1.825 
> summary( mlFixBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlFixBfgs )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixBfgs )
[1] 406.2
> coef( mlFixBfgs )
   mu sigma 
1.000 1.825 
> condiNumber( mlFixBfgs )
sigma 	 1 
> hessian( mlFixBfgs )
          mu  sigma
mu    -30.01  -5.94
sigma  -5.94 -60.03
> logLik( mlFixBfgs )
[1] -202.1
> maximType( mlFixBfgs )
[1] "BFGS maximisation"
> nIter( mlFixBfgs )
function 
      27 
> nParam( mlFixBfgs )
[1] 2
> returnCode( mlFixBfgs )
[1] 0
> returnMessage( mlFixBfgs )
[1] "successful convergence "
> vcov( mlFixBfgs )
      mu   sigma
mu     0 0.00000
sigma  0 0.01666
> logLik( summary( mlFixBfgs ) )
[1] -202.1
> all.equal( mlghFix[ -c( 5, 6, 9, 10 ) ], mlFixBfgs[ -c( 5, 6, 9, 10, 11 ) ],
+    tolerance = 1e-3 )
[1] "Component 3: 'is.NA' value mismatch: 0 in current 1 in target"
[2] "Component 4: 'is.NA' value mismatch: 0 in current 3 in target"
> mlIndFixBfgs <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> all.equal( mlFixBfgs[ -9 ], mlIndFixBfgs[ -c(9,12) ], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001115"
> print(formatC(mlIndFixBfgs$gradientObs, format="f", digits=4, width=7), quote=FALSE)
       mu      sigma  
  [1,] -0.3364 -0.3412
  [2,] -0.1381 -0.5130
  [3,]  0.9355  1.0498
  [4,]  0.0423 -0.5445
  [5,]  0.0776 -0.5368
  [6,]  1.0294  1.3864
  [7,]  0.2766 -0.4081
  [8,] -0.7593  0.5046
  [9,] -0.4122 -0.2376
 [10,] -0.2675 -0.4172
 [11,]  0.7347  0.4375
 [12,]  0.2160 -0.4627
 [13,]  0.2405 -0.4422
 [14,]  0.0664 -0.5398
 [15,] -0.3336 -0.3446
 [16,]  1.0725  1.5519
 [17,]  0.2988 -0.3848
 [18,] -1.1803  1.9954
 [19,]  0.4209 -0.2243
 [20,] -0.2838 -0.4008
 [21,] -0.6409  0.2020
 [22,] -0.1308 -0.5166
 [23,] -0.6158  0.1444
 [24,] -0.4375 -0.1985
 [25,] -0.3751 -0.2909
 [26,] -1.0123  1.3229
 [27,]  0.5028 -0.0863
 [28,]  0.0921 -0.5323
 [29,] -0.6831  0.3040
 [30,]  0.7525  0.4859
 [31,]  0.2560 -0.4282
 [32,] -0.1771 -0.4906
 [33,]  0.5372 -0.0209
 [34,]  0.5270 -0.0407
 [35,]  0.4931 -0.1039
 [36,]  0.4133 -0.2360
 [37,]  0.3325 -0.3460
 [38,] -0.0372 -0.5453
 [39,] -0.1836 -0.4863
 [40,] -0.2284 -0.4526
 [41,] -0.4170 -0.2305
 [42,] -0.1248 -0.5194
 [43,] -0.7595  0.5051
 [44,]  1.3018  2.5457
 [45,]  0.7250  0.4117
 [46,] -0.6741  0.2816
 [47,] -0.2418 -0.4411
 [48,] -0.2801 -0.4046
 [49,]  0.4681 -0.1478
 [50,] -0.0500 -0.5432
 [51,]  0.1520 -0.5056
 [52,] -0.0171 -0.5473
 [53,] -0.0257 -0.5466
 [54,]  0.8214  0.6839
 [55,] -0.1355 -0.5143
 [56,]  0.9102  0.9644
 [57,] -0.9295  1.0295
 [58,]  0.3509 -0.3231
 [59,]  0.0743 -0.5377
 [60,]  0.1296 -0.5171
 [61,]  0.2279 -0.4530
 [62,] -0.3015 -0.3819
 [63,] -0.2000 -0.4748
 [64,] -0.6113  0.1344
 [65,] -0.6433  0.2076
 [66,]  0.1822 -0.4872
 [67,]  0.2690 -0.4157
 [68,]  0.0318 -0.5460
 [69,]  0.5535  0.0115
 [70,]  1.2304  2.2159
 [71,] -0.2947 -0.3893
 [72,] -1.3859  2.9585
 [73,]  0.6036  0.1173
 [74,] -0.4257 -0.2171
 [75,] -0.4129 -0.2365
 [76,]  0.6155  0.1438
 [77,] -0.1709 -0.4945
 [78,] -0.7327  0.4321
 [79,]  0.1088 -0.5262
 [80,] -0.0834 -0.5351
 [81,]  0.0035 -0.5478
 [82,]  0.2312 -0.4502
 [83,] -0.2225 -0.4575
 [84,]  0.3867 -0.2748
 [85,] -0.1323 -0.5158
 [86,]  0.1991 -0.4754
 [87,]  0.6583  0.2433
 [88,]  0.2612 -0.4233
 [89,] -0.1956 -0.4780
 [90,]  0.6895  0.3200
 [91,]  0.5963  0.1013
 [92,]  0.3291 -0.3500
 [93,]  0.1433 -0.5103
 [94,] -0.3769 -0.2885
 [95,]  0.8166  0.6696
 [96,] -0.3603 -0.3109
 [97,]  1.3128  2.5983
 [98,]  0.9199  0.9968
 [99,] -0.1415 -0.5113
[100,] -0.6160  0.1450
>                            # print fradient, only 4 digits to avoid clutter in R CMD tests
> mlIndFixBfgs3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlIndFixBfgs, mlIndFixBfgs3, tolerance = 1e-3 )
[1] TRUE
> mlIndFixBfgs4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlIndFixBfgs, mlIndFixBfgs4, tolerance = 1e-3 )
[1] TRUE
> nObs( mlIndFixBfgs )
[1] 100
> 
> # with analytical gradients
> mlgFixBfgs <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> mlgFixBfgs3 <- maxLik( llf, gf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlgFixBfgs3, tolerance = 1e-3 )
[1] TRUE
> mlgFixBfgs4 <- maxLik( llf, gf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlgFixBfgs4, tolerance = 1e-3 )
[1] TRUE
> summary( mlgFixBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 27 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFixBfgs[ -9 ], mlgFixBfgs[ -9 ], tolerance = 1e-3 )
[1] TRUE
> mlgIndFixBfgs <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "BFGS")
> all.equal( mlgFixBfgs[ ], mlgIndFixBfgs[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlgIndFixBfgs[ 12 ]
$gradientObs
             mu    sigma
  [1,] -0.33639 -0.34124
  [2,] -0.13815 -0.51297
  [3,]  0.93552  1.04982
  [4,]  0.04232 -0.54454
  [5,]  0.07760 -0.53682
  [6,]  1.02936  1.38641
  [7,]  0.27664 -0.40811
  [8,] -0.75927  0.50456
  [9,] -0.41224 -0.23759
 [10,] -0.26748 -0.41720
 [11,]  0.73468  0.43749
 [12,]  0.21596 -0.46267
 [13,]  0.24054 -0.44219
 [14,]  0.06643 -0.53975
 [15,] -0.33361 -0.34464
 [16,]  1.07248  1.55187
 [17,]  0.29880 -0.38482
 [18,] -1.18034  1.99542
 [19,]  0.42094 -0.22435
 [20,] -0.28376 -0.40082
 [21,] -0.64089  0.20199
 [22,] -0.13083 -0.51656
 [23,] -0.61579  0.14441
 [24,] -0.43747 -0.19845
 [25,] -0.37514 -0.29091
 [26,] -1.01233  1.32295
 [27,]  0.50283 -0.08626
 [28,]  0.09205 -0.53234
 [29,] -0.68309  0.30398
 [30,]  0.75252  0.48593
 [31,]  0.25596 -0.42821
 [32,] -0.17710 -0.49055
 [33,]  0.53724 -0.02093
 [34,]  0.52704 -0.04074
 [35,]  0.49310 -0.10395
 [36,]  0.41331 -0.23597
 [37,]  0.33245 -0.34605
 [38,] -0.03716 -0.54529
 [39,] -0.18363 -0.48625
 [40,] -0.22835 -0.45262
 [41,] -0.41695 -0.23045
 [42,] -0.12479 -0.51938
 [43,] -0.75947  0.50512
 [44,]  1.30178  2.54566
 [45,]  0.72500  0.41171
 [46,] -0.67408  0.28164
 [47,] -0.24181 -0.44107
 [48,] -0.28008 -0.40461
 [49,]  0.46812 -0.14778
 [50,] -0.05004 -0.54324
 [51,]  0.15204 -0.50561
 [52,] -0.01713 -0.54727
 [53,] -0.02573 -0.54660
 [54,]  0.82142  0.68388
 [55,] -0.13550 -0.51429
 [56,]  0.91017  0.96440
 [57,] -0.92954  1.02947
 [58,]  0.35088 -0.32307
 [59,]  0.07434 -0.53772
 [60,]  0.12961 -0.51714
 [61,]  0.22785 -0.45303
 [62,] -0.30149 -0.38188
 [63,] -0.19999 -0.47480
 [64,] -0.61134  0.13442
 [65,] -0.64328  0.20757
 [66,]  0.18217 -0.48723
 [67,]  0.26901 -0.41571
 [68,]  0.03181 -0.54596
 [69,]  0.55353  0.01151
 [70,]  1.23043  2.21588
 [71,] -0.29471 -0.38926
 [72,] -1.38593  2.95855
 [73,]  0.60363  0.11734
 [74,] -0.42565 -0.21707
 [75,] -0.41293 -0.23654
 [76,]  0.61553  0.14383
 [77,] -0.17092 -0.49448
 [78,] -0.73266  0.43208
 [79,]  0.10882 -0.52619
 [80,] -0.08336 -0.53512
 [81,]  0.00346 -0.54779
 [82,]  0.23124 -0.45020
 [83,] -0.22247 -0.45746
 [84,]  0.38675 -0.27477
 [85,] -0.13233 -0.51584
 [86,]  0.19913 -0.47542
 [87,]  0.65831  0.24329
 [88,]  0.26119 -0.42327
 [89,] -0.19562 -0.47795
 [90,]  0.68950  0.32003
 [91,]  0.59629  0.10125
 [92,]  0.32914 -0.35005
 [93,]  0.14328 -0.51033
 [94,] -0.37686 -0.28855
 [95,]  0.81665  0.66961
 [96,] -0.36027 -0.31088
 [97,]  1.31281  2.59831
 [98,]  0.91985  0.99677
 [99,] -0.14146 -0.51128
[100,] -0.61604  0.14497

> mlgIndFixBfgs3 <- maxLik( llfInd, gfInd, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlgIndFixBfgs, mlgIndFixBfgs3, tolerance = 1e-3 )
[1] TRUE
> mlgIndFixBfgs4 <- maxLik( llfInd, gfInd, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlgIndFixBfgs, mlgIndFixBfgs4, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessians
> mlghFixBfgs <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "BFGS" )
> all.equal( mlgFixBfgs, mlghFixBfgs, tolerance = 1e-3 )
[1] TRUE
> mlghFixBfgs3 <- maxLik( llf, gf, hf, start = startValFix, fixed = "mu",
+    method = "BFGS" )
> all.equal( mlghFixBfgs, mlghFixBfgs3, tolerance = 1e-3 )
[1] TRUE
> mlghFixBfgs4 <- maxLik( llf, gf, hf, start = startValFix, fixed = 1,
+    method = "BFGS" )
> all.equal( mlghFixBfgs, mlghFixBfgs4, tolerance = 1e-3 )
[1] TRUE
> 
> ## NM method with fixed parameters
> mlFixNm <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> mlFixNm3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm, mlFixNm3, tolerance = 1e-3 )
[1] TRUE
> mlFixNm4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm, mlFixNm4, tolerance = 1e-3 )
[1] TRUE
> print( mlFixNm )
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 (1 free parameter(s))
Estimate(s): 1 1.825 
> summary( mlFixNm )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.2  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlFixNm )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixNm )
[1] 406.2
> coef( mlFixNm )
   mu sigma 
1.000 1.825 
> condiNumber( mlFixNm )
sigma 	 1 
> hessian( mlFixNm )
          mu  sigma
mu    -30.01  -5.94
sigma  -5.94 -60.06
> logLik( mlFixNm )
[1] -202.1
> maximType( mlFixNm )
[1] "Nelder-Mead maximisation"
> nIter( mlFixNm )
function 
      28 
> nParam( mlFixNm )
[1] 2
> returnCode( mlFixNm )
[1] 0
> returnMessage( mlFixNm )
[1] "successful convergence "
> vcov( mlFixNm )
      mu   sigma
mu     0 0.00000
sigma  0 0.01665
> logLik( summary( mlFixNm ) )
[1] -202.1
> all.equal( mlFixBfgs[ -c( 9, 10 ) ], mlFixNm[ -c( 9, 10 ) ], tolerance = 1e-3 )
[1] TRUE
> mlIndFixNm <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlFixNm[ ], mlIndFixNm[ -12 ], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.002035"
> mlIndFixNm[ 12 ]
$gradientObs
             mu    sigma
  [1,] -0.33641 -0.34124
  [2,] -0.13816 -0.51298
  [3,]  0.93558  1.04997
  [4,]  0.04232 -0.54456
  [5,]  0.07760 -0.53684
  [6,]  1.02944  1.38661
  [7,]  0.27666 -0.40812
  [8,] -0.75933  0.50466
  [9,] -0.41227 -0.23757
 [10,] -0.26750 -0.41721
 [11,]  0.73473  0.43757
 [12,]  0.21597 -0.46269
 [13,]  0.24056 -0.44220
 [14,]  0.06644 -0.53977
 [15,] -0.33363 -0.34464
 [16,]  1.07256  1.55208
 [17,]  0.29883 -0.38483
 [18,] -1.18042  1.99567
 [19,]  0.42098 -0.22433
 [20,] -0.28378 -0.40082
 [21,] -0.64094  0.20205
 [22,] -0.13084 -0.51658
 [23,] -0.61584  0.14447
 [24,] -0.43750 -0.19843
 [25,] -0.37517 -0.29090
 [26,] -1.01241  1.32313
 [27,]  0.50287 -0.08623
 [28,]  0.09206 -0.53236
 [29,] -0.68314  0.30406
 [30,]  0.75258  0.48603
 [31,]  0.25598 -0.42822
 [32,] -0.17711 -0.49057
 [33,]  0.53728 -0.02089
 [34,]  0.52708 -0.04070
 [35,]  0.49314 -0.10392
 [36,]  0.41334 -0.23596
 [37,]  0.33248 -0.34605
 [38,] -0.03716 -0.54531
 [39,] -0.18365 -0.48626
 [40,] -0.22837 -0.45263
 [41,] -0.41698 -0.23044
 [42,] -0.12480 -0.51940
 [43,] -0.75953  0.50521
 [44,]  1.30187  2.54598
 [45,]  0.72506  0.41179
 [46,] -0.67412  0.28171
 [47,] -0.24182 -0.44108
 [48,] -0.28010 -0.40461
 [49,]  0.46816 -0.14775
 [50,] -0.05004 -0.54326
 [51,]  0.15205 -0.50563
 [52,] -0.01713 -0.54729
 [53,] -0.02573 -0.54662
 [54,]  0.82148  0.68399
 [55,] -0.13551 -0.51431
 [56,]  0.91023  0.96455
 [57,] -0.92961  1.02963
 [58,]  0.35090 -0.32306
 [59,]  0.07434 -0.53774
 [60,]  0.12961 -0.51716
 [61,]  0.22787 -0.45304
 [62,] -0.30151 -0.38188
 [63,] -0.20000 -0.47481
 [64,] -0.61138  0.13448
 [65,] -0.64332  0.20763
 [66,]  0.18219 -0.48724
 [67,]  0.26903 -0.41571
 [68,]  0.03181 -0.54598
 [69,]  0.55357  0.01155
 [70,]  1.23052  2.21616
 [71,] -0.29473 -0.38926
 [72,] -1.38603  2.95892
 [73,]  0.60368  0.11739
 [74,] -0.42568 -0.21705
 [75,] -0.41296 -0.23653
 [76,]  0.61558  0.14388
 [77,] -0.17093 -0.49450
 [78,] -0.73271  0.43217
 [79,]  0.10882 -0.52621
 [80,] -0.08337 -0.53514
 [81,]  0.00346 -0.54781
 [82,]  0.23126 -0.45021
 [83,] -0.22248 -0.45747
 [84,]  0.38677 -0.27476
 [85,] -0.13234 -0.51586
 [86,]  0.19915 -0.47543
 [87,]  0.65836  0.24336
 [88,]  0.26121 -0.42328
 [89,] -0.19563 -0.47797
 [90,]  0.68955  0.32011
 [91,]  0.59633  0.10130
 [92,]  0.32916 -0.35005
 [93,]  0.14329 -0.51035
 [94,] -0.37689 -0.28854
 [95,]  0.81671  0.66972
 [96,] -0.36029 -0.31087
 [97,]  1.31290  2.59863
 [98,]  0.91992  0.99691
 [99,] -0.14147 -0.51129
[100,] -0.61609  0.14503

> mlIndFixNm3 <- maxLik( llfInd, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlIndFixNm, mlIndFixNm3, tolerance = 1e-3 )
[1] TRUE
> mlIndFixNm4 <- maxLik( llfInd, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlIndFixNm, mlIndFixNm4, tolerance = 1e-3 )
[1] TRUE
> nObs( mlIndFixNm )
[1] 100
> 
> # with analytical gradients
> mlgFixNm <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> mlgFixNm3 <- maxLik( llf, gf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlgFixNm3, tolerance = 1e-3 )
[1] TRUE
> mlgFixNm4 <- maxLik( llf, gf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlgFixNm4, tolerance = 1e-3 )
[1] TRUE
> summary( mlgFixNm )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 28 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFixNm, mlgFixNm, tolerance = 1e-3 )
[1] TRUE
> mlgIndFixNm <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "NM")
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm[ ], mlgIndFixNm[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlgIndFixNm[ 12 ]
$gradientObs
             mu    sigma
  [1,] -0.33641 -0.34124
  [2,] -0.13816 -0.51298
  [3,]  0.93558  1.04997
  [4,]  0.04232 -0.54456
  [5,]  0.07760 -0.53684
  [6,]  1.02944  1.38661
  [7,]  0.27666 -0.40812
  [8,] -0.75933  0.50466
  [9,] -0.41227 -0.23757
 [10,] -0.26750 -0.41721
 [11,]  0.73473  0.43757
 [12,]  0.21597 -0.46269
 [13,]  0.24056 -0.44220
 [14,]  0.06644 -0.53977
 [15,] -0.33363 -0.34464
 [16,]  1.07256  1.55208
 [17,]  0.29883 -0.38483
 [18,] -1.18042  1.99567
 [19,]  0.42098 -0.22433
 [20,] -0.28378 -0.40082
 [21,] -0.64094  0.20205
 [22,] -0.13084 -0.51658
 [23,] -0.61584  0.14447
 [24,] -0.43750 -0.19843
 [25,] -0.37517 -0.29090
 [26,] -1.01241  1.32313
 [27,]  0.50287 -0.08623
 [28,]  0.09206 -0.53236
 [29,] -0.68314  0.30406
 [30,]  0.75258  0.48603
 [31,]  0.25598 -0.42822
 [32,] -0.17711 -0.49057
 [33,]  0.53728 -0.02089
 [34,]  0.52708 -0.04070
 [35,]  0.49314 -0.10392
 [36,]  0.41334 -0.23596
 [37,]  0.33248 -0.34605
 [38,] -0.03716 -0.54531
 [39,] -0.18365 -0.48626
 [40,] -0.22837 -0.45263
 [41,] -0.41698 -0.23044
 [42,] -0.12480 -0.51940
 [43,] -0.75953  0.50521
 [44,]  1.30187  2.54598
 [45,]  0.72506  0.41179
 [46,] -0.67412  0.28171
 [47,] -0.24182 -0.44108
 [48,] -0.28010 -0.40461
 [49,]  0.46816 -0.14775
 [50,] -0.05004 -0.54326
 [51,]  0.15205 -0.50563
 [52,] -0.01713 -0.54729
 [53,] -0.02573 -0.54662
 [54,]  0.82148  0.68399
 [55,] -0.13551 -0.51431
 [56,]  0.91023  0.96455
 [57,] -0.92961  1.02963
 [58,]  0.35090 -0.32306
 [59,]  0.07434 -0.53774
 [60,]  0.12961 -0.51716
 [61,]  0.22787 -0.45304
 [62,] -0.30151 -0.38188
 [63,] -0.20000 -0.47481
 [64,] -0.61138  0.13448
 [65,] -0.64332  0.20763
 [66,]  0.18219 -0.48724
 [67,]  0.26903 -0.41571
 [68,]  0.03181 -0.54598
 [69,]  0.55357  0.01155
 [70,]  1.23052  2.21616
 [71,] -0.29473 -0.38926
 [72,] -1.38603  2.95892
 [73,]  0.60368  0.11739
 [74,] -0.42568 -0.21705
 [75,] -0.41296 -0.23653
 [76,]  0.61558  0.14388
 [77,] -0.17093 -0.49450
 [78,] -0.73271  0.43217
 [79,]  0.10882 -0.52621
 [80,] -0.08337 -0.53514
 [81,]  0.00346 -0.54781
 [82,]  0.23126 -0.45021
 [83,] -0.22248 -0.45747
 [84,]  0.38677 -0.27476
 [85,] -0.13234 -0.51586
 [86,]  0.19915 -0.47543
 [87,]  0.65836  0.24336
 [88,]  0.26121 -0.42328
 [89,] -0.19563 -0.47797
 [90,]  0.68955  0.32011
 [91,]  0.59633  0.10130
 [92,]  0.32916 -0.35005
 [93,]  0.14329 -0.51035
 [94,] -0.37689 -0.28854
 [95,]  0.81671  0.66972
 [96,] -0.36029 -0.31087
 [97,]  1.31290  2.59863
 [98,]  0.91992  0.99691
 [99,] -0.14147 -0.51129
[100,] -0.61609  0.14503

> 
> # with unused Hessians
> mlghFixNm <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlgFixNm, mlghFixNm, tolerance = 1e-3 )
[1] TRUE
> mlghFixNm3 <- maxLik( llf, gf, hf, start = startValFix, fixed = "mu",
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlghFixNm, mlghFixNm3, tolerance = 1e-3 )
[1] TRUE
> mlghFixNm4 <- maxLik( llf, gf, hf, start = startValFix, fixed = 1,
+    method = "NM" )
Warning message:
In optim(par = start[!fixed], fn = logLikFunc, control = control,  :
  one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly
> all.equal( mlghFixNm, mlghFixNm4, tolerance = 1e-3 )
[1] TRUE
> 
> ## SANN method with fixed parameters
> mlFixSann <- maxLik( llf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> mlFixSann3 <- maxLik( llf, start = startValFix, fixed = "mu",
+    method = "SANN" )
> all.equal( mlFixSann, mlFixSann3, tolerance = 1e-3 )
[1] TRUE
> mlFixSann4 <- maxLik( llf, start = startValFix, fixed = 1,
+    method = "SANN" )
> all.equal( mlFixSann, mlFixSann4, tolerance = 1e-3 )
[1] TRUE
> print( mlFixSann )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 (1 free parameter(s))
Estimate(s): 1 1.825 
> summary( mlFixSann )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> activePar( mlFixSann )
   mu sigma 
FALSE  TRUE 
> AIC( mlFixSann )
[1] 406.2
> coef( mlFixSann )
   mu sigma 
1.000 1.825 
> condiNumber( mlFixSann )
sigma 	 1 
> hessian( mlFixSann )
          mu  sigma
mu    -29.98  -5.94
sigma  -5.94 -60.03
> logLik( mlFixSann )
[1] -202.1
> maximType( mlFixSann )
[1] "SANN maximisation"
> nIter( mlFixSann )
function 
   10000 
> nParam( mlFixSann )
[1] 2
> returnCode( mlFixSann )
[1] 0
> returnMessage( mlFixSann )
[1] "successful convergence "
> vcov( mlFixSann )
      mu   sigma
mu     0 0.00000
sigma  0 0.01666
> logLik( summary( mlFixSann ) )
[1] -202.1
> all.equal( mlFixBfgs[ -c( 9, 10 ) ], mlFixSann[ -c( 9, 10 ) ], 
+    tolerance = 1e-3 )
[1] TRUE
> mlIndFixSann <- maxLik( llfInd, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> all.equal( mlFixSann[ ], mlIndFixSann[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlIndFixSann[ 12 ]
$gradientObs
             mu    sigma
  [1,] -0.33640 -0.34124
  [2,] -0.13815 -0.51297
  [3,]  0.93553  1.04985
  [4,]  0.04232 -0.54454
  [5,]  0.07760 -0.53682
  [6,]  1.02938  1.38646
  [7,]  0.27664 -0.40811
  [8,] -0.75929  0.50458
  [9,] -0.41225 -0.23758
 [10,] -0.26749 -0.41721
 [11,]  0.73469  0.43751
 [12,]  0.21596 -0.46268
 [13,]  0.24054 -0.44219
 [14,]  0.06643 -0.53976
 [15,] -0.33361 -0.34464
 [16,]  1.07250  1.55192
 [17,]  0.29881 -0.38483
 [18,] -1.18036  1.99548
 [19,]  0.42095 -0.22434
 [20,] -0.28377 -0.40082
 [21,] -0.64091  0.20200
 [22,] -0.13083 -0.51657
 [23,] -0.61581  0.14442
 [24,] -0.43748 -0.19845
 [25,] -0.37515 -0.29091
 [26,] -1.01235  1.32299
 [27,]  0.50284 -0.08626
 [28,]  0.09205 -0.53234
 [29,] -0.68311  0.30400
 [30,]  0.75254  0.48596
 [31,]  0.25596 -0.42822
 [32,] -0.17710 -0.49056
 [33,]  0.53725 -0.02092
 [34,]  0.52705 -0.04073
 [35,]  0.49311 -0.10394
 [36,]  0.41332 -0.23597
 [37,]  0.33246 -0.34605
 [38,] -0.03716 -0.54529
 [39,] -0.18364 -0.48625
 [40,] -0.22836 -0.45262
 [41,] -0.41696 -0.23045
 [42,] -0.12479 -0.51939
 [43,] -0.75949  0.50514
 [44,]  1.30180  2.54574
 [45,]  0.72502  0.41173
 [46,] -0.67409  0.28166
 [47,] -0.24181 -0.44107
 [48,] -0.28009 -0.40461
 [49,]  0.46813 -0.14777
 [50,] -0.05004 -0.54324
 [51,]  0.15204 -0.50561
 [52,] -0.01713 -0.54728
 [53,] -0.02573 -0.54660
 [54,]  0.82143  0.68390
 [55,] -0.13551 -0.51429
 [56,]  0.91018  0.96444
 [57,] -0.92956  1.02951
 [58,]  0.35088 -0.32307
 [59,]  0.07434 -0.53773
 [60,]  0.12961 -0.51715
 [61,]  0.22786 -0.45304
 [62,] -0.30149 -0.38188
 [63,] -0.19999 -0.47480
 [64,] -0.61135  0.13444
 [65,] -0.64329  0.20759
 [66,]  0.18218 -0.48723
 [67,]  0.26901 -0.41571
 [68,]  0.03181 -0.54597
 [69,]  0.55354  0.01152
 [70,]  1.23046  2.21595
 [71,] -0.29472 -0.38926
 [72,] -1.38596  2.95864
 [73,]  0.60364  0.11735
 [74,] -0.42566 -0.21707
 [75,] -0.41294 -0.23654
 [76,]  0.61555  0.14384
 [77,] -0.17092 -0.49448
 [78,] -0.73267  0.43210
 [79,]  0.10882 -0.52620
 [80,] -0.08336 -0.53513
 [81,]  0.00346 -0.54779
 [82,]  0.23124 -0.45020
 [83,] -0.22247 -0.45747
 [84,]  0.38675 -0.27477
 [85,] -0.13234 -0.51584
 [86,]  0.19913 -0.47543
 [87,]  0.65832  0.24331
 [88,]  0.26119 -0.42328
 [89,] -0.19562 -0.47796
 [90,]  0.68951  0.32005
 [91,]  0.59630  0.10126
 [92,]  0.32915 -0.35005
 [93,]  0.14329 -0.51033
 [94,] -0.37687 -0.28855
 [95,]  0.81666  0.66964
 [96,] -0.36027 -0.31087
 [97,]  1.31283  2.59839
 [98,]  0.91987  0.99680
 [99,] -0.14147 -0.51128
[100,] -0.61606  0.14499

> nObs( mlIndFixSann )
[1] 100
> 
> # with analytical gradients
> mlgFixSann <- maxLik( llf, gf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> summary( mlgFixSann )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -202.1 
1  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.000      0.000      NA      NA    
sigma    1.825      0.129    14.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( mlFixSann, mlgFixSann, tolerance = 1e-3 )
[1] TRUE
> mlgIndFixSann <- maxLik( llfInd, gfInd, start = startValFix, fixed = isFixed,
+    method = "SANN")
> all.equal( mlgFixSann[ ], mlgIndFixSann[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlgIndFixSann[ 12 ]
$gradientObs
             mu    sigma
  [1,] -0.33640 -0.34124
  [2,] -0.13815 -0.51297
  [3,]  0.93553  1.04985
  [4,]  0.04232 -0.54454
  [5,]  0.07760 -0.53682
  [6,]  1.02938  1.38646
  [7,]  0.27664 -0.40811
  [8,] -0.75929  0.50458
  [9,] -0.41225 -0.23758
 [10,] -0.26749 -0.41721
 [11,]  0.73469  0.43751
 [12,]  0.21596 -0.46268
 [13,]  0.24054 -0.44219
 [14,]  0.06643 -0.53976
 [15,] -0.33361 -0.34464
 [16,]  1.07250  1.55192
 [17,]  0.29881 -0.38483
 [18,] -1.18036  1.99548
 [19,]  0.42095 -0.22434
 [20,] -0.28377 -0.40082
 [21,] -0.64091  0.20200
 [22,] -0.13083 -0.51657
 [23,] -0.61581  0.14442
 [24,] -0.43748 -0.19845
 [25,] -0.37515 -0.29091
 [26,] -1.01235  1.32299
 [27,]  0.50284 -0.08626
 [28,]  0.09205 -0.53234
 [29,] -0.68311  0.30400
 [30,]  0.75254  0.48596
 [31,]  0.25596 -0.42822
 [32,] -0.17710 -0.49056
 [33,]  0.53725 -0.02092
 [34,]  0.52705 -0.04073
 [35,]  0.49311 -0.10394
 [36,]  0.41332 -0.23597
 [37,]  0.33246 -0.34605
 [38,] -0.03716 -0.54529
 [39,] -0.18364 -0.48625
 [40,] -0.22836 -0.45262
 [41,] -0.41696 -0.23045
 [42,] -0.12479 -0.51939
 [43,] -0.75949  0.50514
 [44,]  1.30180  2.54574
 [45,]  0.72502  0.41173
 [46,] -0.67409  0.28166
 [47,] -0.24181 -0.44107
 [48,] -0.28009 -0.40461
 [49,]  0.46813 -0.14777
 [50,] -0.05004 -0.54324
 [51,]  0.15204 -0.50561
 [52,] -0.01713 -0.54728
 [53,] -0.02573 -0.54660
 [54,]  0.82143  0.68390
 [55,] -0.13551 -0.51429
 [56,]  0.91018  0.96444
 [57,] -0.92956  1.02951
 [58,]  0.35088 -0.32307
 [59,]  0.07434 -0.53773
 [60,]  0.12961 -0.51715
 [61,]  0.22786 -0.45304
 [62,] -0.30149 -0.38188
 [63,] -0.19999 -0.47480
 [64,] -0.61135  0.13444
 [65,] -0.64329  0.20759
 [66,]  0.18218 -0.48723
 [67,]  0.26901 -0.41571
 [68,]  0.03181 -0.54597
 [69,]  0.55354  0.01152
 [70,]  1.23046  2.21595
 [71,] -0.29472 -0.38926
 [72,] -1.38596  2.95864
 [73,]  0.60364  0.11735
 [74,] -0.42566 -0.21707
 [75,] -0.41294 -0.23654
 [76,]  0.61555  0.14384
 [77,] -0.17092 -0.49448
 [78,] -0.73267  0.43210
 [79,]  0.10882 -0.52620
 [80,] -0.08336 -0.53513
 [81,]  0.00346 -0.54779
 [82,]  0.23124 -0.45020
 [83,] -0.22247 -0.45747
 [84,]  0.38675 -0.27477
 [85,] -0.13234 -0.51584
 [86,]  0.19913 -0.47543
 [87,]  0.65832  0.24331
 [88,]  0.26119 -0.42328
 [89,] -0.19562 -0.47796
 [90,]  0.68951  0.32005
 [91,]  0.59630  0.10126
 [92,]  0.32915 -0.35005
 [93,]  0.14329 -0.51033
 [94,] -0.37687 -0.28855
 [95,]  0.81666  0.66964
 [96,] -0.36027 -0.31087
 [97,]  1.31283  2.59839
 [98,]  0.91987  0.99680
 [99,] -0.14147 -0.51128
[100,] -0.61606  0.14499

> 
> # with unused Hessians
> mlghFixSann <- maxLik( llf, gf, hf, start = startValFix, fixed = isFixed,
+    method = "SANN" )
> all.equal( mlgFixSann, mlghFixSann, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ############### with parameter constraints ###############
> A <- matrix( -1, nrow = 1, ncol = 2 )
> 
> 
> ############### inequality constraints ###############
> inEq <- list( ineqA = A, ineqB = 2.5 )
> 
> ## NR method with inequality constraints
> try( maxLik( llf, start = startVal, constraints = inEq, method = "NR" ) )
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,  : 
  Inequality constraints not implemented for maxNR
> 
> ## BHHH method with inequality constraints
> try( maxLik( llf, start = startVal, constraints = inEq, method = "BHHH" ) )
Error in maxNR(fn = fn, grad = grad, hess = hess, start = start, iterlim = iterlim,  : 
  Inequality constraints not implemented for maxNR
> 
> ## BFGS method with inequality constraints
> mlBfgsInEq <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> print( mlBfgsInEq )
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8197 1.68 
> summary( mlBfgsInEq )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.00145 
--------------------------------------------
> activePar( mlBfgsInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBfgsInEq )
[1] 413.1
> coef( mlBfgsInEq )
    mu  sigma 
0.8197 1.6803 
> condiNumber( mlBfgsInEq )
mu 	 1 
sigma 	 3.611 
> hessian( mlBfgsInEq )
          mu  sigma
mu    -35.44 -15.23
sigma -15.23 -93.71
> logLik( mlBfgsInEq )
[1] -204.5
> maximType( mlBfgsInEq )
[1] "BFGS maximisation"
> nIter( mlBfgsInEq )
function 
     130 
> nParam( mlBfgsInEq )
[1] 2
> returnCode( mlBfgsInEq )
[1] 0
> returnMessage( mlBfgsInEq )
[1] "successful convergence "
> vcov( mlBfgsInEq )
             mu     sigma
mu     0.030335 -0.004932
sigma -0.004932  0.011473
> logLik( summary( mlBfgsInEq ) )
[1] -204.5
> mlBfgsInEqInd <- maxLik( llfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> summary( mlBfgsInEqInd )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 130 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.00145 
--------------------------------------------
> all.equal( mlBfgsInEq[ ], mlBfgsInEqInd[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlBfgsInEqInd[ 12 ]
$gradientObs
              mu    sigma
  [1,] -0.333180 -0.40862
  [2,] -0.099200 -0.57861
  [3,]  1.168027  1.69723
  [4,]  0.113802 -0.57338
  [5,]  0.155441 -0.55454
  [6,]  1.278788  2.15260
  [7,]  0.390363 -0.33910
  [8,] -0.832301  0.56882
  [9,] -0.422704 -0.29491
 [10,] -0.251847 -0.48857
 [11,]  0.930981  0.86119
 [12,]  0.318743 -0.42443
 [13,]  0.347757 -0.39194
 [14,]  0.142261 -0.56114
 [15,] -0.329897 -0.41228
 [16,]  1.329685  2.37568
 [17,]  0.416527 -0.30362
 [18,] -1.329276  2.37385
 [19,]  0.560688 -0.06691
 [20,] -0.271066 -0.47168
 [21,] -0.692580  0.21083
 [22,] -0.090556 -0.58136
 [23,] -0.662956  0.14335
 [24,] -0.452484 -0.25112
 [25,] -0.378916 -0.35389
 [26,] -1.130981  1.55412
 [27,]  0.657334  0.13088
 [28,]  0.172503 -0.54514
 [29,] -0.742389  0.33092
 [30,]  0.952044  0.92783
 [31,]  0.365957 -0.37011
 [32,] -0.145171 -0.55973
 [33,]  0.697952  0.22338
 [34,]  0.685915  0.19539
 [35,]  0.645854  0.10574
 [36,]  0.551680 -0.08375
 [37,]  0.456244 -0.24538
 [38,]  0.019997 -0.59447
 [39,] -0.152886 -0.55587
 [40,] -0.205667 -0.52407
 [41,] -0.428268 -0.28696
 [42,] -0.083432 -0.58345
 [43,] -0.832538  0.56949
 [44,]  1.600320  3.70807
 [45,]  0.919562  0.82568
 [46,] -0.731743  0.30455
 [47,] -0.221545 -0.51267
 [48,] -0.266719 -0.47561
 [49,]  0.616374  0.04322
 [50,]  0.004797 -0.59510
 [51,]  0.243303 -0.49568
 [52,]  0.043633 -0.59194
 [53,]  0.033486 -0.59326
 [54,]  1.033358  1.19910
 [55,] -0.096079 -0.57963
 [56,]  1.138106  1.58129
 [57,] -1.033265  1.19878
 [58,]  0.477989 -0.21125
 [59,]  0.151592 -0.55653
 [60,]  0.216825 -0.51615
 [61,]  0.332787 -0.40906
 [62,] -0.291986 -0.45189
 [63,] -0.172186 -0.54533
 [64,] -0.657693  0.13168
 [65,] -0.695391  0.21738
 [66,]  0.278871 -0.46447
 [67,]  0.381362 -0.35077
 [68,]  0.101402 -0.57787
 [69,]  0.717179  0.26910
 [70,]  1.516113  3.26712
 [71,] -0.283986 -0.45963
 [72,] -1.571936  3.55677
 [73,]  0.776309  0.41748
 [74,] -0.438535 -0.27200
 [75,] -0.423523 -0.29375
 [76,]  0.790359  0.45447
 [77,] -0.137875 -0.56320
 [78,] -0.800889  0.48262
 [79,]  0.192288 -0.53301
 [80,] -0.034534 -0.59314
 [81,]  0.067938 -0.58739
 [82,]  0.336783 -0.40456
 [83,] -0.198717 -0.52879
 [84,]  0.520324 -0.14023
 [85,] -0.092336 -0.58082
 [86,]  0.298886 -0.44504
 [87,]  0.840844  0.59284
 [88,]  0.372133 -0.36245
 [89,] -0.167032 -0.54826
 [90,]  0.877658  0.69914
 [91,]  0.767642  0.39500
 [92,]  0.452333 -0.25135
 [93,]  0.232970 -0.50395
 [94,] -0.380947 -0.35130
 [95,]  1.027726  1.17959
 [96,] -0.361363 -0.37573
 [97,]  1.613338  3.77836
 [98,]  1.149540  1.62524
 [99,] -0.103113 -0.57728
[100,] -0.663251  0.14401

> nObs( mlBfgsInEqInd )
[1] 100
> 
> # with analytical gradients
> mlgBfgsInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlBfgsInEq, mlgBfgsInEq, tolerance = 1e-3 )
[1] TRUE
> mlgBfgsInEqInd <- maxLik( llfInd, gfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEqInd[ -12 ], mlgBfgsInEq[ ], tolerance = 1e-3 )
[1] TRUE
> mlgBfgsInEqInd[ 12 ]
$gradientObs
              mu    sigma
  [1,] -0.333180 -0.40862
  [2,] -0.099200 -0.57861
  [3,]  1.168027  1.69723
  [4,]  0.113802 -0.57338
  [5,]  0.155441 -0.55454
  [6,]  1.278789  2.15260
  [7,]  0.390363 -0.33910
  [8,] -0.832301  0.56882
  [9,] -0.422704 -0.29491
 [10,] -0.251847 -0.48857
 [11,]  0.930981  0.86119
 [12,]  0.318743 -0.42443
 [13,]  0.347757 -0.39194
 [14,]  0.142261 -0.56114
 [15,] -0.329897 -0.41228
 [16,]  1.329685  2.37568
 [17,]  0.416527 -0.30362
 [18,] -1.329276  2.37385
 [19,]  0.560688 -0.06691
 [20,] -0.271066 -0.47168
 [21,] -0.692580  0.21083
 [22,] -0.090556 -0.58136
 [23,] -0.662956  0.14335
 [24,] -0.452484 -0.25112
 [25,] -0.378916 -0.35389
 [26,] -1.130981  1.55412
 [27,]  0.657334  0.13088
 [28,]  0.172503 -0.54514
 [29,] -0.742389  0.33092
 [30,]  0.952044  0.92783
 [31,]  0.365957 -0.37011
 [32,] -0.145171 -0.55973
 [33,]  0.697952  0.22338
 [34,]  0.685915  0.19539
 [35,]  0.645854  0.10574
 [36,]  0.551680 -0.08375
 [37,]  0.456244 -0.24538
 [38,]  0.019997 -0.59447
 [39,] -0.152886 -0.55587
 [40,] -0.205667 -0.52407
 [41,] -0.428268 -0.28696
 [42,] -0.083432 -0.58345
 [43,] -0.832538  0.56949
 [44,]  1.600320  3.70807
 [45,]  0.919562  0.82568
 [46,] -0.731743  0.30456
 [47,] -0.221545 -0.51267
 [48,] -0.266719 -0.47561
 [49,]  0.616374  0.04322
 [50,]  0.004797 -0.59510
 [51,]  0.243303 -0.49568
 [52,]  0.043633 -0.59194
 [53,]  0.033486 -0.59326
 [54,]  1.033358  1.19910
 [55,] -0.096079 -0.57963
 [56,]  1.138106  1.58129
 [57,] -1.033265  1.19878
 [58,]  0.477989 -0.21125
 [59,]  0.151592 -0.55653
 [60,]  0.216825 -0.51615
 [61,]  0.332787 -0.40906
 [62,] -0.291986 -0.45189
 [63,] -0.172186 -0.54533
 [64,] -0.657693  0.13168
 [65,] -0.695391  0.21738
 [66,]  0.278871 -0.46447
 [67,]  0.381362 -0.35077
 [68,]  0.101402 -0.57787
 [69,]  0.717179  0.26910
 [70,]  1.516113  3.26712
 [71,] -0.283986 -0.45963
 [72,] -1.571936  3.55677
 [73,]  0.776309  0.41748
 [74,] -0.438535 -0.27200
 [75,] -0.423523 -0.29375
 [76,]  0.790359  0.45447
 [77,] -0.137875 -0.56320
 [78,] -0.800889  0.48262
 [79,]  0.192288 -0.53301
 [80,] -0.034534 -0.59314
 [81,]  0.067938 -0.58739
 [82,]  0.336783 -0.40456
 [83,] -0.198717 -0.52879
 [84,]  0.520324 -0.14023
 [85,] -0.092336 -0.58082
 [86,]  0.298886 -0.44504
 [87,]  0.840844  0.59284
 [88,]  0.372133 -0.36245
 [89,] -0.167032 -0.54826
 [90,]  0.877658  0.69914
 [91,]  0.767642  0.39500
 [92,]  0.452333 -0.25135
 [93,]  0.232970 -0.50395
 [94,] -0.380947 -0.35130
 [95,]  1.027726  1.17959
 [96,] -0.361363 -0.37573
 [97,]  1.613338  3.77836
 [98,]  1.149540  1.62524
 [99,] -0.103113 -0.57728
[100,] -0.663251  0.14401

> mlgBfgsInEqInd2 <- maxLik( llf, gfInd, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEqInd, mlgBfgsInEqInd2, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused Hessian
> mlghBfgsInEq <- maxLik( llf, gf, hf, start = startVal, constraints = inEq,
+    method = "BFGS" )
> all.equal( mlgBfgsInEq, mlghBfgsInEq, tolerance = 1e-3 )
[1] TRUE
> 
> ## NM method with inequality constraints
> mlNmInEq <- maxLik( llf, start = startVal, constraints = inEq, method = "NM" )
> print( mlNmInEq )
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8197 1.68 
> summary( mlNmInEq )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.001468 
--------------------------------------------
> activePar( mlNmInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNmInEq )
[1] 413.1
> coef( mlNmInEq )
    mu  sigma 
0.8197 1.6803 
> condiNumber( mlNmInEq )
mu 	 1 
sigma 	 3.61 
> hessian( mlNmInEq )
          mu  sigma
mu    -35.44 -15.23
sigma -15.23 -93.68
> logLik( mlNmInEq )
[1] -204.5
> maximType( mlNmInEq )
[1] "Nelder-Mead maximisation"
> nIter( mlNmInEq )
function 
     103 
> nParam( mlNmInEq )
[1] 2
> returnCode( mlNmInEq )
[1] 0
> returnMessage( mlNmInEq )
[1] "successful convergence "
> vcov( mlNmInEq )
             mu     sigma
mu     0.030336 -0.004933
sigma -0.004933  0.011477
> logLik( summary( mlNmInEq ) )
[1] -204.5
> all.equal( mlBfgsInEq, mlNmInEq, tolerance = 1e-3 )
[1] "Component 9: Mean relative difference: 0.2077"               
[2] "Component 10: 1 string mismatch"                             
[3] "Component 11: Component 2: Mean relative difference: 0.01189"
> mlNmInEqInd <- maxLik( llfInd, start = startVal, constraints = inEq,
+    method = "NM" )
> summary( mlNmInEqInd )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 103 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.001468 
--------------------------------------------
> all.equal( mlNmInEq[ ], mlNmInEqInd[ -12 ], tolerance = 1e-3 )
[1] TRUE
> mlNmInEqInd[ 12 ]
$gradientObs
              mu    sigma
  [1,] -0.333175 -0.40862
  [2,] -0.099198 -0.57861
  [3,]  1.168019  1.69721
  [4,]  0.113803 -0.57338
  [5,]  0.155442 -0.55454
  [6,]  1.278780  2.15258
  [7,]  0.390362 -0.33910
  [8,] -0.832292  0.56880
  [9,] -0.422699 -0.29492
 [10,] -0.251843 -0.48857
 [11,]  0.930975  0.86118
 [12,]  0.318742 -0.42443
 [13,]  0.347756 -0.39194
 [14,]  0.142262 -0.56113
 [15,] -0.329892 -0.41228
 [16,]  1.329676  2.37565
 [17,]  0.416525 -0.30362
 [18,] -1.329262  2.37381
 [19,]  0.560685 -0.06692
 [20,] -0.271061 -0.47168
 [21,] -0.692572  0.21081
 [22,] -0.090553 -0.58136
 [23,] -0.662948  0.14334
 [24,] -0.452478 -0.25113
 [25,] -0.378911 -0.35390
 [26,] -1.130969  1.55409
 [27,]  0.657331  0.13088
 [28,]  0.172503 -0.54514
 [29,] -0.742381  0.33091
 [30,]  0.952038  0.92782
 [31,]  0.365956 -0.37011
 [32,] -0.145167 -0.55973
 [33,]  0.697948  0.22338
 [34,]  0.685911  0.19539
 [35,]  0.645851  0.10574
 [36,]  0.551678 -0.08375
 [37,]  0.456242 -0.24538
 [38,]  0.019999 -0.59447
 [39,] -0.152882 -0.55587
 [40,] -0.205663 -0.52407
 [41,] -0.428262 -0.28696
 [42,] -0.083429 -0.58344
 [43,] -0.832529  0.56947
 [44,]  1.600308  3.70803
 [45,]  0.919556  0.82568
 [46,] -0.731735  0.30454
 [47,] -0.221540 -0.51267
 [48,] -0.266714 -0.47561
 [49,]  0.616371  0.04322
 [50,]  0.004799 -0.59510
 [51,]  0.243303 -0.49567
 [52,]  0.043634 -0.59194
 [53,]  0.033488 -0.59326
 [54,]  1.033351  1.19908
 [55,] -0.096076 -0.57963
 [56,]  1.138099  1.58127
 [57,] -1.033254  1.19875
 [58,]  0.477987 -0.21124
 [59,]  0.151593 -0.55653
 [60,]  0.216826 -0.51614
 [61,]  0.332787 -0.40905
 [62,] -0.291981 -0.45189
 [63,] -0.172182 -0.54533
 [64,] -0.657685  0.13166
 [65,] -0.695383  0.21737
 [66,]  0.278871 -0.46447
 [67,]  0.381361 -0.35077
 [68,]  0.101404 -0.57786
 [69,]  0.717175  0.26909
 [70,]  1.516102  3.26709
 [71,] -0.283982 -0.45963
 [72,] -1.571920  3.55671
 [73,]  0.776305  0.41748
 [74,] -0.438530 -0.27201
 [75,] -0.423517 -0.29375
 [76,]  0.790354  0.45446
 [77,] -0.137872 -0.56320
 [78,] -0.800880  0.48260
 [79,]  0.192289 -0.53301
 [80,] -0.034532 -0.59314
 [81,]  0.067940 -0.58738
 [82,]  0.336783 -0.40456
 [83,] -0.198713 -0.52879
 [84,]  0.520322 -0.14023
 [85,] -0.092333 -0.58082
 [86,]  0.298885 -0.44504
 [87,]  0.840839  0.59283
 [88,]  0.372132 -0.36245
 [89,] -0.167028 -0.54826
 [90,]  0.877652  0.69913
 [91,]  0.767638  0.39499
 [92,]  0.452332 -0.25135
 [93,]  0.232970 -0.50394
 [94,] -0.380942 -0.35130
 [95,]  1.027720  1.17958
 [96,] -0.361357 -0.37573
 [97,]  1.613326  3.77832
 [98,]  1.149532  1.62522
 [99,] -0.103110 -0.57728
[100,] -0.663243  0.14400

> nObs( mlNmInEqInd )
[1] 100
> 
> # with unused analytical gradients
> mlgNmInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "NM" )
> all.equal( mlNmInEq, mlgNmInEq, tolerance = 1e-3 )
[1] TRUE
> 
> # with unused analytical gradients and Hessians
> mlghNmInEq <- maxLik( llf, gf, hf, start = startVal, constraints = inEq,
+    method = "NM" )
> all.equal( mlgNmInEq, mlghNmInEq, tolerance = 1e-3 )
[1] TRUE
> 
> ## SANN method with inequality constraints
> mlSannInEq <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "SANN" )
> print( mlSannInEq )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8297 1.67 
> summary( mlSannInEq )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.830      0.173     4.8 1.6e-06 ***
sigma    1.670      0.106    15.8 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.001043 
--------------------------------------------
> activePar( mlSannInEq )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSannInEq )
[1] 413.1
> coef( mlSannInEq )
    mu  sigma 
0.8297 1.6702 
> condiNumber( mlSannInEq )
mu 	 1 
sigma 	 3.601 
> hessian( mlSannInEq )
          mu  sigma
mu    -35.84 -15.06
sigma -15.06 -96.12
> logLik( mlSannInEq )
[1] -204.5
> maximType( mlSannInEq )
[1] "SANN maximisation"
> nIter( mlSannInEq )
function 
   10000 
> nParam( mlSannInEq )
[1] 2
> returnCode( mlSannInEq )
[1] 0
> returnMessage( mlSannInEq )
[1] "successful convergence "
> vcov( mlSannInEq )
             mu     sigma
mu     0.029869 -0.004681
sigma -0.004681  0.011137
> logLik( summary( mlSannInEq ) )
[1] -204.5
> all.equal( mlBfgsInEq, mlSannInEq, tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.008016"           
[2] "Component 3: Mean relative difference: 0.03946"            
[3] "Component 4: Mean relative difference: 0.01976"            
[4] "Component 9: Mean relative difference: 75.92"              
[5] "Component 10: 1 string mismatch"                           
[6] "Component 11: Component 2: Mean relative difference: 0.281"
> 
> # with unused analytical gradients
> mlgSannInEq <- maxLik( llf, gf, start = startVal, constraints = inEq,
+    method = "SANN" )
> all.equal( mlSannInEq, mlgSannInEq, tolerance = 1e-3 )
[1] TRUE
> 
> # with a user-specified function to generate a new candidate point
> mlSannInEqCand <- maxLik( llf, start = startVal, constraints = inEq,
+    method = "SANN", cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
> summary( mlSannInEqCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.812      0.175    4.65 3.4e-06 ***
sigma    1.682      0.108   15.65 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on constrOptim 
1  outer iterations, barrier value -0.0005163 
--------------------------------------------
> all.equal( mlSannInEqCand, mlSannInEq, tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.01216"
[2] "Component 3: Mean relative difference: 0.05196"
[3] "Component 4: Mean relative difference: 0.02616"
> 
> ############### equality constraints ###############
> eqCon <- list( eqA = A, eqB = 2.5 )
> 
> ## NR method with equality constraints
> mlCon <- maxLik( llf, start = startVal, constraints = eqCon )
> print( mlCon )
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8198 1.68 
> summary( mlCon )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> activePar( mlCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlCon )
[1] 413.1
> coef( mlCon )
    mu  sigma 
0.8198 1.6803 
> condiNumber( mlCon )
mu 	 1 
sigma 	 3.614 
> hessian( mlCon )
          mu  sigma
mu    -35.44 -15.26
sigma -15.26 -93.71
> logLik( mlCon )
[1] -204.5
> maximType( mlCon )
[1] "Newton-Raphson maximisation"
> nIter( mlCon )
[1] 2
> nParam( mlCon )
[1] 2
> returnCode( mlCon )
[1] 1
> returnMessage( mlCon )
[1] "gradient close to zero"
> vcov( mlCon )
             mu     sigma
mu     0.030343 -0.004942
sigma -0.004942  0.011477
> logLik( summary( mlCon ) )
[1] -204.5
> mlConInd <- maxLik( llfInd, start = startVal, constraints = eqCon )
> summary( mlConInd )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 2 iterations
Return code 1: gradient close to zero
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> all.equal( mlCon[], mlConInd[-11], tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001862"
> mlConInd[11]
$gradientObs
              mu    sigma
  [1,] -0.333193 -0.40861
  [2,] -0.099212 -0.57861
  [3,]  1.168023  1.69720
  [4,]  0.113792 -0.57339
  [5,]  0.155431 -0.55455
  [6,]  1.278785  2.15258
  [7,]  0.390354 -0.33911
  [8,] -0.832318  0.56886
  [9,] -0.422718 -0.29490
 [10,] -0.251860 -0.48856
 [11,]  0.930976  0.86117
 [12,]  0.318734 -0.42444
 [13,]  0.347748 -0.39195
 [14,]  0.142251 -0.56114
 [15,] -0.329910 -0.41226
 [16,]  1.329682  2.37565
 [17,]  0.416518 -0.30364
 [18,] -1.329295  2.37393
 [19,]  0.560680 -0.06693
 [20,] -0.271079 -0.47167
 [21,] -0.692596  0.21086
 [22,] -0.090568 -0.58136
 [23,] -0.662971  0.14338
 [24,] -0.452498 -0.25110
 [25,] -0.378930 -0.35388
 [26,] -1.130999  1.55418
 [27,]  0.657327  0.13086
 [28,]  0.172493 -0.54515
 [29,] -0.742405  0.33096
 [30,]  0.952039  0.92781
 [31,]  0.365949 -0.37013
 [32,] -0.145183 -0.55973
 [33,]  0.697945  0.22336
 [34,]  0.685908  0.19537
 [35,]  0.645847  0.10572
 [36,]  0.551672 -0.08377
 [37,]  0.456236 -0.24540
 [38,]  0.019986 -0.59447
 [39,] -0.152898 -0.55586
 [40,] -0.205679 -0.52406
 [41,] -0.428282 -0.28694
 [42,] -0.083443 -0.58345
 [43,] -0.832555  0.56953
 [44,]  1.600319  3.70805
 [45,]  0.919557  0.82566
 [46,] -0.731759  0.30459
 [47,] -0.221557 -0.51266
 [48,] -0.266732 -0.47560
 [49,]  0.616366  0.04320
 [50,]  0.004786 -0.59511
 [51,]  0.243293 -0.49569
 [52,]  0.043622 -0.59195
 [53,]  0.033475 -0.59326
 [54,]  1.033353  1.19907
 [55,] -0.096091 -0.57963
 [56,]  1.138102  1.58126
 [57,] -1.033283  1.19883
 [58,]  0.477981 -0.21126
 [59,]  0.151582 -0.55654
 [60,]  0.216816 -0.51616
 [61,]  0.332778 -0.40907
 [62,] -0.291999 -0.45188
 [63,] -0.172198 -0.54532
 [64,] -0.657709  0.13171
 [65,] -0.695406  0.21741
 [66,]  0.278862 -0.46448
 [67,]  0.381353 -0.35078
 [68,]  0.101392 -0.57787
 [69,]  0.717173  0.26908
 [70,]  1.516111  3.26710
 [71,] -0.283999 -0.45962
 [72,] -1.571957  3.55687
 [73,]  0.776303  0.41746
 [74,] -0.438549 -0.27199
 [75,] -0.423537 -0.29373
 [76,]  0.790352  0.45444
 [77,] -0.137887 -0.56320
 [78,] -0.800905  0.48266
 [79,]  0.192278 -0.53302
 [80,] -0.034546 -0.59314
 [81,]  0.067927 -0.58739
 [82,]  0.336774 -0.40457
 [83,] -0.198729 -0.52879
 [84,]  0.520316 -0.14025
 [85,] -0.092347 -0.58082
 [86,]  0.298876 -0.44505
 [87,]  0.840838  0.59282
 [88,]  0.372124 -0.36247
 [89,] -0.167044 -0.54826
 [90,]  0.877652  0.69912
 [91,]  0.767636  0.39498
 [92,]  0.452325 -0.25137
 [93,]  0.232960 -0.50396
 [94,] -0.380961 -0.35129
 [95,]  1.027722  1.17957
 [96,] -0.361376 -0.37571
 [97,]  1.613337  3.77834
 [98,]  1.149536  1.62521
 [99,] -0.103125 -0.57728
[100,] -0.663266  0.14404

> nObs( mlConInd )
[1] 100
> 
> # with analytical gradients
> mlgCon <- maxLik( llf, gf, start = startVal, constraints = eqCon )
> summary( mlgCon )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 1 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.842      0.172    4.88   1e-06 ***
sigma    1.670      0.105   15.84  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
7  outer iterations, barrier value 0.0001299 
--------------------------------------------
> all.equal( mlCon[ -c( 5, 6, 7, 9 ) ], mlgCon[ -c( 5, 6, 7, 9 ) ], 
+    tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.01296"         
[2] "Component 3: Mean relative difference: 0.05056"         
[3] "Component 4: Mean relative difference: 0.02514"         
[4] "Component 7: Component 3: Mean relative difference: 1"  
[5] "Component 7: Component 4: 1 string mismatch"            
[6] "Component 7: Component 5: Mean relative difference: 0.3"
> mlgConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon )
> all.equal( mlConInd, mlgConInd, tolerance = 1e-3 )
 [1] "Component 2: Mean relative difference: 0.01296"          
 [2] "Component 3: Mean relative difference: 0.05056"          
 [3] "Component 4: Mean relative difference: 0.0248"           
 [4] "Component 5: Mean relative difference: 2"                
 [5] "Component 6: 1 string mismatch"                          
 [6] "Component 7: target is NULL, current is list"            
 [7] "Component 9: Mean relative difference: 0.5"              
 [8] "Component 11: Mean relative difference: 0.01789"         
 [9] "Component 12: Component 3: Mean relative difference: 1"  
[10] "Component 12: Component 4: 1 string mismatch"            
[11] "Component 12: Component 5: Mean relative difference: 0.3"
> all.equal( mlgCon[], mlgConInd[-11], tolerance = 1e-3 )
[1] TRUE
> mlgConInd[11]
$gradientObs
              mu    sigma
  [1,] -0.345249 -0.39986
  [2,] -0.108315 -0.57930
  [3,]  1.174915  1.70609
  [4,]  0.107378 -0.57964
  [5,]  0.149542 -0.56155
  [6,]  1.287075  2.16717
  [7,]  0.387431 -0.34825
  [8,] -0.850673  0.60942
  [9,] -0.435904 -0.28161
 [10,] -0.262889 -0.48349
 [11,]  0.934876  0.86047
 [12,]  0.314907 -0.43330
 [13,]  0.344287 -0.40097
 [14,]  0.136196 -0.56792
 [15,] -0.341925 -0.40367
 [16,]  1.338615  2.39314
 [17,]  0.413925 -0.31280
 [18,] -1.353923  2.46196
 [19,]  0.559907 -0.07543
 [20,] -0.282350 -0.46577
 [21,] -0.709187  0.24091
 [22,] -0.099561 -0.58234
 [23,] -0.679189  0.17137
 [24,] -0.466059 -0.23620
 [25,] -0.391563 -0.34288
 [26,] -1.153124  1.62138
 [27,]  0.657773  0.12356
 [28,]  0.166819 -0.55242
 [29,] -0.759626  0.36461
 [30,]  0.956205  0.92782
 [31,]  0.362717 -0.37921
 [32,] -0.154865 -0.55884
 [33,]  0.698904  0.21673
 [34,]  0.686715  0.18853
 [35,]  0.646148  0.09825
 [36,]  0.550785 -0.09234
 [37,]  0.454144 -0.25451
 [38,]  0.012388 -0.59863
 [39,] -0.162678 -0.55470
 [40,] -0.216125 -0.52089
 [41,] -0.441538 -0.27336
 [42,] -0.092347 -0.58465
 [43,] -0.850913  0.61011
 [44,]  1.612667  3.74365
 [45,]  0.923313  0.82459
 [46,] -0.748845  0.33746
 [47,] -0.232204 -0.50886
 [48,] -0.277948 -0.46989
 [49,]  0.616296  0.03532
 [50,] -0.003004 -0.59887
 [51,]  0.238514 -0.50390
 [52,]  0.036322 -0.59669
 [53,]  0.026047 -0.59776
 [54,]  1.038546  1.20208
 [55,] -0.105154 -0.58043
 [56,]  1.144617  1.58874
 [57,] -1.054175  1.25669
 [58,]  0.476163 -0.22030
 [59,]  0.145645 -0.56347
 [60,]  0.211702 -0.52405
 [61,]  0.329128 -0.41801
 [62,] -0.303534 -0.44505
 [63,] -0.182222 -0.54344
 [64,] -0.673860  0.15933
 [65,] -0.712033  0.24767
 [66,]  0.274531 -0.47304
 [67,]  0.378316 -0.35991
 [68,]  0.094821 -0.58388
 [69,]  0.718374  0.26281
 [70,]  1.527397  3.29656
 [71,] -0.295434 -0.45315
 [72,] -1.599648  3.67381
 [73,]  0.778251  0.41244
 [74,] -0.451935 -0.25785
 [75,] -0.436733 -0.28041
 [76,]  0.792478  0.44976
 [77,] -0.147478 -0.56257
 [78,] -0.818864  0.52075
 [79,]  0.186855 -0.54059
 [80,] -0.042832 -0.59583
 [81,]  0.060934 -0.59269
 [82,]  0.333175 -0.41354
 [83,] -0.209088 -0.52589
 [84,]  0.519033 -0.14906
 [85,] -0.101363 -0.58173
 [86,]  0.294798 -0.45378
 [87,]  0.843600  0.58942
 [88,]  0.368970 -0.37157
 [89,] -0.177002 -0.54658
 [90,]  0.880879  0.69676
 [91,]  0.769474  0.38976
 [92,]  0.450184 -0.26049
 [93,]  0.228050 -0.51205
 [94,] -0.393619 -0.34018
 [95,]  1.032843  1.18235
 [96,] -0.373787 -0.36559
 [97,]  1.625850  3.81493
 [98,]  1.156195  1.63322
 [99,] -0.112276 -0.57784
[100,] -0.679488  0.17205

> 
> # with analytical gradients as attribute
> mlGCon <- maxLik( llfGrad, start = startVal, constraints = eqCon )
> all.equal( mlGCon, mlgCon, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGCon, mlCon, tolerance = 1e-3 )
 [1] "Component 2: Mean relative difference: 0.0129"                 
 [2] "Component 3: Mean relative difference: 0.05047"                
 [3] "Component 4: Mean relative difference: 0.02495"                
 [4] "Component 5: Mean relative difference: 0.6667"                 
 [5] "Component 6: 1 string mismatch"                                
 [6] "Component 7: Modes: list, NULL"                                
 [7] "Component 7: names for target but not for current"             
 [8] "Component 7: Length mismatch: comparison on first 0 components"
 [9] "Component 9: Mean relative difference: 1"                      
[10] "Component 11: Component 3: Mean relative difference: 0.5"      
[11] "Component 11: Component 4: 1 string mismatch"                  
[12] "Component 11: Component 5: Mean relative difference: 0.4286"   
> 
> # with analytical gradients and Hessians
> mlghCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon )
> all.equal( mlgCon, mlghCon, tolerance = 1e-3 )
[1] "Component 7: Component 2: Attributes: < Component 2: Attributes: < Length mismatch: comparison on first 1 components > >"
> 
> # with analytical gradients and Hessians as attributes
> mlGHCon <- maxLik( llfGradHess, start = startVal, constraints = eqCon )
> all.equal( mlGHCon, mlghCon, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGHCon, mlCon, tolerance = 1e-3 )
 [1] "Component 2: Mean relative difference: 0.0129"                 
 [2] "Component 3: Mean relative difference: 0.05047"                
 [3] "Component 4: Mean relative difference: 0.02495"                
 [4] "Component 5: Mean relative difference: 0.6667"                 
 [5] "Component 6: 1 string mismatch"                                
 [6] "Component 7: Modes: list, NULL"                                
 [7] "Component 7: names for target but not for current"             
 [8] "Component 7: Length mismatch: comparison on first 0 components"
 [9] "Component 9: Mean relative difference: 1"                      
[10] "Component 11: Component 3: Mean relative difference: 0.5"      
[11] "Component 11: Component 4: 1 string mismatch"                  
[12] "Component 11: Component 5: Mean relative difference: 0.4286"   
> 
> 
> ## BHHH method with equality constraints
> mlBhhhCon <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> print( mlBhhhCon )
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8199 1.68 
> summary( mlBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.69 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.085e-10 
--------------------------------------------
> activePar( mlBhhhCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBhhhCon )
[1] 413.1
> coef( mlBhhhCon )
    mu  sigma 
0.8199 1.6801 
> condiNumber( mlBhhhCon )
mu 	 1 
sigma 	 3.615 
> hessian( mlBhhhCon )
          mu  sigma
mu    -35.41 -15.23
sigma -15.23 -93.76
> logLik( mlBhhhCon )
[1] -204.5
> maximType( mlBhhhCon )
[1] "BHHH maximisation"
> nIter( mlBhhhCon )
[1] 8
> nParam( mlBhhhCon )
[1] 2
> returnCode( mlBhhhCon )
[1] 2
> returnMessage( mlBhhhCon )
[1] "successive function values within tolerance limit"
> vcov( mlBhhhCon )
             mu     sigma
mu     0.030360 -0.004933
sigma -0.004933  0.011467
> logLik( summary( mlBhhhCon ) )
[1] -204.5
> all.equal( mlCon[ -c( 5, 6, 7, 9, 10 ) ], mlBhhhCon[ -c( 5, 6, 7, 9, 10, 11 ) ],
+    tolerance = 1e-3 )
[1] TRUE
> mlBhhhCon[11]
$gradientObs
              mu    sigma
  [1,] -0.333308 -0.40855
  [2,] -0.099285 -0.57864
  [3,]  1.168182  1.69756
  [4,]  0.113758 -0.57346
  [5,]  0.155405 -0.55462
  [6,]  1.278964  2.15304
  [7,]  0.390371 -0.33917
  [8,] -0.832523  0.56928
  [9,] -0.422849 -0.29479
 [10,] -0.251960 -0.48854
 [11,]  0.931091  0.86134
 [12,]  0.318738 -0.42451
 [13,]  0.347757 -0.39201
 [14,]  0.142223 -0.56121
 [15,] -0.330025 -0.41221
 [16,]  1.329870  2.37617
 [17,]  0.416540 -0.30369
 [18,] -1.329591  2.37493
 [19,]  0.560728 -0.06694
 [20,] -0.271182 -0.47164
 [21,] -0.692776  0.21115
 [22,] -0.090639 -0.58140
 [23,] -0.663146  0.14365
 [24,] -0.452635 -0.25098
 [25,] -0.379053 -0.35380
 [26,] -1.131259  1.55492
 [27,]  0.657393  0.13089
 [28,]  0.172470 -0.54522
 [29,] -0.742594  0.33129
 [30,]  0.952158  0.92800
 [31,]  0.365961 -0.37019
 [32,] -0.145263 -0.55975
 [33,]  0.698018  0.22340
 [34,]  0.685979  0.19541
 [35,]  0.645910  0.10574
 [36,]  0.551719 -0.08378
 [37,]  0.456265 -0.24544
 [38,]  0.019936 -0.59453
 [39,] -0.152980 -0.55588
 [40,] -0.205771 -0.52406
 [41,] -0.428414 -0.28683
 [42,] -0.083513 -0.58348
 [43,] -0.832761  0.56994
 [44,]  1.600556  3.70888
 [45,]  0.919670  0.82583
 [46,] -0.731946  0.30491
 [47,] -0.221652 -0.51266
 [48,] -0.266834 -0.47557
 [49,]  0.616424  0.04321
 [50,]  0.004733 -0.59516
 [51,]  0.243283 -0.49576
 [52,]  0.043575 -0.59201
 [53,]  0.033427 -0.59332
 [54,]  1.033487  1.19932
 [55,] -0.096162 -0.57966
 [56,]  1.138255  1.58160
 [57,] -1.033525  1.19945
 [58,]  0.478014 -0.21130
 [59,]  0.151555 -0.55661
 [60,]  0.216801 -0.51623
 [61,]  0.332785 -0.40913
 [62,] -0.292106 -0.45184
 [63,] -0.172284 -0.54533
 [64,] -0.657882  0.13197
 [65,] -0.695587  0.21771
 [66,]  0.278858 -0.46455
 [67,]  0.381368 -0.35084
 [68,]  0.101356 -0.57794
 [69,]  0.717249  0.26913
 [70,]  1.516333  3.26782
 [71,] -0.284105 -0.45959
 [72,] -1.572297  3.55824
 [73,]  0.776390  0.41754
 [74,] -0.438683 -0.27187
 [75,] -0.423668 -0.29363
 [76,]  0.790442  0.45453
 [77,] -0.137967 -0.56322
 [78,] -0.801105  0.48304
 [79,]  0.192259 -0.53310
 [80,] -0.034606 -0.59319
 [81,]  0.067885 -0.58746
 [82,]  0.336781 -0.40464
 [83,] -0.198820 -0.52879
 [84,]  0.520357 -0.14027
 [85,] -0.092418 -0.58085
 [86,]  0.298876 -0.44512
 [87,]  0.840937  0.59293
 [88,]  0.372137 -0.36253
 [89,] -0.167128 -0.54827
 [90,]  0.877758  0.69926
 [91,]  0.767721  0.39505
 [92,]  0.452353 -0.25141
 [93,]  0.232948 -0.50403
 [94,] -0.381084 -0.35120
 [95,]  1.027855  1.17981
 [96,] -0.361496 -0.37564
 [97,]  1.613577  3.77919
 [98,]  1.149691  1.62555
 [99,] -0.103198 -0.57731
[100,] -0.663441  0.14431

> nObs( mlBhhhCon )
[1] 100
> 
> # with analytical gradients
> mlgBhhhCon <- maxLik( llf, gfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> summary( mlgBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 7 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.834      0.172    4.84 1.3e-06 ***
sigma    1.666      0.105   15.88 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.178e-08 
--------------------------------------------
> all.equal( mlBhhhCon, mlgBhhhCon, tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.01121"          
[2] "Component 3: Mean relative difference: 0.05516"          
[3] "Component 4: Mean relative difference: 0.02774"          
[4] "Component 5: Mean relative difference: 0.5"              
[5] "Component 6: 1 string mismatch"                          
[6] "Component 7: target is NULL, current is list"            
[7] "Component 9: Mean relative difference: 0.125"            
[8] "Component 11: Mean relative difference: 0.02016"         
[9] "Component 12: Component 5: Mean relative difference: 0.1"
> mlgBhhhConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlgBhhhCon, mlgBhhhConInd, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients as attribute
> mlGBhhhCon <- maxLik( llfGradInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> summary( mlGBhhhCon )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 7 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.834      0.172    4.84 1.3e-06 ***
sigma    1.666      0.105   15.88 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.178e-08 
--------------------------------------------
> all.equal( mlGBhhhCon, mlgBhhhCon, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGBhhhCon, mlBhhhCon, tolerance = 1e-3 )
 [1] "Component 2: Mean relative difference: 0.01121"                
 [2] "Component 3: Mean relative difference: 0.05343"                
 [3] "Component 4: Mean relative difference: 0.02715"                
 [4] "Component 5: Mean relative difference: 0.3333"                 
 [5] "Component 6: 1 string mismatch"                                
 [6] "Component 7: Modes: list, NULL"                                
 [7] "Component 7: names for target but not for current"             
 [8] "Component 7: Length mismatch: comparison on first 0 components"
 [9] "Component 9: Mean relative difference: 0.1429"                 
[10] "Component 11: Mean relative difference: 0.01981"               
[11] "Component 12: Component 5: Mean relative difference: 0.1111"   
> 
> # with analytical gradients and unused Hessians
> mlghBhhhCon <- maxLik( llf, gfInd, hf, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlgBhhhCon, mlghBhhhCon, tolerance = 1e-3 )
[1] TRUE
> 
> # with analytical gradients and unused Hessians as attributes
> mlGHBhhhCon <- maxLik( llfGradHessInd, start = startVal, constraints = eqCon,
+    method = "BHHH" )
> all.equal( mlGHBhhhCon, mlghBhhhCon, tolerance = 1e-3 )
[1] TRUE
> all.equal( mlGHBhhhCon, mlGBhhhCon, tolerance = 1e-3 )
[1] TRUE
> 
> 
> ## BFGS method with equality constraints
> mlBfgsCon <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> print( mlBfgsCon )
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8198 1.68 
> summary( mlBfgsCon )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174    4.71 2.5e-06 ***
sigma    1.680      0.107   15.68 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> activePar( mlBfgsCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlBfgsCon )
[1] 413.1
> coef( mlBfgsCon )
    mu  sigma 
0.8198 1.6803 
> condiNumber( mlBfgsCon )
mu 	 1 
sigma 	 3.609 
> hessian( mlBfgsCon )
          mu  sigma
mu    -35.41 -15.21
sigma -15.21 -93.65
> logLik( mlBfgsCon )
[1] -204.5
> maximType( mlBfgsCon )
[1] "BFGS maximisation"
> nIter( mlBfgsCon )
function 
      31 
> nParam( mlBfgsCon )
[1] 2
> returnCode( mlBfgsCon )
[1] 0
> returnMessage( mlBfgsCon )
[1] "successful convergence "
> vcov( mlBfgsCon )
             mu     sigma
mu     0.030354 -0.004928
sigma -0.004928  0.011478
> logLik( summary( mlBfgsCon ) )
[1] -204.5
> all.equal( mlBfgsCon[ -c( 5, 6, 9, 10 ) ], mlCon[ -c( 5, 6, 9, 10 ) ],
+    tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001248"
> mlBfgsConInd <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> summary( mlBfgsConInd )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.07e-10 
--------------------------------------------
> all.equal( mlBfgsCon[], mlBfgsConInd[-12], tolerance = 1e-3 )
[1] TRUE
> mlBfgsConInd[12]
$gradientObs
              mu    sigma
  [1,] -0.333193 -0.40861
  [2,] -0.099212 -0.57861
  [3,]  1.168023  1.69720
  [4,]  0.113792 -0.57339
  [5,]  0.155431 -0.55455
  [6,]  1.278785  2.15258
  [7,]  0.390354 -0.33911
  [8,] -0.832318  0.56886
  [9,] -0.422718 -0.29490
 [10,] -0.251860 -0.48856
 [11,]  0.930976  0.86117
 [12,]  0.318734 -0.42444
 [13,]  0.347748 -0.39195
 [14,]  0.142251 -0.56114
 [15,] -0.329910 -0.41226
 [16,]  1.329682  2.37565
 [17,]  0.416518 -0.30364
 [18,] -1.329295  2.37393
 [19,]  0.560680 -0.06693
 [20,] -0.271079 -0.47167
 [21,] -0.692596  0.21086
 [22,] -0.090568 -0.58136
 [23,] -0.662971  0.14338
 [24,] -0.452498 -0.25110
 [25,] -0.378930 -0.35388
 [26,] -1.130999  1.55418
 [27,]  0.657327  0.13086
 [28,]  0.172493 -0.54515
 [29,] -0.742405  0.33096
 [30,]  0.952039  0.92781
 [31,]  0.365949 -0.37013
 [32,] -0.145183 -0.55973
 [33,]  0.697945  0.22336
 [34,]  0.685908  0.19537
 [35,]  0.645847  0.10572
 [36,]  0.551672 -0.08377
 [37,]  0.456236 -0.24540
 [38,]  0.019986 -0.59447
 [39,] -0.152898 -0.55586
 [40,] -0.205679 -0.52406
 [41,] -0.428282 -0.28694
 [42,] -0.083443 -0.58345
 [43,] -0.832555  0.56953
 [44,]  1.600319  3.70805
 [45,]  0.919557  0.82566
 [46,] -0.731759  0.30459
 [47,] -0.221557 -0.51266
 [48,] -0.266732 -0.47560
 [49,]  0.616366  0.04320
 [50,]  0.004786 -0.59511
 [51,]  0.243293 -0.49569
 [52,]  0.043622 -0.59195
 [53,]  0.033475 -0.59326
 [54,]  1.033353  1.19907
 [55,] -0.096091 -0.57963
 [56,]  1.138102  1.58126
 [57,] -1.033283  1.19883
 [58,]  0.477981 -0.21126
 [59,]  0.151582 -0.55654
 [60,]  0.216816 -0.51616
 [61,]  0.332778 -0.40907
 [62,] -0.291999 -0.45188
 [63,] -0.172198 -0.54532
 [64,] -0.657709  0.13171
 [65,] -0.695406  0.21741
 [66,]  0.278862 -0.46448
 [67,]  0.381353 -0.35078
 [68,]  0.101392 -0.57787
 [69,]  0.717173  0.26908
 [70,]  1.516111  3.26710
 [71,] -0.283999 -0.45962
 [72,] -1.571957  3.55687
 [73,]  0.776303  0.41746
 [74,] -0.438549 -0.27199
 [75,] -0.423537 -0.29373
 [76,]  0.790352  0.45444
 [77,] -0.137887 -0.56320
 [78,] -0.800905  0.48266
 [79,]  0.192278 -0.53302
 [80,] -0.034546 -0.59314
 [81,]  0.067927 -0.58739
 [82,]  0.336774 -0.40457
 [83,] -0.198729 -0.52879
 [84,]  0.520316 -0.14025
 [85,] -0.092347 -0.58082
 [86,]  0.298876 -0.44505
 [87,]  0.840838  0.59282
 [88,]  0.372124 -0.36247
 [89,] -0.167044 -0.54826
 [90,]  0.877652  0.69912
 [91,]  0.767636  0.39498
 [92,]  0.452325 -0.25137
 [93,]  0.232960 -0.50396
 [94,] -0.380961 -0.35129
 [95,]  1.027722  1.17957
 [96,] -0.361376 -0.37571
 [97,]  1.613337  3.77834
 [98,]  1.149536  1.62521
 [99,] -0.103125 -0.57728
[100,] -0.663266  0.14404

> nObs( mlBfgsConInd )
[1] 100
> 
> # with analytical gradients
> mlgBfgsCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> summary( mlgBfgsCon )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 30 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.9 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.814      0.173     4.7 2.7e-06 ***
sigma    1.670      0.106    15.8 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
7  outer iterations, barrier value 0.0002481 
--------------------------------------------
> all.equal( mlBfgsCon, mlgBfgsCon, tolerance = 1e-3 )
[1] "Component 1: Mean relative difference: 0.001554"         
[2] "Component 2: Mean relative difference: 0.006306"         
[3] "Component 3: Mean relative difference: 0.05463"          
[4] "Component 4: Mean relative difference: 0.02744"          
[5] "Component 9: Mean relative difference: 0.03226"          
[6] "Component 11: Component 3: Mean relative difference: 1"  
[7] "Component 11: Component 4: 1 string mismatch"            
[8] "Component 11: Component 5: Mean relative difference: 0.3"
> mlgBfgsConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> all.equal( mlgBfgsCon[], mlgBfgsConInd[-12], tolerance = 1e-3 )
[1] TRUE
> mlgBfgsConInd[12]
$gradientObs
              mu    sigma
  [1,] -0.335092 -0.41114
  [2,] -0.098314 -0.58255
  [3,]  1.184065  1.74311
  [4,]  0.117235 -0.57573
  [5,]  0.159372 -0.55627
  [6,]  1.296151  2.20745
  [7,]  0.397103 -0.33530
  [8,] -0.840181  0.58039
  [9,] -0.425686 -0.29601
 [10,] -0.252786 -0.49196
 [11,]  0.944185  0.89037
 [12,]  0.324627 -0.42267
 [13,]  0.353987 -0.38939
 [14,]  0.146035 -0.56307
 [15,] -0.331769 -0.41484
 [16,]  1.347656  2.43490
 [17,]  0.423579 -0.29900
 [18,] -1.343098  2.41441
 [19,]  0.569464 -0.05702
 [20,] -0.272234 -0.47490
 [21,] -0.698789  0.21693
 [22,] -0.089567 -0.58529
 [23,] -0.668810  0.14845
 [24,] -0.455822 -0.25164
 [25,] -0.381375 -0.35575
 [26,] -1.142431  1.58132
 [27,]  0.667266  0.14501
 [28,]  0.176638 -0.54657
 [29,] -0.749194  0.33884
 [30,]  0.965500  0.95836
 [31,]  0.372406 -0.36704
 [32,] -0.144834 -0.56365
 [33,]  0.708370  0.23945
 [34,]  0.696189  0.21088
 [35,]  0.655649  0.11934
 [36,]  0.560349 -0.07423
 [37,]  0.463772 -0.23943
 [38,]  0.022309 -0.59786
 [39,] -0.152642 -0.55977
 [40,] -0.206054 -0.52777
 [41,] -0.431317 -0.28795
 [42,] -0.082357 -0.58736
 [43,] -0.840421  0.58106
 [44,]  1.621527  3.79315
 [45,]  0.932630  0.85415
 [46,] -0.738420  0.31207
 [47,] -0.222121 -0.51628
 [48,] -0.267836 -0.47887
 [49,]  0.625816  0.05548
 [50,]  0.006927 -0.59861
 [51,]  0.248284 -0.49572
 [52,]  0.046227 -0.59512
 [53,]  0.035959 -0.59653
 [54,]  1.047786  1.23507
 [55,] -0.095155 -0.58357
 [56,]  1.153787  1.62487
 [57,] -1.043548  1.22027
 [58,]  0.485777 -0.20453
 [59,]  0.155477 -0.55831
 [60,]  0.221490 -0.51675
 [61,]  0.338839 -0.40692
 [62,] -0.293405 -0.45490
 [63,] -0.172172 -0.54918
 [64,] -0.663485  0.13660
 [65,] -0.701633  0.22359
 [66,]  0.284278 -0.46371
 [67,]  0.387994 -0.34724
 [68,]  0.104687 -0.58038
 [69,]  0.727827  0.28613
 [70,]  1.536313  3.34368
 [71,] -0.285310 -0.46272
 [72,] -1.588659  3.61691
 [73,]  0.787664  0.43760
 [74,] -0.441707 -0.27280
 [75,] -0.426515 -0.29484
 [76,]  0.801881  0.47534
 [77,] -0.137452 -0.56713
 [78,] -0.808392  0.49286
 [79,]  0.196660 -0.53409
 [80,] -0.032875 -0.59688
 [81,]  0.070823 -0.59031
 [82,]  0.342883 -0.40231
 [83,] -0.199021 -0.53253
 [84,]  0.528618 -0.13194
 [85,] -0.091367 -0.58475
 [86,]  0.304532 -0.44379
 [87,]  0.852970  0.61656
 [88,]  0.378655 -0.35920
 [89,] -0.166957 -0.55213
 [90,]  0.890224  0.72503
 [91,]  0.778893  0.41465
 [92,]  0.459814 -0.24554
 [93,]  0.237828 -0.50421
 [94,] -0.383430 -0.35312
 [95,]  1.042087  1.21518
 [96,] -0.363611 -0.37785
 [97,]  1.634701  3.86480
 [98,]  1.165357  1.66969
 [99,] -0.102273 -0.58122
[100,] -0.669109  0.14912

> 
> # with analytical gradients and unused Hessians
> mlghBfgsCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon,
+    method = "BFGS" )
> all.equal( mlgBfgsCon, mlghBfgsCon, tolerance = 1e-3 )
[1] TRUE
> 
> ## NM method with equality constraints
> mlNmCon <- maxLik( llf, start = startVal, constraints = eqCon, method = "NM", SUMTTol=0)
> print( mlNmCon )
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.8197 1.68 
> summary( mlNmCon )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.418e-10 
--------------------------------------------
> activePar( mlNmCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlNmCon )
[1] 413.1
> coef( mlNmCon )
    mu  sigma 
0.8197 1.6803 
> condiNumber( mlNmCon )
mu 	 1 
sigma 	 3.609 
> hessian( mlNmCon )
          mu  sigma
mu    -35.41 -15.21
sigma -15.21 -93.65
> logLik( mlNmCon )
[1] -204.5
> maximType( mlNmCon )
[1] "Nelder-Mead maximisation"
> nIter( mlNmCon )
function 
      57 
> nParam( mlNmCon )
[1] 2
> returnCode( mlNmCon )
[1] 0
> returnMessage( mlNmCon )
[1] "successful convergence "
> vcov( mlNmCon )
             mu     sigma
mu     0.030354 -0.004928
sigma -0.004928  0.011478
> logLik( summary( mlNmCon ) )
[1] -204.5
> all.equal( mlNmCon[ -c( 5, 6, 9, 10 ) ], mlCon[ -c( 5, 6, 9, 10 ) ],
+    tolerance = 1e-3 )
[1] "Component 4: Mean relative difference: 0.001248"
> mlNmConInd <- maxLik( llfInd, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> summary( mlNmConInd )
--------------------------------------------
Maximum Likelihood estimation
Nelder-Mead maximisation, 57 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.820      0.174     4.7 2.5e-06 ***
sigma    1.680      0.107    15.7 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
10  outer iterations, barrier value 2.418e-10 
--------------------------------------------
> all.equal( mlNmCon[], mlNmConInd[-12], tolerance = 1e-3 )
[1] TRUE
> mlNmConInd[12]
$gradientObs
              mu    sigma
  [1,] -0.333153 -0.40862
  [2,] -0.099187 -0.57859
  [3,]  1.167967  1.69707
  [4,]  0.113803 -0.57336
  [5,]  0.155439 -0.55453
  [6,]  1.278722  2.15241
  [7,]  0.390348 -0.33909
  [8,] -0.832245  0.56872
  [9,] -0.422672 -0.29493
 [10,] -0.251825 -0.48857
 [11,]  0.930935  0.86110
 [12,]  0.318732 -0.42442
 [13,]  0.347744 -0.39193
 [14,]  0.142261 -0.56112
 [15,] -0.329870 -0.41228
 [16,]  1.329615  2.37547
 [17,]  0.416510 -0.30362
 [18,] -1.329191  2.37357
 [19,]  0.560663 -0.06693
 [20,] -0.271042 -0.47168
 [21,] -0.692532  0.21076
 [22,] -0.090543 -0.58135
 [23,] -0.662910  0.14329
 [24,] -0.452450 -0.25115
 [25,] -0.378887 -0.35391
 [26,] -1.130907  1.55392
 [27,]  0.657303  0.13085
 [28,]  0.172500 -0.54513
 [29,] -0.742338  0.33084
 [30,]  0.951996  0.92774
 [31,]  0.365944 -0.37011
 [32,] -0.145155 -0.55972
 [33,]  0.697919  0.22334
 [34,]  0.685883  0.19536
 [35,]  0.645824  0.10572
 [36,]  0.551656 -0.08376
 [37,]  0.456225 -0.24538
 [38,]  0.020004 -0.59445
 [39,] -0.152869 -0.55586
 [40,] -0.205647 -0.52406
 [41,] -0.428236 -0.28698
 [42,] -0.083419 -0.58343
 [43,] -0.832482  0.56938
 [44,]  1.600234  3.70775
 [45,]  0.919516  0.82560
 [46,] -0.731693  0.30447
 [47,] -0.221524 -0.51267
 [48,] -0.266696 -0.47561
 [49,]  0.616345  0.04320
 [50,]  0.004804 -0.59509
 [51,]  0.243296 -0.49566
 [52,]  0.043638 -0.59193
 [53,]  0.033491 -0.59324
 [54,]  1.033305  1.19898
 [55,] -0.096066 -0.57962
 [56,]  1.138048  1.58114
 [57,] -1.033197  1.19861
 [58,]  0.477969 -0.21125
 [59,]  0.151591 -0.55651
 [60,]  0.216820 -0.51613
 [61,]  0.332776 -0.40905
 [62,] -0.291961 -0.45189
 [63,] -0.172168 -0.54532
 [64,] -0.657647  0.13161
 [65,] -0.695343  0.21731
 [66,]  0.278863 -0.46446
 [67,]  0.381347 -0.35076
 [68,]  0.101404 -0.57785
 [69,]  0.717145  0.26906
 [70,]  1.516032  3.26684
 [71,] -0.283962 -0.45963
 [72,] -1.571837  3.55639
 [73,]  0.776272  0.41743
 [74,] -0.438502 -0.27203
 [75,] -0.423491 -0.29377
 [76,]  0.790320  0.45441
 [77,] -0.137860 -0.56319
 [78,] -0.800834  0.48252
 [79,]  0.192285 -0.53300
 [80,] -0.034525 -0.59312
 [81,]  0.067942 -0.58737
 [82,]  0.336771 -0.40455
 [83,] -0.198698 -0.52878
 [84,]  0.520302 -0.14024
 [85,] -0.092323 -0.58080
 [86,]  0.298876 -0.44503
 [87,]  0.840802  0.59277
 [88,]  0.372119 -0.36245
 [89,] -0.167014 -0.54825
 [90,]  0.877614  0.69907
 [91,]  0.767605  0.39495
 [92,]  0.452315 -0.25135
 [93,]  0.232964 -0.50393
 [94,] -0.380917 -0.35131
 [95,]  1.027674  1.17948
 [96,] -0.361334 -0.37574
 [97,]  1.613252  3.77804
 [98,]  1.149480  1.62509
 [99,] -0.103099 -0.57726
[100,] -0.663205  0.14395

> nObs( mlNmConInd )
[1] 100
> 
> # with unused analytical gradients
> mlgNmCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlNmCon, mlgNmCon, tolerance = 1e-3 )
[1] TRUE
> mlgNmConInd <- maxLik( llfInd, gfInd, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlgNmCon[], mlgNmConInd[-12], tolerance = 1e-3 )
[1] TRUE
> mlgNmConInd[12]
$gradientObs
              mu    sigma
  [1,] -0.333153 -0.40862
  [2,] -0.099187 -0.57859
  [3,]  1.167967  1.69707
  [4,]  0.113803 -0.57336
  [5,]  0.155439 -0.55453
  [6,]  1.278722  2.15241
  [7,]  0.390348 -0.33909
  [8,] -0.832245  0.56872
  [9,] -0.422672 -0.29493
 [10,] -0.251825 -0.48857
 [11,]  0.930935  0.86110
 [12,]  0.318732 -0.42442
 [13,]  0.347744 -0.39193
 [14,]  0.142261 -0.56112
 [15,] -0.329870 -0.41228
 [16,]  1.329615  2.37547
 [17,]  0.416510 -0.30362
 [18,] -1.329191  2.37357
 [19,]  0.560663 -0.06693
 [20,] -0.271042 -0.47168
 [21,] -0.692532  0.21076
 [22,] -0.090543 -0.58135
 [23,] -0.662910  0.14329
 [24,] -0.452450 -0.25115
 [25,] -0.378887 -0.35391
 [26,] -1.130907  1.55392
 [27,]  0.657303  0.13085
 [28,]  0.172500 -0.54513
 [29,] -0.742338  0.33084
 [30,]  0.951996  0.92774
 [31,]  0.365944 -0.37011
 [32,] -0.145155 -0.55972
 [33,]  0.697919  0.22334
 [34,]  0.685883  0.19536
 [35,]  0.645824  0.10572
 [36,]  0.551656 -0.08376
 [37,]  0.456225 -0.24538
 [38,]  0.020004 -0.59445
 [39,] -0.152869 -0.55586
 [40,] -0.205647 -0.52406
 [41,] -0.428236 -0.28698
 [42,] -0.083419 -0.58343
 [43,] -0.832482  0.56938
 [44,]  1.600234  3.70775
 [45,]  0.919516  0.82560
 [46,] -0.731693  0.30447
 [47,] -0.221524 -0.51267
 [48,] -0.266696 -0.47561
 [49,]  0.616345  0.04320
 [50,]  0.004804 -0.59509
 [51,]  0.243296 -0.49566
 [52,]  0.043638 -0.59193
 [53,]  0.033491 -0.59324
 [54,]  1.033305  1.19898
 [55,] -0.096066 -0.57962
 [56,]  1.138048  1.58114
 [57,] -1.033197  1.19861
 [58,]  0.477969 -0.21125
 [59,]  0.151591 -0.55651
 [60,]  0.216820 -0.51613
 [61,]  0.332776 -0.40905
 [62,] -0.291961 -0.45189
 [63,] -0.172168 -0.54532
 [64,] -0.657647  0.13161
 [65,] -0.695343  0.21731
 [66,]  0.278863 -0.46446
 [67,]  0.381347 -0.35076
 [68,]  0.101404 -0.57785
 [69,]  0.717145  0.26906
 [70,]  1.516032  3.26684
 [71,] -0.283962 -0.45963
 [72,] -1.571837  3.55639
 [73,]  0.776272  0.41743
 [74,] -0.438502 -0.27203
 [75,] -0.423491 -0.29377
 [76,]  0.790320  0.45441
 [77,] -0.137860 -0.56319
 [78,] -0.800834  0.48252
 [79,]  0.192285 -0.53300
 [80,] -0.034525 -0.59312
 [81,]  0.067942 -0.58737
 [82,]  0.336771 -0.40455
 [83,] -0.198698 -0.52878
 [84,]  0.520302 -0.14024
 [85,] -0.092323 -0.58080
 [86,]  0.298876 -0.44503
 [87,]  0.840802  0.59277
 [88,]  0.372119 -0.36245
 [89,] -0.167014 -0.54825
 [90,]  0.877614  0.69907
 [91,]  0.767605  0.39495
 [92,]  0.452315 -0.25135
 [93,]  0.232964 -0.50393
 [94,] -0.380917 -0.35131
 [95,]  1.027674  1.17948
 [96,] -0.361334 -0.37574
 [97,]  1.613252  3.77804
 [98,]  1.149480  1.62509
 [99,] -0.103099 -0.57726
[100,] -0.663205  0.14395

> 
> # with unused analytical gradients and Hessians
> mlghNmCon <- maxLik( llf, gf, hf, start = startVal, constraints = eqCon,
+    method = "NM", SUMTTol=0)
> all.equal( mlgNmCon, mlghNmCon, tolerance = 1e-3 )
[1] TRUE
> 
> ## SANN method with equality constraints
> mlSannCon <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "SANN", SUMTTol=0)
> print( mlSannCon )
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 (2 free parameter(s))
Estimate(s): 0.816 1.684 
> summary( mlSannCon )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -204.5 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       0.816      0.175    4.67   3e-06 ***
sigma    1.684      0.108   15.63  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 1 
penalty close to zero 
9  outer iterations, barrier value 1.234e-09 
--------------------------------------------
> activePar( mlSannCon )
   mu sigma 
 TRUE  TRUE 
> AIC( mlSannCon )
[1] 413.1
> coef( mlSannCon )
   mu sigma 
0.816 1.684 
> condiNumber( mlSannCon )
mu 	 1 
sigma 	 3.616 
> hessian( mlSannCon )
          mu  sigma
mu    -35.27 -15.29
sigma -15.29 -92.80
> logLik( mlSannCon )
[1] -204.5
> maximType( mlSannCon )
[1] "SANN maximisation"
> nIter( mlSannCon )
function 
   10000 
> nParam( mlSannCon )
[1] 2
> returnCode( mlSannCon )
[1] 0
> returnMessage( mlSannCon )
[1] "successful convergence "
> vcov( mlSannCon )
             mu     sigma
mu     0.030533 -0.005031
sigma -0.005031  0.011605
> logLik( summary( mlSannCon ) )
[1] -204.5
> all.equal( mlSannCon[ -c( 5, 6, 9, 10 ) ], mlBfgsCon[ -c( 5, 6, 9, 10 ) ],
+    tolerance = 1e-3 )
[1] "Component 2: Mean relative difference: 0.003013"           
[2] "Component 3: Mean relative difference: 0.01451"            
[3] "Component 4: Mean relative difference: 0.007345"           
[4] "Component 7: Component 5: Mean relative difference: 0.1111"
> 
> # with unused analytical gradients
> mlgSannCon <- maxLik( llf, gf, start = startVal, constraints = eqCon,
+    method = "SANN", SUMTTol=0)
> all.equal( mlSannCon, mlgSannCon, tolerance = 1e-3 )
[1] TRUE
> 
> # with a user-specified function to generate a new candidate point
> mlSannConCand <- maxLik( llf, start = startVal, constraints = eqCon,
+    method = "SANN", cand = function(x)c(rnorm(1,x[1]),rnorm(1,x[2])) )
Warning message:
In (function (fn, grad = NULL, hess = NULL, start, maxRoutine, constraints,  :
  problem in imposing equality constraints: the constraints are not satisfied (barrier value = 0.254780368286163). Try setting 'SUMTTol' to 0
> summary( mlSannConCand )
--------------------------------------------
Maximum Likelihood estimation
SANN maximisation, 10000 iterations
Return code 0: successful convergence 
Log-Likelihood: -201.6 
2  free parameters
Estimates:
      Estimate Std. error t value Pr(> t)    
mu       1.183      0.182     6.5 8.2e-11 ***
sigma    1.822      0.129    14.1 < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Warning: constrained likelihood estimation. Inference is probably wrong
Constrained optimization based on SUMT 
Return code: 2 
successive function values within tolerance limit 
2  outer iterations, barrier value 0.2548 
--------------------------------------------
> all.equal( mlSannConCand, mlSannCon, tolerance = 1e-3 )
[1] "Component 1: Mean relative difference: 0.01463"          
[2] "Component 2: Mean relative difference: 0.168"            
[3] "Component 3: Mean relative difference: 68.17"            
[4] "Component 4: Mean relative difference: 0.7647"           
[5] "Component 11: Component 2: Mean relative difference: 1"  
[6] "Component 11: Component 3: Mean relative difference: 0.5"
[7] "Component 11: Component 4: 1 string mismatch"            
[8] "Component 11: Component 5: Mean relative difference: 3.5"
> 
> 
> ## test for method "estfun"
> library( sandwich )
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

> try( estfun( ml ) )
Error in estfun.maxLik(ml) : 
  cannot return the gradients of the log-likelihood function evaluated at each observation: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> estfun( mlInd )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlgInd )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlBHHH )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlgBHHH )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlIndBFGS )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlgIndBFGS )[ 1:5, ]
           mu   sigma
[1,] -0.39452 -0.2678
[2,] -0.19432 -0.4819
[3,]  0.88999  0.8883
[4,] -0.01206 -0.5503
[5,]  0.02357 -0.5495
> estfun( mlIndNM )[ 1:5, ]
           mu   sigma
[1,] -0.39439 -0.2679
[2,] -0.19422 -0.4819
[3,]  0.88990  0.8882
[4,] -0.01200 -0.5502
[5,]  0.02363 -0.5495
> estfun( mlgIndNM )[ 1:5, ]
           mu   sigma
[1,] -0.39439 -0.2679
[2,] -0.19422 -0.4819
[3,]  0.88990  0.8882
[4,] -0.01200 -0.5502
[5,]  0.02363 -0.5495
> estfun( mlIndSANN )[ 1:5, ]
           mu   sigma
[1,] -0.39480 -0.2674
[2,] -0.19460 -0.4817
[3,]  0.88966  0.8873
[4,] -0.01235 -0.5502
[5,]  0.02327 -0.5495
> estfun( mlgIndSANN )[ 1:5, ]
           mu   sigma
[1,] -0.39480 -0.2674
[2,] -0.19460 -0.4817
[3,]  0.88966  0.8873
[4,] -0.01235 -0.5502
[5,]  0.02327 -0.5495
> estfun( mlIndFix )[ 1:5, ]
     mu   sigma
[1,] NA -0.3412
[2,] NA -0.5130
[3,] NA  1.0498
[4,] NA -0.5445
[5,] NA -0.5368
> estfun( mlgIndFix )[ 1:5, ]
     mu   sigma
[1,] NA -0.3412
[2,] NA -0.5130
[3,] NA  1.0498
[4,] NA -0.5445
[5,] NA -0.5368
> estfun( mlFixBHHH )[ 1:5, ]
     mu   sigma
[1,] NA -0.3412
[2,] NA -0.5130
[3,] NA  1.0498
[4,] NA -0.5445
[5,] NA -0.5368
> estfun( mlgFixBHHH )[ 1:5, ]
     mu   sigma
[1,] NA -0.3412
[2,] NA -0.5130
[3,] NA  1.0498
[4,] NA -0.5445
[5,] NA -0.5368
> estfun( mlIndFixBfgs )[ 1:5, ]
           mu   sigma
[1,] -0.33639 -0.3412
[2,] -0.13815 -0.5130
[3,]  0.93552  1.0498
[4,]  0.04232 -0.5445
[5,]  0.07760 -0.5368
> estfun( mlgIndFixBfgs )[ 1:5, ]
           mu   sigma
[1,] -0.33639 -0.3412
[2,] -0.13815 -0.5130
[3,]  0.93552  1.0498
[4,]  0.04232 -0.5445
[5,]  0.07760 -0.5368
> estfun( mlIndFixNm )[ 1:5, ]
           mu   sigma
[1,] -0.33641 -0.3412
[2,] -0.13816 -0.5130
[3,]  0.93558  1.0500
[4,]  0.04232 -0.5446
[5,]  0.07760 -0.5368
> estfun( mlgIndFixNm )[ 1:5, ]
           mu   sigma
[1,] -0.33641 -0.3412
[2,] -0.13816 -0.5130
[3,]  0.93558  1.0500
[4,]  0.04232 -0.5446
[5,]  0.07760 -0.5368
> estfun( mlIndFixSann )[ 1:5, ]
           mu   sigma
[1,] -0.33640 -0.3412
[2,] -0.13815 -0.5130
[3,]  0.93553  1.0499
[4,]  0.04232 -0.5445
[5,]  0.07760 -0.5368
> estfun( mlgIndFixSann )[ 1:5, ]
           mu   sigma
[1,] -0.33640 -0.3412
[2,] -0.13815 -0.5130
[3,]  0.93553  1.0499
[4,]  0.04232 -0.5445
[5,]  0.07760 -0.5368
> estfun( mlBfgsInEqInd )[ 1:5, ]
          mu   sigma
[1,] -0.3332 -0.4086
[2,] -0.0992 -0.5786
[3,]  1.1680  1.6972
[4,]  0.1138 -0.5734
[5,]  0.1554 -0.5545
> estfun( mlgBfgsInEqInd )[ 1:5, ]
          mu   sigma
[1,] -0.3332 -0.4086
[2,] -0.0992 -0.5786
[3,]  1.1680  1.6972
[4,]  0.1138 -0.5734
[5,]  0.1554 -0.5545
> estfun( mlNmInEqInd )[ 1:5, ]
          mu   sigma
[1,] -0.3332 -0.4086
[2,] -0.0992 -0.5786
[3,]  1.1680  1.6972
[4,]  0.1138 -0.5734
[5,]  0.1554 -0.5545
> estfun( mlConInd )[ 1:5, ]
           mu   sigma
[1,] -0.33319 -0.4086
[2,] -0.09921 -0.5786
[3,]  1.16802  1.6972
[4,]  0.11379 -0.5734
[5,]  0.15543 -0.5546
> estfun( mlgConInd )[ 1:5, ]
          mu   sigma
[1,] -0.3452 -0.3999
[2,] -0.1083 -0.5793
[3,]  1.1749  1.7061
[4,]  0.1074 -0.5796
[5,]  0.1495 -0.5615
> estfun( mlBhhhCon )[ 1:5, ]
           mu   sigma
[1,] -0.33331 -0.4085
[2,] -0.09928 -0.5786
[3,]  1.16818  1.6976
[4,]  0.11376 -0.5735
[5,]  0.15540 -0.5546
> estfun( mlgBhhhCon )[ 1:5, ]
          mu   sigma
[1,] -0.3440 -0.4030
[2,] -0.1060 -0.5815
[3,]  1.1828  1.7307
[4,]  0.1106 -0.5798
[5,]  0.1530 -0.5612
> estfun( mlBfgsConInd )[ 1:5, ]
           mu   sigma
[1,] -0.33319 -0.4086
[2,] -0.09921 -0.5786
[3,]  1.16802  1.6972
[4,]  0.11379 -0.5734
[5,]  0.15543 -0.5546
> estfun( mlgBfgsConInd )[ 1:5, ]
           mu   sigma
[1,] -0.33509 -0.4111
[2,] -0.09831 -0.5825
[3,]  1.18407  1.7431
[4,]  0.11724 -0.5757
[5,]  0.15937 -0.5563
> estfun( mlNmConInd )[ 1:5, ]
           mu   sigma
[1,] -0.33315 -0.4086
[2,] -0.09919 -0.5786
[3,]  1.16797  1.6971
[4,]  0.11380 -0.5734
[5,]  0.15544 -0.5545
> estfun( mlgNmConInd )[ 1:5, ]
           mu   sigma
[1,] -0.33315 -0.4086
[2,] -0.09919 -0.5786
[3,]  1.16797  1.6971
[4,]  0.11380 -0.5734
[5,]  0.15544 -0.5545
> 
> 
> ## test for method "bread"
> try( bread( ml ) )
Error in nObs.maxLik(x) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> bread( mlInd )
         mu sigma
mu    3.301 0.000
sigma 0.000 1.649
> bread( mlgInd )
              mu      sigma
mu     3.300e+00 -8.456e-11
sigma -8.456e-11  1.650e+00
> bread( mlBHHH )
           mu   sigma
mu     3.3062 -0.1088
sigma -0.1088  1.7979
> bread( mlgBHHH )
           mu   sigma
mu     3.3062 -0.1088
sigma -0.1088  1.7979
> bread( mlIndBFGS )
         mu sigma
mu    3.301 0.000
sigma 0.000 1.649
> bread( mlgIndBFGS )
              mu      sigma
mu     3.300e+00 -2.235e-06
sigma -2.235e-06  1.650e+00
> bread( mlIndNM )
             mu     sigma
mu     3.297506 -0.001547
sigma -0.001547  1.650300
> bread( mlgIndNM )
              mu      sigma
mu     3.3001669 -0.0003702
sigma -0.0003702  1.6505071
> bread( mlIndSANN )
         mu sigma
mu    3.298 0.000
sigma 0.000 1.649
> bread( mlgIndSANN )
            mu    sigma
mu    3.299743 0.001754
sigma 0.001754 1.649976
> bread( mlIndFix )
      mu sigma
mu     0 0.000
sigma  0 1.667
> bread( mlgIndFix )
      mu sigma
mu     0 0.000
sigma  0 1.666
> bread( mlFixBHHH )
      mu sigma
mu     0 0.000
sigma  0 1.786
> bread( mlgFixBHHH )
      mu sigma
mu     0 0.000
sigma  0 1.786
> bread( mlIndFixBfgs )
      mu sigma
mu     0 0.000
sigma  0 1.667
> bread( mlgIndFixBfgs )
      mu sigma
mu     0 0.000
sigma  0 1.666
> bread( mlIndFixNm )
      mu sigma
mu     0 0.000
sigma  0 1.665
> bread( mlgIndFixNm )
      mu sigma
mu     0 0.000
sigma  0 1.666
> bread( mlIndFixSann )
      mu sigma
mu     0 0.000
sigma  0 1.667
> bread( mlgIndFixSann )
      mu sigma
mu     0 0.000
sigma  0 1.666
> bread( mlBfgsInEqInd )
           mu   sigma
mu     3.0353 -0.4927
sigma -0.4927  1.1475
> bread( mlgBfgsInEqInd )
           mu   sigma
mu     3.0353 -0.4933
sigma -0.4933  1.1477
> bread( mlNmInEqInd )
           mu   sigma
mu     3.0343 -0.4941
sigma -0.4941  1.1473
> bread( mlConInd )
           mu   sigma
mu     3.0335 -0.4932
sigma -0.4932  1.1473
> bread( mlgConInd )
           mu   sigma
mu     2.9715 -0.4514
sigma -0.4514  1.1112
> bread( mlBhhhCon )
           mu   sigma
mu     3.0360 -0.4933
sigma -0.4933  1.1467
> bread( mlgBhhhCon )
           mu   sigma
mu     2.9668 -0.4582
sigma -0.4582  1.1005
> bread( mlBfgsConInd )
           mu   sigma
mu     3.0362 -0.4937
sigma -0.4937  1.1478
> bread( mlgBfgsConInd )
           mu   sigma
mu     3.0053 -0.4903
sigma -0.4903  1.1161
> bread( mlNmConInd )
           mu   sigma
mu     3.0361 -0.4936
sigma -0.4936  1.1474
> bread( mlgNmConInd )
           mu   sigma
mu     3.0355 -0.4934
sigma -0.4934  1.1479
> 
> 
> ## test for method "sandwich"
> try( sandwich( ml ) )
Error in nObs.maxLik(x) : 
  cannot return the number of observations: please re-run 'maxLik' and provide a gradient function using argument 'grad' or (if no gradient function is specified) a log-likelihood function using argument 'logLik' that return the gradients or log-likelihood values, respectively, at each observation
> printSandwich <- function( x ) {
+    print( sandwich( x ) )
+    print( all.equal( sandwich( x ), vcov( x ) ) )
+ }
> printSandwich( mlInd )
             mu     sigma
mu    0.0330159 0.0009978
sigma 0.0009978 0.0151502
[1] "Mean relative difference: 0.06664"
> printSandwich( mlgInd )
             mu     sigma
mu    0.0329960 0.0009981
sigma 0.0009981 0.0151695
[1] "Mean relative difference: 0.06628"
> printSandwich( mlBHHH )
             mu     sigma
mu     0.033062 -0.001088
sigma -0.001088  0.017979
[1] TRUE
> printSandwich( mlgBHHH )
             mu     sigma
mu     0.033062 -0.001088
sigma -0.001088  0.017979
[1] TRUE
> printSandwich( mlIndBFGS )
             mu     sigma
mu    0.0330159 0.0009978
sigma 0.0009978 0.0151502
[1] "Mean relative difference: 0.06664"
> printSandwich( mlgIndBFGS )
             mu     sigma
mu    0.0329960 0.0009981
sigma 0.0009981 0.0151695
[1] "Mean relative difference: 0.06628"
> printSandwich( mlIndNM )
             mu     sigma
mu    0.0329410 0.0009714
sigma 0.0009714 0.0151702
[1] "Mean relative difference: 0.06674"
> printSandwich( mlgIndNM )
             mu     sigma
mu    0.0329956 0.0009949
sigma 0.0009949 0.0151747
[1] "Mean relative difference: 0.06646"
> printSandwich( mlIndSANN )
             mu     sigma
mu    0.0329513 0.0009792
sigma 0.0009792 0.0151472
[1] "Mean relative difference: 0.06637"
> printSandwich( mlgIndSANN )
            mu    sigma
mu    0.032998 0.001014
sigma 0.001014 0.015171
[1] "Mean relative difference: 0.0662"
> printSandwich( mlIndFix )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlgIndFix )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlFixBHHH )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlgFixBHHH )
      mu sigma
mu    NA    NA
sigma NA    NA
[1] "'is.NA' value mismatch: 0 in current 4 in target"
> printSandwich( mlIndFixBfgs )
      mu   sigma
mu     0 0.00000
sigma  0 0.01555
[1] "Mean relative difference: 0.07172"
> printSandwich( mlgIndFixBfgs )
      mu   sigma
mu     0 0.00000
sigma  0 0.01554
[1] "Mean relative difference: 0.07209"
> printSandwich( mlIndFixNm )
      mu   sigma
mu     0 0.00000
sigma  0 0.01553
[1] "Mean relative difference: 0.0725"
> printSandwich( mlgIndFixNm )
      mu   sigma
mu     0 0.00000
sigma  0 0.01554
[1] "Mean relative difference: 0.07205"
> printSandwich( mlIndFixSann )
      mu   sigma
mu     0 0.00000
sigma  0 0.01555
[1] "Mean relative difference: 0.07167"
> printSandwich( mlgIndFixSann )
      mu   sigma
mu     0 0.00000
sigma  0 0.01554
[1] "Mean relative difference: 0.07208"
> printSandwich( mlBfgsInEqInd )
             mu     sigma
mu     0.035466 -0.003874
sigma -0.003874  0.011784
[1] "Mean relative difference: 0.1369"
> printSandwich( mlgBfgsInEqInd )
             mu     sigma
mu     0.035464 -0.003888
sigma -0.003888  0.011789
[1] "Mean relative difference: 0.1365"
> printSandwich( mlNmInEqInd )
             mu     sigma
mu     0.035435 -0.003906
sigma -0.003906  0.011779
[1] "Mean relative difference: 0.1357"
> printSandwich( mlConInd )
             mu     sigma
mu     0.035421 -0.003887
sigma -0.003887  0.011781
[1] "Mean relative difference: 0.1361"
> printSandwich( mlgConInd )
             mu     sigma
mu     0.035080 -0.003484
sigma -0.003484  0.011496
[1] "Mean relative difference: 0.1459"
> printSandwich( mlBhhhCon )
             mu     sigma
mu     0.035494 -0.003893
sigma -0.003893  0.011774
[1] "Mean relative difference: 0.1366"
> printSandwich( mlgBhhhCon )
             mu     sigma
mu     0.035184 -0.003562
sigma -0.003562  0.011427
[1] "Mean relative difference: 0.1485"
> printSandwich( mlBfgsConInd )
             mu     sigma
mu     0.035483 -0.003898
sigma -0.003898  0.011790
[1] "Mean relative difference: 0.1364"
> printSandwich( mlgBfgsConInd )
             mu     sigma
mu     0.035521 -0.003882
sigma -0.003882  0.011565
[1] "Mean relative difference: 0.1443"
> printSandwich( mlNmConInd )
             mu     sigma
mu     0.035478 -0.003893
sigma -0.003893  0.011780
[1] "Mean relative difference: 0.1364"
> printSandwich( mlgNmConInd )
             mu     sigma
mu     0.035464 -0.003888
sigma -0.003888  0.011790
[1] "Mean relative difference: 0.1365"
> 
> proc.time()
   user  system elapsed 
 31.128   0.084  31.242 
