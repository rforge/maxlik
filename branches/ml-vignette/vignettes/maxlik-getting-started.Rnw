\documentclass{article}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[inline]{enumitem}
\usepackage{indentfirst}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{xspace}

\newcommand{\COii}{\ensuremath{\mathit{CO}_{2}}\xspace}
\newcommand*{\mat}[1]{\mathsf{#1}}
\newcommand{\likelihood}{\mathcal{L}}% likelihood
\newcommand{\loglik}{\ell}% log likelihood
\newcommand{\maxlik}{\texttt{maxLik}\xspace}
\newcommand{\me}{\mathrm{e}} % Konstant e=2,71828
\newcommand{\R}{\texttt{R}\xspace}
\newcommand*{\transpose}{^{\mkern-1.5mu\mathsf{T}}}
\renewcommand*{\vec}[1]{\boldsymbol{#1}}

% \VignetteIndexEntry{Introduction: what is maximum likelihood}

\begin{document}
<<foo,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60,
        try.outFile=stdout()  # make try to produce error messages
        )
foo <- packageDescription("maxLik")
library(ggplot2)
library(magrittr)
library(plot3D)
@

\title{Getting started with maximum likelihood and \texttt{maxLik}}
\author{Ott Toomet}
\maketitle

\section{Introduction}

This vignette is intended for those who are rather new to both
maximum likelihood (ML) estimation and the \texttt{maxLik} package.
The potential target group contains advanced undergraduate students in
technical fields, such as statistics or economics, graduate students
in social sciences or engineering who are devising their own
estimators, and researchers and practitioners who have little previous
experience with ML or with \texttt{maxLik}.  However, one should have basic knowledge
of \R language.  If you are familiar enough with the concept of ML, you
may
skip the theoretical introduction and go straight to the
Section~\ref{sec:maxlik-usage} for \texttt{maxLik} usage.

Maximum Likelihood (ML) in its core is maximizing the \emph{likelihood}
over the parameters of interest.  The first section explains what is
likelihood and how is it related to probability.  We provide two toy
examples, and at the end of the section derive the likelihood function
for linear regression.  All the cases are supplemented with code
examples.  This section should help beginners to get started with both
theoretical background and \texttt{maxLik} usage.
The second section is solely devoted to
\texttt{maxLik} usage, the reader is assumed to know the relevant
concepts and look these up as necessary.


\section{What Is Likelihood? }
\label{sec:what-is-likelihood}

This section is intended for readers who are unfamiliar with the
concept of likelihood, or need a quick intuitive brush-up.  We discuss
three cases: tossing a coin (binomial distribution), computing sample
average (normal distribution), and linear regression (normal
distribution).  The examples assume little knowledge besides basic
statistics and \R knowledge.

Experienced readers should skip this section and start from
Section~\ref{sec:basic-usage}. 


\section{Discrete Random Variables}
\label{sec:discrete-random-variables}

We start with discrete random variables.  ``Discrete'' refers to the
case where only a limited number of different outcomes are possible,
and hence we can compute the probability of all these outcomes.

Imagine you are tossing a fair
coin.  What are the possible outcomes and what are the related
probabilities?  Obviously, in case of a coin there are only two
outcomes, heads $H$ and tails $T$.  If the coin is fair, both of these
will have probability exactly 0.5.
Such process is called \emph{Bernoulli
  process}.  More specifically, this is \emph{Bernoulli(0.5)} process
as for the fair coin the probability of ``success'' is 0.5 (we consider
success to be heads in this example).
If the coin is not fair, we denote the corresponding process
Bernoulli($p$), where $p$ is the probability to get heads.

Now let us toss the coin two times.  What is the probability that we end
up with one heads and one tails?  First, as the coin tosses are
independent,\footnote{Events are independent when outcome of one event
  does not influence the outcome of the other event.  Here the result
  of the second toss is not affected by the outcome of the first toss.}
we can just multiply the probabilities: $0.5$ for a single heads and $0.5$
for a single tails equals $0.25$ when multiplied.  However, this is not the whole
story--we have two ways to get one heads and one tails,
either $H$, $T$ or $T$, $H$.  Both of these events are equally likely,
so the final answer will be 0.5.

But now imagine we do not know if the coin is fair.  Imagine we are
not tossing a
coin but and object of complex shape instead.  We can still label one
side of the object as ``heads'' and the other as ``tails''.
How can we tell what is the probability of heads?
Let's start by 
denoting it with $p$.  Hence the probability of tails will be $1-p$,
and the probability to receive one heads, one tails when we toss the
object two times will be
$2 p (1-p)$, $p$ for one heads, $1-p$ for one tails, and ``2'' takes
into account the fact that we can get this outcome in two
different orders.

This probability is essentially the likelihood.  We usually denote the
likelihood with $\likelihood(p)$, stressing that it depends on the
unknown probability $p$.  Hence in this example we have
\begin{equation}
  \label{eq:2-coin-likelihood}
  \likelihood(p) = 2 \, p \, (1-p).
\end{equation}
$p$ is the \emph{model parameter}, the unknown number we are computing
using the ML method.

Let's repeat here what did we do above:
\begin{enumerate}
\item First, we described the coin toss result as Bernoulli($p$)
  process.  In order to us ML method, we 
  need a probability model to describe our data.  $p$, the probability
  of heads, is the model parameter we want to
  calculate.  Bernoulli
  process has only a single parameter, but more complex processes can
  have many more.
\item We compute the likelihood based on data: in this example it was
  just a single heads, a single tails.
\item Thereafter we computed the probability to observe the data.
  This is why we have a suitable
  probability model.  As the model contains unknown
  parameters, the probability will also contain parameters.
\item And finally we just called this probability
  \emph{likelihood} $\likelihood(p)$ to
  stressed that it depends on the model parameter.  It also depends on
  data (the probability will look different for e.g. two heads) but we typically
  do not stress it in the notation.
\end{enumerate}

What is left is to use this likelihood function to \emph{estimate} the
parameters, to use
data to find out the best possible set of parameters.  \emph{Maximum
  likelihood} (ML) method finds such combination of parameters' values that
maximizes the likelihood function.  It can be shown that such combination
has number of desirable properties, in particular it will become
increasingly similar to the ``true value'' on an increasingly large
dataset, given that our probability model is correct.\footnote{This
  property is formally referred to as \emph{consistency}.  ML is a
  consistent estimator.}  These desirable
properties, and relative simplicity of the method, have made ML one of
the most widely used statistical estimators.

Let us now generalize the example we did above to an arbitrary number
of coin tosses.  Assume the coin is of unknown
``fairness'' where we just denote the probability to receive heads
with $p$.  Further, assume that out of $N$ trials, $N_{H}$ trials
turned out heads and $N_{T}$ trials turned tails.  The probability of
this occuring is
\begin{equation}
  \label{eq:general-cointoss-probability}
  \binom{N}{N_{H}} \, p^{N_{H}} \, (1 - p)^{N_{T}} =
  \likelihood(p; N_{H}, N_{T}).
\end{equation}
$p^{N_{H}}$ is the probability to get $N_{H}$ heads, $(1 - p)^{N_{T}}$ is
the probability to get $N_{T}$ tails, and
the binomial coefficient $\displaystyle\binom{N}{N_{H}} = \displaystyle\frac{N!}{N_{H}!(N -
  N_{H})!}$ takes into account that there are many ways how heads
and tail can turn up while still resulting in $N_{H}$ heads and
$N_{T}$ tails.  In the example above there were just two possible
combinations.  The probability depends on both the parameter $p$ and
data--the corresponding counts $N_{H}$ and $N_{T}$.  We stress this in
notation by writing $p$ in the first position followed by data, as our
prime interest is to compute $p$.

Technically, it is easier to work with log-likelihood instead of
likelihood (as log is monotonic function, maximum of likelihood and
maximum of log-likelihood occur at the same parameter value).
We denote log-likelihood by $\loglik$ and write
\begin{equation}
  \label{eq:general-cointoss-loglik}
  \loglik(p; N_{H}, N_{T}) =
  \log\likelihood(p; N_{H}, N_{T}) =
  \log \binom{N}{N_{H}} +
  N_{H} \log p + N_{T} \log (1 - p).
\end{equation}
ML estimation is to find the value of $p$ that maximizes this expression.
Fortunately, in this case
the binomial coefficient $\binom{N}{N_{H}}$ depends only on data but does not
depend on the parameter $p$.  Intuitively, $p$ determines the
probability of various combinations of heads and tails, but \emph{what
  kind of combinations are possible} does not depend on $p$.  Hence we
can ignore the first term on the right hand side
of~\eqref{eq:general-cointoss-loglik} when maximizing the
log-likelihood.  Such approach is very common in practice, many terms
that are invariant with respect to parameters are often ignored.
Hence, with we can re-define the
log-likelihood as
\begin{equation}
  \label{eq:general-cointoss-partial-loglik}
  \loglik(p; N_{H}, N_{T}) =
  N_{H} \log p + N_{T} \log (1 - p).
\end{equation}
It is easy to check that the solution, the value of $p$ that maximizes
log-likelihood~\eqref{eq:general-cointoss-partial-loglik}
is\footnote{Just differentiate $\loglik(p)$ with respect to $p$, set
  the result to zero, and isolate $p$.}
\begin{equation}
  \label{eq:general-cointoss-solution}
  p^{*} =
  \frac{N_{H}}{N}.
\end{equation}
This should be surprise to no-one--the intuitive 
``fairness'' of the coin is just the average percentage of heads we
get.

Now it is time to try this out on computer with \texttt{maxLik}.  Lets
assume we tossed the coin and received $H_{H} = 3$ heads and $H_{T} =
7$ tails:
<<>>=
NH <- 3
NT <- 7
@
Next, we have to define the log-likelihood function.  It has to be a
function of the parameter, and the parameter must be its first
argument.  We can access data in different ways, for instance through
the \R workspace environment.  So we can write the log-likelihood as
<<>>=
loglik <- function(p) {
   NH*log(p) + NT*log(1-p)
}
@ 
And finally, we can use \texttt{maxLik} to compute the likelihood.  In
its simplest form, \texttt{maxLik} requires two arguments: the
log-likelihood function, and the start value for the iterative
algorithm (see Section~\ref{sec:maxlik-usage} for more detailed
explanations).
The start value must be a valid parameter value (it must
not give errors).  We can choose $p_{0} = 0.5$ as the initial value,
and let the algorithm work to find the best possible $p$ from there:
<<>>=
library(maxLik)
m <- maxLik(loglik, start=0.5)
summary(m)
@
As expected, the best bet for $p$ is 0.3 in this case.  Our intuitive
approach--just percentage of heads in the experiment--turns also out
to be the ML estimate.

Next, we look at an example with continuous outcomes--linear
regression.


\section{Continuous variables: probability density and likelihood}
\label{sec:continuous-outcomes}

In the example above we looked at a case where there were only a small
number of distinct possibilities (heads and tails).  Such cases are called discrete
random variables.  Discrete random variables are easy to
understand because we can actually compute the respective
probabilities, such as the probability to receive one heads and one
tails in our experiment.  Now we consider continuous random variables,
cases where the outcome can be any number in a certain interval.
Unfortunately we cannot compute probability of a single value for continuous
random variables.  Or more precisely--yes, we can, but it is always 0.
This may sound a little counter-intuitive but perhaps the
following example helps.  If you ask the computer to generate a single
random number between 0 and 1, you may get
\Sexpr{x <- runif(1); x}.  What
is the probability to get the same number again?  You can try, but you
never get it again.\footnote{As computers operate with finite
  precision, the actual chances to repeat any particular random number
  are positive, although small.  The exact answer depends on the
  numeric precision and the quality of random number generator.
}
But despite of probability to receive any such number is zero we
somehow still produced it in the first place.  Clearly, zero
probability does not mean the number (the event) was impossible.
However, if we want to receive a negative number from the same random
number generator, it will be impossible (because we it only generates
numbers between 0 and 1).  So probability 0-events may be both
possible and impossible.  And to make matter worse, they may also be
more or less likely.  For instance, in case of 0-centered normal
random numbers (also known as the ``bell curve'') the
values near 0 are much more likely than values around 3, despite of
the probability to receive any particular number still being 0.

The solution is to look not at the probabilities of individual numbers
but numbers in a narrow interval near these numbers.  Consider
the number of interest $x$, and compute the
probability that the random value $X$ falls into the narrow  width
$\delta$ interval
$[x - \delta/2,\, x + \delta/2]$ around this
number.  Obviously, the smaller the width $\delta$, the less likely
$X$ falls into this narrow interval.  But it turns out that when we
divide the probability by the width, we get a stable value at the
limit
\begin{equation}
  \label{eq:probability-density}
  f(x) =
  \lim_{\delta\to0}
  \frac{\Pr(X \in [x - \delta/2,\, x + \delta/2])}{\delta}.
\end{equation}
The result, $f(x)$, is called \emph{probability density function},
often abbreviated as pdf.  In
case of continuous random variables, we have to work with pdf-s
instead of probabilities.

% Do the figure here ....

Consider the following somewhat trivial example: we have sampled two
independent datapoints, 
$x_{1}$ and $x_{2}$, from a normally distributed random variable with
variance 1 and mean (expected value) equal to $\mu$.  Assume we don't
know the latter value and let's use ML approach to estimate it.  We
proceed in a similar steps as what we did for discrete random
variables:
\begin{enumerate*}[label=\roman*)]
\item derive the probability model;
\item use the model to compute likelihood based on data;
\item compute probability to observe this data;
\item and write it as likelihood of the parameter.
  % we don't need 4 steps, do we? ....
\end{enumerate*}
Here the unknown parameter is $\mu$ and we want to derive the
likelihood function $\likelihood(\mu)$ in a way that maximizing it
would give us the best estimate of $\mu$.

We start with the probability model.
The pdf for unit-variance normal distribution is
\begin{equation}
  \label{eq:standard-normal-pdf}
  f(x; \mu) =
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x - \mu)^{2}
  }.
\end{equation}
We write it as $f(x; \mu)$ as pdf is usually written as a function of
data but as our primary interest is $\mu$, we also add this as an
argument.  Now by using this pdf we can find from~\eqref{eq:probability-density}
the probability that we observe a datapoint in the narrow
interval around $x$, this is just $f(x; \mu)\cdot \delta$.  As $x_{1}$
and $x_{2}$ are independent, we can just multiply the corresponding
probabilities to find the probability that both random numbers are
near their corresponding values:
\begin{multline}
  \label{eq:two-normal-probability-likelihood}
  \Pr{\big(X_{1} \in [x_{1} - \delta/2, x + \delta/2]
    \quad\text{and}\quad
    X_{2} \in [x_{2} - \delta/2, x + \delta/2]\big)}
  =\\[2ex]=
  \underbrace{
    \frac{1}{\sqrt{2\pi}}
    \,
    \me^{
      \displaystyle
      -\frac{1}{2}
      (x_{1} - \mu)^{2}
    } \cdot\delta\
  }_{
    \text{First random value near $x_{1}$}
  }
  \times
  \underbrace{
    \frac{1}{\sqrt{2\pi}}
    \,
    \me^{
      \displaystyle
      -\frac{1}{2}
      (x_{2} - \mu)^{2}
    } \cdot\delta
  }_{
    \text{Second random value near $x_{2}$}
  }
  \equiv\\[2ex]\equiv
  \likelihood^{*}(\mu; x_{1}, x_{2})
\end{multline}
where the interval width $\delta$ must be small for the equation to
hold precisely.  We denote this probability with $\likelihood^{*}$ to
stress that it is essentially the likelihood, just not written in the
way it is usually done.  As in the coin-toss example above, we write
it as a function of the parameter $\mu$, and put data $x_{1}$ and
$x_{2}$ after
semicolon.  Based on data, we can compute maximum-likelihood estimator
for $\mu$ by just finding such a $\mu$ value that maximizes the
expression. 

But note that $\delta$ plays no role in maximizing the likelihood.  It
is just a multiplicative factor, and because it is a width, it must be
positive.  So for our maximization problem we can just ignore it.
This is what is normally done when working with continuous variables,
and hence we can write the likelihood as
\begin{equation}
  \label{eq:two-normal-likelihood}
  \likelihood(\mu; x_{1}, x_{2})
  =
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{1} - \mu)^{2}
  }
  \times
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{2} - \mu)^{2}
  }.
\end{equation}
We denote this by $\likelihood$ instead of $\likelihood^{*}$ to stress
that this is how likelihood function for continuous random variables
is usually constructed.

Exactly as in the case of discrete random variables, it is better to use
log-likelihood instead of likelihood to actually compute the maximum.
From~\eqref{eq:two-normal-likelihood} we get log-likelihood as
\begin{multline}
  \label{eq:two-standard-normal-loglik}
  \loglik(\mu; x_{1}, x_{2})
  =
  -\log{\sqrt{2\pi}}
  -\frac{1}{2}
  (x_{1} - \mu)^{2}
  +
  (- \log{\sqrt{2\pi}})
  -\frac{1}{2}
  (x_{2} - \mu)^{2}
  =\\[2ex]=
  - 2\log{\sqrt{2\pi}}
  - \frac{1}{2}
  \sum_{i=1}^{2} (x_{i} - \mu)^{2}.
\end{multline}
The first term, $- 2\log{\sqrt{2\pi}}$, is just an additive constant
and plays no role in the
actual maximization but it is typically included when defining the
likelihood function.\footnote{While additive or multiplicative
  constants do not play any role for optimization, they play an
  important role when comparing different log-likelihood values.  This
  is necessary for likelihood-based tests.
}
The $1/2$ is a positive factor that does not
play any role either.  When we remove these two terms, what is left is
$-\sum_{i}(x_{i} - \mu)^{2}$.  So we end up maximizing negative of sum
of squared errors, equivalent to minimizing the positive sum of squared errors.
Maximum likelihood method is equivalent to least squares in case of
normally distributed random variables. 

One can easily check by differentiating the log-likelihood function
that the maximum of log-likelihood is achieved when $\mu =
\frac{1}{2}(x_{1} + x_{2})$.  It is not surprising, our intuitive
understanding of the mean value carries immediately over to the normal
distribution context.

Now it is time to demonstrate these results with \texttt{maxLik}
package.  First, create our ``data'', just two normally distributed
random numbers:
<<>>=
x1 <- rnorm(1)  # centered around 0
x2 <- rnorm(1)
x1
x2
@
and define the log-likelihood function.  We include all the terms as in
in~\eqref{eq:two-standard-normal-loglik}:
<<>>=
loglik <- function(mu) {
   -2*log(sqrt(2*pi)) - 0.5*((x1 - mu)^2 + (x2 - mu)^2)
}
@
We also need the parameter start value--we can pick $0$.  And we use
\texttt{maxLik} to find the best $\mu$:
<<>>=
m <- maxLik(loglik, start=0)
summary(m)
@
It is easy to check that the answer is the same as sample mean:
<<>>=
(x1 + x2)/2
@ 


\section{Vector arguments}
\label{sec:vector-arguments}

The previous example is instructive but it does have very few practical
applications.  The problem is that we wrote the probability model
as standard normal density with unknown location $\mu$.  However, in
practice we hardly ever know that we are dealing with standard normal.
More likely both location and scale $\sigma$ are
unknown.
(In case of normal distribution, scale $\sigma$ is equal to the
standard deviation and $\sigma^{2}$ to the variance.)
So in order to make the previous example applicable, we need
to incorporate the unknown scale into the model.

The more general normal density function with standard deviation $\sigma$ is
\begin{equation}
  \label{eq:normal-pdf}
  f(x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi}}
  \frac{1}{\sigma}
  \,
  \me^{
    -\frac{1}{2}
    \frac{(x - \mu)^{2}}{\sigma^{2}}
  }.
\end{equation}
Similar argumentation as what we did above will give the
log-likelihood
\begin{equation}
  \label{eq:two-normal-loglik}
  \loglik(\mu, \sigma; x_{1}, x_{2})
  =
  - 2\log{\sqrt{2\pi}}
  - 2\log \sigma
  - \frac{1}{2}
  \sum_{i=1}^{2} \frac{(x_{i} - \mu)^{2}}{\sigma^{2}}.
\end{equation}
We write the log-likelihood as function of both parameters, $\mu$ and
$\sigma$; $x_{1}$ and $x_{2}$ after semicolon show that though it
depends on data too, we are not much interested in that dependency for
now.  This formula immediately extends to the case of $N$ datapoints
as 
\begin{equation}
  \label{eq:normal-loglik}
  \loglik(\mu, \sigma)
  =
  - N\log{\sqrt{2\pi}}
  - N\log \sigma
  - \frac{1}{2}
  \sum_{i=1}^{N} \frac{(x_{i} - \mu)^{2}}{\sigma^{2}}
\end{equation}
where we have dropped the dependency on data in the notation.
In this case we can actually do the optimization analytically, and
derive the well-known intuitive results: the best estimator for location $\mu$ is
the sample mean, and for variance $\sigma^{2}$ it is the sample variance.

However, in general the expression does not allow for analytic
solution.  In this case we need to use a numeric optimization
algorithm that searches for the best $\mu$ and $\sigma$ combination.
The common multi-dimensional optimizers rely on linear algebra and
want all the parameters submitted as a single vector.  So we can write
the log-likelihood as
\begin{equation}
  \label{eq:normal-loglik-vector}
  \loglik(\vec{\theta})
  \quad\text{where}\quad
  \vec{\theta} = (\mu, \sigma).
\end{equation}
Here we denote both parameters $\mu$ and $\sigma$ as components of a
single parameter vector $\vec{\theta}$.  We have also
dropped dependency on data in the notation but
remember that in practical applications log-likelihood will always
depend on data.  This notation can be converted to computer code almost
verbatim, just remember to extract the parameters $\mu$ and $\sigma$
from $\vec{\theta}$ inside of the log-likelihood function.

Let us do an example using the \emph{CO2} dataset (in package
\emph{datasets}).  
It describes \COii uptake (variable \emph{uptake}) by different
grasses in various conditions.  Let us start by plotting the histogram
of uptake:
<<fig=TRUE>>=
data(CO2)
hist(CO2$uptake,
     xlab=expression(paste("uptake, ", mu*mol/(m^2 %.% sec))))
@

Let us model the uptake as a normal
random variable with expected value $\mu$ and standard deviation
$\sigma$.  We code~\eqref{eq:normal-loglik} while keeping both
parameters in a single vector as in~\eqref{eq:normal-loglik-vector}:
<<>>=
loglik <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   N <- nrow(CO2)
   -N*log(sqrt(2*pi)) - N*log(sigma) -
      0.5*sum((CO2$uptake - mu)^2/sigma^2)
}
@
The function is similar to the one used in
Section~\ref{sec:continuous-outcomes}.  There are just two main
differences:
\begin{itemize}
\item both arguments, $\mu$ and $\sigma$ are passed to it as
  components of $\vec{\theta}$, and hence the function starts its work
  by unpacking the values.
\item instead of using variables \texttt{x1} and \texttt{x2} as
  previously, we now extract data directly from the data frame.
\end{itemize}
The other logic though is similar.  As our parameter vector now
contains two components, the start vector must also be of length two.
Based on the figure we guess that a good starting value would be
$\mu=30$ and $\sigma=10$:
<<>>=
m <- maxLik(loglik, start=c(mu=30, sigma=10))
summary(m)
@ 
Indeed, the results are close.


\section{Final Example: Linear Regression}
\label{sec:linear-regression}

Now when we have the main tools in place, it is rather easy to extend
the example above to a real statistical model.
Let us extend the previous example into a linear regression.
We describe \COii uptake (variable \emph{uptake}) by 
different \COii concentration (variable \emph{conc}) in air.  We can
describe the corresponding regression model as
\begin{equation}
  \label{eq:co2-regression}
  \mathit{uptake}_{i} = \beta_{0} +
  \beta_{1} \cdot \mathit{conc}_{i} +
  \epsilon_{i}.
\end{equation}
In order to turn this regression model into a maximum likelihood
problem, we again need a parametric probability model.  Assume that
the disturbance term $\epsilon$ is normally distributed with mean 0
and (unknown) variance $\sigma^{2}$ (this is a standard assumption in
linear regression).  Now we can
follow~\eqref{eq:normal-loglik} and write for a single observation
\begin{equation}
  \label{eq:co2-epsilon-loglik}
  \loglik(\sigma; \epsilon_{i})
  =
  - \log{\sqrt{2\pi}}
  - \log \sigma
  - \frac{1}{2}
  \frac{\epsilon_{i}^{2}}{\sigma^{2}}.
\end{equation}
Note that as the expected value $\mu=0$ by assumption, we do not have
$\mu$ in~\eqref{eq:co2-epsilon-loglik} and hence we drop it also from
the $\loglik$ argument list.
Next, we can express $\epsilon_{i}$ from~\eqref{eq:co2-regression}:
\begin{equation}
  \label{eq:co2-epsilon}
  \epsilon_{i} =
  \mathit{uptake}_{i} - \beta_{0} -
  \beta_{1} \cdot \mathit{conc}_{i}
\end{equation}
and plug this into~\eqref{eq:co2-epsilon-loglik}:
\begin{multline}
  \label{eq:co2-single-loglik}
  \loglik(\beta_{0}, \beta_{1}, \sigma; \mathit{uptake}_{i}, \mathit{conc}_{i})
  =\\=
  - \log{\sqrt{2\pi}}
  - \log \sigma
  - \frac{1}{2}
  \frac{(
    \mathit{uptake}_{i} - \beta_{0} -
    \beta_{1} \cdot \mathit{conc}_{i}
    - \mu)^{2}}{\sigma^{2}}.
\end{multline}
We have designed log-likelihood formula for a single linear regression
observation.  For $N$ observations we have
\begin{multline}
  \label{eq:co2-loglik}
  \loglik(\beta_{0}, \beta_{1}, \sigma; \vec{\mathit{uptake}}, \vec{\mathit{conc}})
  =\\=
  - N\log{\sqrt{2\pi}}
  - N\log \sigma
  - \frac{1}{2}
  \sum_{i=1}^{N}
  \frac{(
    \mathit{uptake}_{i} - \beta_{0} -
    \beta_{1} \cdot \mathit{conc}_{i}
    - \mu)^{2}}{\sigma^{2}}.
\end{multline}
This is a fully specified log-likelihood function we can use for
optimization.  Let us repeat what we have done:
\begin{itemize}
\item We write the log-likelihood as a function of parameters
  $\beta_{0}$, $\beta_{1}$ and $\sigma$.  Note that in ordinary
  regression model we do not call $\sigma$ a parameter.  But it is
  still a parameter, although one we usually do not care much about
  (sometimes
  called ``nuisance parameter'').  We will denote all parameters
  $\vec{\theta}$ later.
\item The likelihood function also depends on data, here of the
  vectors $\vec{\mathit{uptake}}$ and  $\vec{\mathit{conc}}$.
\item The function definition itself is just sum of log-likelihood
  contributions of individual normal disturbance terms, but as we do
  not observe the disturbance terms
  directly, we express those through the regression
  equation in~\eqref{eq:co2-single-loglik}.
\end{itemize}
Finally, we also wrap the three parameters into a single vector
$\vec{\theta}$ and write
\begin{equation}
  \label{eq:co2-loglik-simplified}
  \loglik(\vec{\theta})
  =
  - N\log{\sqrt{2\pi}}
  - N\log \sigma
  - \frac{1}{2}
  \sum_{i=1}^{N}
  \frac{(
    \mathit{uptake}_{i} - \beta_{0} -
    \beta_{1} \cdot \mathit{conc}_{i}
    - \mu)^{2}}{\sigma^{2}}.
\end{equation}
This is the definition we can easily code and estimate.  We guess
start values $\beta_{0} = 30$ (close to the mean), $\beta_{1} = 0$
(uptake does not depend on concentration) and $\sigma=10$ (close to
sample standard deviation).  The results are
<<>>=
loglik <- function(theta) {
   beta0 <- theta[1]
   beta1 <- theta[2]
   sigma <- theta[3]
   N <- nrow(CO2)
   # compute new mu based on beta1, beta2
   mu <- beta0 + beta1*CO2$conc
   # use this mu in a similar fashion as previously
   -N*log(sqrt(2*pi)) - N*log(sigma) -
      0.5*sum((CO2$uptake - mu)^2/sigma^2)
}
m <- maxLik(loglik, start=c(beta0=30, beta1=0, sigma=10))
summary(m)
@ 
One can check that a linear regression model will give similar
results:
<<>>=
summary(lm(uptake ~ conc, data=CO2))
@ 
Indeed, the results are close although not identical.


\section{Non-linear optimization}
\label{sec:non-linear-optimization}

Finally, we discuss the magic inside \texttt{maxLik} that finds the
optimal parameter values.  Although not necessary in everyday work,
this knowledge helps a lot to understand the types of issues and
potential solutions when doing non-linear optimization.
So how does the optimization work?

Consider the example in Section~\ref{sec:vector-arguments}
where we computed the normal distribution parameters for \COii
intake.  There were two parameters, $\mu$ and $\sigma$, and the
maximum likelihood procedure returns such a combination that gives the
largest possible log-likelihood value.
We can visualize the task by plotting the log-likelihood value for
different combinations of $\mu$, $\sigma$
(Figure~\ref{fig:mu-sigma-plot}).

\begin{figure}[ht]
  \centering
<<echo=FALSE, fig=TRUE>>=
loglik <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   N <- nrow(CO2)
   -N*log(sqrt(2*pi)) - N*log(sigma) -
      0.5*sum((CO2$uptake - mu)^2/sigma^2)
}
m <- maxLik(loglik, start=c(mu=30, sigma=10))
params <- coef(m)
np <- 33
mu <- seq(6, 36, length.out=np)
sigma <- seq(5, 50, length.out=np)
X <- expand.grid(mu=mu, sigma=sigma) %>%
   as.matrix()
ll <- apply(X, 1, loglik) %>%
   matrix(nrow=33)
levels <- quantile(ll, c(0.05, 0.4, 0.6, 0.8, 0.9, 0.97))
                           # where to dwar the contours
colors <- colorRampPalette(c("Blue", "White"))(30)
par(mar=c(0,0,0,0),
    mgp=2:0)
## Perspective plot
persp3D(mu, sigma, ll, 
               xlab=expression(mu),
               ylab=expression(sigma),
               zlab=expression(log-likelihood),
               theta=40, phi=30,
               colkey=FALSE,
               col=colors, alpha=0.5, facets=TRUE,
               shade=1,
               lighting="ambient", lphi=60, ltheta=0,
               image=TRUE,
               bty="b2",
               contour=list(col="gray", side=c("z"), levels=levels)
               )
## add the dot for maximum
scatter3D(rep(coef(m)[1], 2), rep(coef(m)[2], 2), c(maxValue(m), min(ll)),
          col="red", pch=16, facets=FALSE,
          bty="n", add=TRUE)
## line from max on persp to max at bottom surface
segments3D(coef(m)[1], coef(m)[2], maxValue(m),
          coef(m)[1], coef(m)[2], min(ll),
          col="red", lty=2,
          bty="n", add=TRUE)
## contours for the bottom image
contour3D(mu, sigma, z=min(ll) + 0.1, colvar=ll, col="black",
          levels=levels,
          add=TRUE)
@
\caption{Log-likelihood surface as a function of $\mu$ and $\sigma$.
  The optimum, denoted as a red dot, is at
  $\mu=\Sexpr{round(coef(m)[1], 3)}$ and
  $\sigma=\Sexpr{round(coef(m)[2], 3)}$.  The corresponding countour
  plot is shows at the bottom.
}
\label{fig:mu-sigma-plot}
\end{figure}

So how does the algorithm find the optimal parameter value
$\vec{\theta}^*$, the red dot on the figure?
All the common methods are iterative, i.e. they
start with a given start value, and repeatedly find a new and better
parameter that gives larger
log-likelihood based on the previous iteration.  While humans look at
the figure, they can immediately see where is its maximum.  But
computers cannot visualize the image in this way.  And more
importantly--even humans cannot visualize the function in more than
three dimensions.  This visualization is so helpful for us because we
can intuitively understand the 3-dimensional surface.  It is 3-D
because we have two parameters, $\mu$ and $\sigma$, and a single
log-likelihood value.  Add one more parameter as we did in
Section~\ref{sec:linear-regression}, and visualization options are
very limited.  In case of 10 parameters, it is essentially impossible
to solve the problem by just visualizations.

It is like climbing uphill in whiteout
conditions where you cannot distinguish any details around you--sky is
just white fog and ground is just exactly similar white snow.  But you
can still feel which way the ground goes up and so you can still go
uphill.  This is what the popular algorithms do.  They rely on the slope of the
function, the gradient, and follow the direction suggested by gradient.
Most optimizers included in the \texttt{maxLik} package need
gradients, including the default Newton-Raphson method.  But how do we
know the gradient if the log-likelihood function only returns a single
value?  There are two ways:
\begin{enumerate*}[label=\roman*)]
\item provide a separate function that also computes gradient;
\item compute the log-likelihood value in multiple points nearby and
  deduce the gradient from that information.
\end{enumerate*}
The first option is superior, in high dimensions it is much faster and
much less error prone.  But computing and coding the gradient function
can easily take days of work.  The second approach, numeric gradient,
forces the computer to do more work more and hence it is slower.  More
importantly, it is also unreliable for more complex cases.  In
practice you can notice how the algorithm refuses to converge for
thousand of iterations.  But numeric gradient works very well, for
example, the algorithm we used to compute the mean and variance for 
normally distributed random variables in
Section~\ref{sec:vector-arguments}
converged in $\Sexpr{nIter(m)}$ iterations 


\bibliographystyle{apecon}
\bibliography{sga}

\end{document}
