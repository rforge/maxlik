\documentclass{article}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{xspace}

\newcommand{\elemProd}{\ensuremath{\odot}}  % elementwise product of matrices
\newcommand*{\mat}[1]{\mathsf{#1}}
\newcommand{\likelihood}{\mathcal{L}}% likelihood
\newcommand{\loglik}{\ell}% log likelihood
\newcommand{\maxlik}{\texttt{maxLik}\xspace}
\newcommand{\me}{\mathrm{e}} % Konstant e=2,71828
\newcommand*{\transpose}{^{\mkern-1.5mu\mathsf{T}}}
%\newcommand{\transpose}{\intercal}
\renewcommand*{\vec}[1]{\boldsymbol{#1}}

% \VignetteIndexEntry{SGA introduction: the basic usage of maxSGA}

\begin{document}
<<foo,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60,
        try.outFile=stdout()  # make try to produce error messages
        )
foo <- packageDescription("maxLik")
library(ggplot2)
library(magrittr)
@

\title{Getting started with maximum likelihood and \texttt{maxLik}}
\author{Ott Toomet}
\maketitle


\section{Introduction}

This vignette is intended for those who are rather new for both
maximum likelihood (ML) estimation and the \texttt{maxLik} package.
The potential target group contains advanced undergraduate students in
technical fields, such as statistics or economics, graduate students
in social sciences or engineering who have to devise their own
estimators, and research stuff and practitioners who are just moving
into ML tasks.  If you are familiar enough with the concept of ML, you
may
skip the theoretical introduction and go straight to the
Section~\ref{sec:maxlik-usage} for \texttt{maxLik} usage.


\section{What is maximum likelihood estimation?}
\label{sec:what-is-ml}

Maximum Likelihood (ML) is in essence of maximizing \emph{likelihood}
over the parameters of interest.  This section explains what is
likelihood and how is it related to probability.  We start by
introducing two important concepts for probability distributions,
probability mass function and probability density function.
Thereafter we explain how one transforms probabilities to likelihood,
and what are the parameters there.  Finally, we also incorporate data
as most common ML applications are based on data.


\subsection{Probability mass function and probability density
  function}
\label{sec:pmf-pdf}

We start with a very simple example.  Imagine you are tossing a fair
coin.  What are the possible outcomes and what are the related
probabilities?  Obviously, in case of a coin there are only two
outcomes, heads $H$ and tails $T$.  If the coin is fair, both of these
will have probability exactly 0.5.  We can denote tails with 0, heads
with 1, and make a plot of the result
(Figure~\ref{fig:fair-coin-pmf}).

\begin{figure}[ht]
  \begin{center}
<<fig=TRUE, echo=FALSE, height=3.2>>=
N <- 1
p <- 0.5
data.frame(n=0:N, p=dbinom(0:N, N, p)) %>%
   ggplot(aes(n, p)) +
   geom_segment(aes(xend=n, yend=0), size=1) +
   geom_point(size=2) +
   labs(x = "Number of heads", y = "Probability") +
   scale_x_continuous(breaks=0:1, labels=0:1,
                      limits=c(-0.2, 1.2))
@   
\end{center}
\caption{Probability mass function for a fair coin toss}
\label{fig:fair-coin-pmf}
\end{figure}

The plot shows the probabilities for all possible events for our coin
toss example.  This is called \emph{probability mass function} (pmf).
Pmf just tells you the probability for every possible event.  Our coin toss
has only two possible events, tails (0) and heads (1), and hence its pmf
only has two points of support.  Such process is called \emph{Bernoulli
  process}.  More specifically, this is \emph{Bernoulli(0.5)} process
as for the fair coin the probability of ``success'' (i.e. heads) is
0.5.  If the coin is not fair, we denote the corresponding process
Bernoulli($p$), where $p$ is the probability to get heads.

Now lets toss the coin two times.  What is the probability that we end
up with one heads and one tails?  First, as the coin tosses are
independent,\footnote{Events are independent when outcome of one event
  does not influence the outcome of the other event.  Here the result
  of the second toss is not affected by the first toss.}
we can just multiply the probabilities: $0.5$ for one heads and $0.5$
for one tails, $0.25$ when multiplied.  However, this is not the whole
story--we have two possibilities to get one heads and one tails,
either $H$, $T$ or $T$, $H$.  Both of these events are equally likely,
so the final answer will be 0.5.

But now imagine we do not know if the coin is fair.  Maybe it is not a
coin but and object of complex shape instead.  How can we tell if it
is fair or not?  We can repeat the exercise what we did with two
coins.  But as we don't know the true probability of heads, lets
denote it with $p$.  The probability of tails will be $1-p$
accordingly, and the probability of tossing the coin two times will be
$2 p (1-p)$, $p$ for one heads, $1-p$ for one tails, and ``2'' takes
into account the fact that we can get one tails, one heads in two
possible orders.

This probability is essentially the likelihood.  We usually denote the
likelihood with $\likelihood(p)$, stressing that it depends on the
model parameter $p$.  Hence in this example we have
\begin{equation}
  \label{eq:2-coin-likelihood}
  \likelihood(p) = 2 \, p \, (1-p).
\end{equation}
Let's repeat here what did we do above:
\begin{enumerate}
\item First, we described the coin toss result as Bernoulli($p$)
  process.  In order to apply maximum likelihood method, we always
  need a probability model to describe our data.  $p$, the probability
  of heads, is the model parameter we typically don't know.  Bernoulli
  process has only a single parameter, but more complex processes can
  have many more.
\item Thereafter we computed the probability to observe the data--one
  heads, one tails.
  This is only possible if we have a suitable
  probability model.  As the model contains (usually unknown)
  parameters, the probability will also contain parameters.
\item And finally we just called this probability
  \emph{likelihood} $\likelihood(p)$ to
  stressed that it depends on the model parameter.
\end{enumerate}

What is left is to use this likelihood function to \emph{estimate} the
parameters.  These are normally unknown, and we want to use
data to find out the best possible set of parameters.  \emph{Maximum
  likelihood} (ML) method finds such combination of parameters' values that
maximizes the likelihood function.  It can be shown that such value
has number of desirable properties, in particular it will become
increasingly similar to the ``true value'' on increasingly large
dataset, given that our probability model is correct (it is a
consistent estimator).  These desirable
properties, and relative simplicity of the method, have made ML one of
the most widely used statistical estimators.

Let us now generalize the example we did above, and convert it into a
form suitable for ML estimation.  Assume we toss a coin of unknown
``fairness'' where we just denote the probability to receive heads
with $p$.  Further, assume that out of $N$ trials, $N_{H}$ trials
turned out heads and $N_{T}$ trials turned tails.  The probability of
this occuring is
\begin{equation}
  \label{eq:general-cointoss-probability}
  \binom{N}{N_{H}} \, p^{N_{H}} \, (1 - p)^{N_{T}} =
  \likelihood(p; N_{H}, N_{T})
\end{equation}
The binomial coefficient $\displaystyle\binom{N}{N_{H}} = \displaystyle\frac{N!}{N_{H}!(N -
  N_{H})!}$ takes into account that there are many ways to how heads
and tail can turn up while still resulting in $N_{H}$ heads and
$H_{T}$ tails, in the example above there were just two possible
combinations.  The probability depends on both the parameter $p$ and
data--the corresponding counts $N_{H}$ and $N_{T}$.  We stress this in
notation by writing $p$ in the first position followed by data. 

Technically, it is easier to work with log-likelihood instead of
likelihood (as log is monotonic function, maximum of likelihood and
maximum of log-likelihood occur at the same parameter value).
We denote log-likelihood by $\loglik$ and write
\begin{equation}
  \label{eq:general-cointoss-loglik}
  \loglik(p; N_{H}, N_{T}) =
  \log\likelihood(p; N_{H}, N_{T}) =
  \log \binom{N}{N_{H}} +
  N_{H} \log p + N_{T} \log (1 - p).
\end{equation}
ML method means finding value of $p$ that maximizes this expression.
Fortunately, the binomial coefficient $\binom{N}{N_{H}}$ does not
depend on the parameter $p$.  Intuitively, $p$ determines the
probability of various combinations of heads and tails, but \emph{what
  kind of combinations are possible} does not depend on $p$.  Hence we
can ignore the first term on the right hand side
of~\eqref{eq:general-cointoss-loglik} when maximizing the
log-likelihood.  Such approach is very common in practice, many terms
that are invariant with respect to parameters are often ignored.
Hence, with certain abuse of notation we can rewrite the
log-likelihood as
\begin{equation}
  \label{eq:general-cointoss-partial-loglik}
  \loglik(p; N_{H}, N_{T}) =
  N_{H} \log p + N_{T} \log (1 - p).
\end{equation}
It is easy to check that the solution, the value of $p$ that maximizes
log-likelihood~\eqref{eq:general-cointoss-partial-loglik} is
\begin{equation}
  \label{eq:general-cointoss-solution}
  p^{*} =
  \frac{N_{H}}{N}.
\end{equation}
This should be surprise to no-one--the intuitive 
``fairness'' of the coin is just the average percentage of heads we
get.


\subsection{Doing all this with maxlik}
\label{sec:doing-this-with-maxlik}

TBD



Next, we look at an example with continuous outcomes--linear
regression.

\subsection{Continuous variables: probability density and likelihood}
\label{sec:continuous-outcomes}

In the example above we looked at a case where there were only a small
number of distinct possibilities (heads and tails).  These are called discrete
random variables.  What makes discrete random variables easy to
understand is the fact that we can actually compute the respective
probabilities, such as the probability to receive one heads, one tails
in case of two coin toss.  But we cannot do this with continuous
random variables--probability to receive any particular number is
zero.  This may sound a little counter-intuitive but perhaps the
following example helps.  If we ask the computer to produce a single
random number, uniformly distributed between 0 and 1, we may get
\Sexpr{x <- runif(1); x}.  What
is the probability to get the same number again?  You can try, but you
never get it again.\footnote{As computers operate with finite
  precision, the actual chances to repeat any particular random number
  are positive, although small.  The exact answer depends on the
  numeric precision and the quality of random number generator.
}
But despite of probability to receive any such number is zero we
somehow still produced it in the first place.  Clearly, zero
probability does not mean the number (the event) was impossible.
However, if we want to receive a negative number from the same random
number generator (RNG), it will be impossible (because we ask for
numbers between 0 and 1).  So probability 0-events may be both
possible and impossible.  And to make matter worse, they may also be
more or less likely, e.g. in case of standard normal random numbers the
values near 0 are much more likely than around 3, despite of
the probability to receive any particular number still being 0.

The solution is to look not at the probabilities of particular numbers
but numbers in a narrow interval near these numbers.  This is how the
concept of probability density is defined.  We look at
the number of interest $x$, and compute the
probability that the random value $X$ falls into the narrow interval
of width $\delta$, $[a - \delta/2, a + \delta/2]$, around this
number.  Obviously, the smaller the width $\delta$, the less likely
$X$ falls into this narrow interval.  But it turns out that when we
divide the probability by the width, we get a stable value at the
limit
\begin{equation}
  \label{eq:probability-density}
  f(x) =
  \lim_{\delta\to0}
  \frac{\Pr(X \in [x - \delta/2, x + \delta/2])}{\delta}.
\end{equation}
The result, $f(x)$, is called \emph{probability density function}, or pdf.  In
case of continuous random variables, we have to work with pdf-s
instead.

Consider the following somewhat trivial example: we have sampled two
independent datapoints, 
$x_{1}$ and $x_{2}$, from a normally distributed random variable with
variance 1 and mean (expected value) equal to $\mu$.  The latter is
a parameter, in a similar fashion as $p$ was the parameter of the
probability of heads in the coin toss example.
The pdf for unit-variance normal distribution is
\begin{equation}
  \label{eq:normal-pdf}
  f(x; \mu) =
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x - \mu)^{2}
  }
\end{equation}
and hence from~\eqref{eq:probability-density}
the probability that we observe a datapoint in the narrow
interval around $x$ is $f(x; \mu)\cdot \delta$.  As these two
probabilities are independent, we can just multiply the corresponding
probabilities to find the probability that both random numbers are
near their corresponding values:
\begin{multline}
  \label{eq:two-normal-probability-likelihood}
  \Pr{\big(X_{1} \in [x_{1} - \delta/2, x + \delta/2]
    \quad\text{and}\quad
    X_{2} \in [x_{2} - \delta/2, x + \delta/2]\big)}
  =\\=
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{1} - \mu)^{2}
  } \cdot\delta
  \times
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{2} - \mu)^{2}
  } \cdot\delta
  \equiv\\\equiv
  \likelihood^{*}(\mu; x_{1}, x_{2})
\end{multline}
where the interval width $\delta$ must be small for the equation to
hold correctly.  We denote this probability with $\likelihood^{*}$ to
stress that it is essentially a likelihood, just not written in the
way it is usually done.  As in the coin-toss example above, we write
it as a function of the parameter $\mu$, and put data $x_{1}$ and
$x_{2}$ after
semicolon.  Based on data, we can compute maximum-likelihood estimator
for $\mu$ by just finding such a $\mu$ value that maximizes the
expression. 

But note that $\delta$ plays no role in maximizing the likelihood.  It
is just a multiplicative factor, as the interval width it also must be
positive.  So for our maximization problem we can just ignore it.
This is what is normally done when working with continuous variables,
and hence we can write the likelihood as
\begin{equation}
  \label{eq:two-normal-likelihood}
  \likelihood(\mu; x_{1}, x_{2})
  =
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{1} - \mu)^{2}
  }
  \times
  \frac{1}{\sqrt{2\pi}}
  \,
  \me^{
    \displaystyle
    -\frac{1}{2}
    (x_{2} - \mu)^{2}
  }.
\end{equation}
We denote this by $\likelihood$ instead of $\likelihood^{*}$ to stress
that this is how likelihood function for continuous random variables
is usually constructed.

Exactly as in case with discrete variables, it is better to use
log-likelihood instead of likelihood to actually compute the maximum.
The log-likelihood of~\eqref{eq:two-normal-likelihood} is
\begin{multline}
  \label{eq:two-normal-loglik}
  \loglik(\mu; x_{1}, x_{2})
  =
  -\log{\sqrt{2\pi}}
  -\frac{1}{2}
  (x_{1} - \mu)^{2}
  +
  (- \log{\sqrt{2\pi}})
  -\frac{1}{2}
  (x_{2} - \mu)^{2}
  =\\=
  - 2\log{\sqrt{2\pi}}
  - \frac{1}{2}
  \sum_{i} (x_{i} - \mu)^{2}.
\end{multline}
The first term, $- 2\log{\sqrt{2\pi}}$, is just an additive constant
and plays no role in the
actual maximization but it is anyway typically used when defining the
likelihood function.  The $1/2$ is a positive factor that does not
play any role either.  When we remove these two terms, what is left is
$-\sum_{i}(x_{i} - \mu)^{2}$.  So we end up maximizing negative of sum
of squared errors, equivalent to minimizing the positive sum of squared errors.
Maximum likelihood method is equivalent to least squares in case of
normally distributed random variables. 

One can easily check by differentiating the log-likelihood function,
that the maximum of log-likelihood is achieved when $\mu =
\frac{1}{2}(x_{1} + x_{2})$.  It is not surprising, our intuitive
understanding of the mean value carries immediately over to the normal
distribution context.



\subsection{Vector arguments}
\label{sec:from-probability-likelihood}


Vector arguments: put the $\mu$, $\sigma$ into the same vector


\subsection{Non-linear optimization}
\label{sec:non-linear-optimization}

Why do we need it, and why we do the stuff in vector form

What are the issues in high dimensions

Why gradients are needed



\section{How to use maxLik}
\label{sec:maxlik-usage}


\subsection{Basic usage}
\label{sec:basic-usage}

maxLik function

summary, coef, stdEr

vector arguments

select optimizers

BHHH

providing analytic derivatives

\subsection{Advanced usage}
\label{sec:advanced-usage}

condiNumber, compareDerivatives

fixed coefficients

mention SGA

\bibliographystyle{apecon}
\bibliography{sga}

\end{document}
