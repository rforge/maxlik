\documentclass{article}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage[inline]{enumitem}
\usepackage[T1]{fontenc}
\usepackage[bookmarks=TRUE,
            colorlinks,
            pdfpagemode=none,
            pdfstartview=FitH,
            citecolor=black,
            filecolor=black,
            linkcolor=blue,
            urlcolor=black,
            ]{hyperref}
\usepackage{graphicx}
\usepackage{icomma}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}  % for extended pderiv arguments
\usepackage{natbib}
\usepackage{xargs}  % for extended pderiv arguments
\usepackage{xspace}

\newcommand{\COii}{\ensuremath{\mathit{CO}_{2}}\xspace}
\DeclareMathOperator*{\E}{\mathbbm{E}}% expectation
\newcommand*{\mat}[1]{\mathsf{#1}}
\newcommand{\likelihood}{\mathcal{L}}% likelihood
\newcommand{\loglik}{\ell}% log likelihood
\newcommand{\maxlik}{\texttt{maxLik}\xspace}
\newcommand{\me}{\mathrm{e}} % Konstant e=2,71828
\newcommandx{\pderiv}[3][1={}, 2={}]{\frac{\partial^{#2}{#1}}{\mathmbox{\partial{#3}}^{#2}}}
% #1: function to differentiate (optional, empty = write after the formula)
% #2: the order of differentiation (optional, empty=1)
% #3: the variable to differentiate wrt (mandatory)
\newcommand{\R}{\texttt{R}\xspace}
\newcommand*{\transpose}{^{\mkern-1.5mu\mathsf{T}}}
\renewcommand*{\vec}[1]{\boldsymbol{#1}}
% \VignetteIndexEntry{Maximum likelihood estimation with maxLik}

\title{Maximum Likelihood Estimation with \emph{maxLik}}
\author{Ott Toomet}

\begin{document}
\maketitle

<<echo=FALSE>>=
library(maxLik)
set.seed(6)
@ 

\section{Introduction}
\label{sec:introduction}

This document is intended for users who are well familiar with
concepts of likelihood, log-likelihood, and related methods, such as
information equality and BHHH approximation, and with \R language.  It only
introduces how to use \maxlik.  Potential target group
includes researchers, graduate students, and industry practitioners.

\section{Basic usage}
\label{sec:basic-usage}

\subsection{The maxLik function}
\label{sec:maxlik-function}

The main entry point to the \maxlik functionality is the function of
the same name, \verb|maxLik|.  It is a wrapper around the underlying
optimization algorithms that also sets the classes right, so that one
can use the convenience functions, such as \verb|summary| or
\verb|logLik| on the returned object.

The basic usage of the function is very simple: one has just to submit
the likelihood function (argument \verb|logLik|) and start value
(argument \verb|start|).  Let us demonstrate the basic usage
with ML estimation
of normal distribution parameters.  We create 100 standard normals,
and estimate the sample mean and standard deviation.  For a refresher,
the normal probability density function is
\begin{equation}
  \label{eq:normal-pdf}
  f(x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi}}
  \frac{1}{\sigma}
  \,
  \me^{
    -\frac{1}{2}
    \frac{(x - \mu)^{2}}{\sigma^{2}}
  }.
\end{equation}
and hence the log-likelihood contribution of $x$ is
\begin{equation}
  \label{eq:normal-loglik}
  \loglik(\mu, \sigma; x)
  =
  - \log{\sqrt{2\pi}}
  - \log \sigma
  - \frac{1}{2} \frac{(x - \mu)^{2}}{\sigma^{2}}.
\end{equation}
Instead of explicitly coding our own version, we can instead rely on
\R function \verb|dnorm|:
<<>>=
x <- rnorm(100)  # data.  true mu = 0, sigma = 1
loglik <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   sum(dnorm(x, mean=mu, sd=sigma, log=TRUE))
}
m <- maxLik(loglik, start=c(mu=1, sigma=2))
                           # give start value somewhat off
summary(m)
@ 
The algorithm converged in 5 iterations, and one can check that the
results are practically identical to sample mean and
variance.\footnote{Note that \R function \texttt{var} returns the
  unbiased
  estimator by using denominator
  $n-1$, the ML estimator is biased with denominator $n$.
}

This example demonstrates a number of key features of \verb|maxLik|:
\begin{itemize}
\item The first argument of \verb|logLik| is the parameter vector.  In
  this example we define it as $\vec{\theta} = (\mu, \sigma)$, and the
  first lines of \verb|logLik| are used to extract these values from
  the vector.
\item The \verb|logLik| function returns a single number, sum of
  individual log-likelihood contributions of individual $x$
  components.  (It may also return the components individually, see
  the description of BHHH below.)
\item Vector of start values must be of correct length.  In case the
  components are named, those names are also displayed for \verb|summary|
  (and for \verb|coef| and \verb|stdEr|, see below).
\item \verb|summary| method displays a handy summary of the results,
  including the convergence message, the estimated values, and
  statistical significance test results.
\end{itemize}
As we did not specify the optimizer, \verb|maxLik| picked
Newton-Raphson by default, and computed the necessary gradient and
Hessian matrix numerically.

Besides summary, \verb|maxLik| also contains a number of utility
functions to simplify handling of the estimated models:
\begin{itemize}
\item \verb|coef| extracts the model coefficients:
<<>>=
coef(m)
@   
\item \verb|stdEr| returns the standard errors (by inverting the
  corresponding Hessian).
<<>>=
stdEr(m)
@   
\item Other functions include \verb|logLik| to return the
  log-likelihood value, \verb|returnCode| and \verb|returnMessage| to
  return the convergence code and message respectively, and \verb|AIC|
  to return Akaike's information criterion.  See the respective
  documentation for more information.
\item One can also query the number of observations with \verb|nObs|,
  but this requires likelihood values to be supplied by observation (see
  the BHHH method below).
\end{itemize}


\subsection{Supplying gradients}
\label{sec:supplying-gradients}

The simple example above worked fast and well.  In particular, the
numeric gradients \verb|maxLik| had to compute implicitly
did not pose any problems.  But users are strongly
advised to supply at least analytic gradients.  More complex problems
may be intractably slow, fail to converge completely, or to converge to a
sub-optimal region if numeric gradients are too noisy.  Here we
demonstrate how to supply the gradient to the \verb|maxLik| function.

It is easy to see from~\eqref{eq:normal-loglik} that the gradient
components are
\begin{equation}
  \label{eq:loglik-gradient}
  \begin{split}
    \pderiv{\mu}\loglik(\mu, \sigma; x) &=
    \frac{x - \mu}{\sigma^{2}}
    \\
    \pderiv{\sigma}\loglik(\mu, \sigma; x) &=
    -\frac{1}{\sigma} + \frac{(x - \mu)^{2}}{\sigma^{3}}.
  \end{split}
\end{equation}
Hence we can program the gradient function as
<<>>=
gradlik <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   N <- length(x)  # number of observations
   gradient <- numeric(2)
   gradient[1] <- sum(x - mu)/sigma^2
   gradient[2] <- -N/sigma + sum((x - mu)^2)/sigma^3
   gradient
}
@ 
Note that have moved $1/\sigma^{2}$ out of \verb|sum| to avoid
redundant computations inside, we also have written $N/\sigma$ as the
term $1/\sigma$ must be summed for all observations (despite it being
invariant).  We also return gradient as a length-2 vector, not a
matrix.  The example with BHHH below demonstrates gradient in a matrix form.

Now we can supply this function to \verb|maxLik| as
<<>>=
m <- maxLik(loglik, gradlik, start=c(mu=1, sigma=2))
summary(m)
@ 
While these results are identical to the ones above with numeric
gradients, the algorithm is now much more robust, and much faster in
case of large number of parameters.

While this is perhaps the most straightforward way to compute
gradients, \maxlik also supports gradients (and Hessian) supplied as
log-likelihood function attribute.  This is motivated by the fact that
computing gradient often involves a number of similar computations as
gradient, and one may want to re-use the auxiliary results.  We
demonstrate this on the same example, but this time we do not rely on
the \verb|dnorm| function in order to show how certain results can be
reused:
<<>>=
loglikA <- function(theta) {
   ## log-likelihood with gradent attribute
   mu <- theta[1]
   sigma <- theta[2]
   N <- length(x)  # number of observations
   sse <- sum((x - mu)^2)  # we re-use this value for the gradient
   ## compute log likelihood
   ll <- -N*log(sqrt(2*pi)) - N*log(sigma) - 0.5*sse/sigma^2
   ## compute gradient
   gradient <- numeric(2)
   gradient[1] <- sum(x - mu)/sigma^2
   gradient[2] <- -N/sigma + sse/sigma^3
   attr(ll, "gradient") <- gradient
                           # add gradient as attribute 'gradient'
   ll
}
m <- maxLik(loglikA, gradlik, start=c(mu=1, sigma=2))
summary(m)
@
The log-likelihood with attribute \verb|loglikA| computes
log-likelihood as above, but also computes its gradient, and adds it
as attribute ``gradient'' to the log-likelihood.  This gives a
potential efficiency gain as sum of squared errors, \verb|sse|, is
re-used.  \maxlik checks the presence of the attribute, and if it is
there, it uses the provided gradient.  Obviously, in real applications
the efficiency gain will depend on the amount of computations re-used,
and the number of likelihood calls versus gradient calls.

While analytic gradients are always helpful and often necessary, they
may be hard to derive and code.  In order to help debugging the provided function,
\verb|compareDerivatives|, takes the log-likelihood function, analytic
gradent, and compares the numeric and analytic gradient.  As an
example, we compare the log-likelihood and gradient functions we coded above:
<<>>=
compareDerivatives(loglik, gradlik, t0=c(1,2))
                           # 't0' is the parameter value
@
The function prints the analytic gradient, numeric gradient, their
relative difference, and the largest relative difference (in absolute
value).  The latter is handy in case of large gradient vectors where
it may be hard to spot a lonely component that is off.
In case of reasonably smooth functions, expect
the relative difference to be smaller than $10^{-7}$.  In this simple
case it is of order $10^{-9}$.

Note that the gradient of log-likelihood, a scalar function, with
respect to length-2 parameter vector is
$1\times2$ matrix.  \maxlik uses numerator layout.


\subsection{Different optimizers}
\label{sec:different-optimizers}

By default, \maxlik uses Newton-Raphson optimizer but one can easily
swap the optimizer by \verb|method| argument.  The supported
optimizers include ``NR'' for the default Newton-Raphson, ``BFGS'' for
gradient-only Broyden-Fletcher-Goldfarb-Shannon, ``BHHH'' for the
information-equality based Berndt-Hall-Hall-Hausman, and ``NM'' for
gradient-less Nelder-Mead.  Different arguments 

For instance, although Newton-Raphson is a simple, fast and intuitive
method that approximates the function with a parabola, it needs to
know the Hessian matrix (the second derivatives).  This is usually
even harder to program, and even slower and more error-prone when
computed numerically.  Let us replace NR with gradient-only
BFGS:\footnote{Internally, BFGS approximates Hessian through gradient.}
<<>>=
m <- maxLik(loglik, gradlik, start=c(mu=1, sigma=2),
            method="BFGS")
summary(m)
@ 
One can see that the results were identical, but while NR converged in
5 iterations, it took 30 iterations for BFGS.  This is a manifestation
of the fact that providing more information (in this case gradient)
helps to find the solution.
In a similar fashion, one can use most other provided optimizers.
Each of those have their strong and weak sides.

One method that is very popular in case of maximum likelihood is
BHHH.  We discuss it here at length because that method requires both
log-likelihood and gradient function to return somewhat different
value.  The essence of BHHH is information equality, the fact that in
case of log-likelihood function $\loglik(\theta)$, the expected value
of Hessian at the true parameter value $\vec{\theta}_{0}$ can be
expressed through the expected value of the outer product of the
gradient: 
\begin{equation}
  \label{eq:information-equality}
  \E
  \left[
    \frac{\partial^2 l(\vec{\theta})}
    {\partial\vec{\theta} \partial\vec{\theta}'}
  \right]_{\vec{\theta} = \vec{\theta}_0}
  =
  - \E
  \left[
    \left.
      \frac{\partial l(\vec{\theta})}
      {\partial\vec{\theta}'}
    \right|_{\vec{\theta} = \vec{\theta}_0}
    % 
    \left.
      \frac{\partial l(\vec{\theta})}
      {\partial\vec{\theta}}
    \right|_{\vec{\theta} = \vec{\theta}_0}
  \right].
\end{equation}
Hence we can approximate Hessian by the average outer product of the
gradient.  Obviously, this is only an approximation, and it is less
correct when we are far from the true value $\vec{\theta}_{0}$.  Note
also that information equality relies on the assumption that the
observations are independent, and may not work with non-independent
data, such as time series observations.

However, in order to compute the average outer product, we need to
compute gradient \emph{by observation}.  Hence it is not enough to
just compute a single gradient vector, we have to compute a matrix
where rows correspond to individual data points and columns to the
parameter components.  The following example demonstrates the usage:
<<>>=
gradlikH <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   N <- length(x)  # number of observations
   gradient <- matrix(0, N, 2)  # gradient is matrix
   gradient[, 1] <- (x - mu)/sigma^2
                           # first column: derivative wrt mu
   gradient[, 2] <- -1/sigma + (x - mu)^2/sigma^3
                           # second column: derivative wrt sigma
   gradient
}
m <- maxLik(loglik, gradlikH, start=c(mu=1, sigma=2),
            method="BHHH")
summary(m)
@ 
The code of the new gradient function is similar to the previous one,
but we do not sum over the individual values.  Instead, we fill the
rows of the $N\times2$ gradient matrix with the values
observation-wise.

In case we do not have time and energy for analytic gradient, we can
do BHHH with numeric one.  In this case we have to supply the
log-likelihood by observation.  This essentially means we remove
summing from the original likelihood function:
<<>>=
loglikH <- function(theta) {
   mu <- theta[1]
   sigma <- theta[2]
   -log(sqrt(2*pi)) - log(sigma) - 0.5*(x - mu)^2/sigma^2
                           # no summing here
                           # also no 'N*' terms as we work by individual observations
}
m <- maxLik(loglikH, start=c(mu=1, sigma=2),
            method="BHHH")
summary(m)
@

Besides of relying on information equality, BHHH is
essentially the same algorithm as NR.  As the Hessian is just
approximated, its is converging at a slower pace than NR with analytic
Hessian.  But when relying on numeric derivatives, BHHH may be more
reliable. 

For convenience, the other methods also support
observation-wise gradients and log-likelihood values, those numbers
are just summed internally.  So one can just implement the
BHHH-compatible functions and use these for all supported optimizers.


\subsection{Control options}
\label{sec:control-options}

\maxlik supports a number of control options, most of which can be
supplied through \verb|control=list(...)| method.  Some of the most
important options include 
\verb|printLevel| to control debugging information, \verb|iterLim| to
control the maximum number of iterations, and various
\verb|tol|-parameters to control the convergence tolerances.  For
instance, we can limit the iterations to two, while also printing out
the parameter estimates at each step.  We use the previous
example with BHHH optimizer:
<<>>=
m <- maxLik(loglikH, start=c(mu=1, sigma=2),
            method="BHHH",
            control=list(printLevel=3, iterlim=2))
summary(m)
@
The first option, \verb|printLevel=3|, prints out parameters, gradient
a few other pieces of information at every step.  Printlevel 1 only
prints the first and last parameter values, and larger numbers print
more information.  The output from \maxlik-implemented
optimizers is fairly consistent, but optimizers that are based
code from other packages, such as BFGS, may output debugging
information in a quite different way.  We can also see that the
algorithm now returned after just two iterations with code 4:
iteration limit exceeded. 

Other sets of handy options are the convergence tolerances.  There are
three convergence tolerances:
\begin{description}
\item[tol] This measures
  the absolute convergence tolerance.  Stop if
  successive function evaluations
  differ by less than \emph{tol} (default $10^{-8}$).  
\item[reltol] This is somewhat similar to \emph{tol}, but relative to
  the function value.  Stop if successive function evaluations differ by less than
  $\mathit{reltol}\cdot (\loglik(\vec{\theta}) + \mathit{reltol})$
  (default \verb|sqrt(.Machine[["double.eps"]])|).
\item[gradtol] stop if the (Euclidean) norm of the gradient is smaller
  than this value (default $10^{-6}$).
\end{description}
The default values are typically good enough, but in certain cases one
may want to switch off certain tolerance-based criteria.  For
instance, in case our function values are very small, we may want to
rely only on the relative tolerance.  A simple way to achieve this is
to set both \emph{tol} and \emph{gradtol} to negative values.  In that
case these two conditions are never satisfied and the algorithm stops
only when the relative convergence criterion is fulfilled.  We
demonstrate this with the BHHH example with no iteration limit:
<<>>=
m <- maxLik(loglikH, start=c(mu=1, sigma=2),
            method="BHHH",
            control=list(tol=-1, gradtol=-1))
summary(m)
@ 

Note that stochastic gradient ascent, rarely used for ML estimation,
relies on different convergence criteria.  See the dedicated vignette
``Stochastic Gradient Ascent in \maxlik''.


\section{Advanced usage}
\label{sec:advanced-usage}

This section describes more advanced and less frequently used aspects
of \maxlik.

\subsection{Additional arguments to the log-likelihood function}
\label{sec:additional-arguments-loglik}

The only rule about the arguments for the log-likelihood is that its
first argument must be the parameter vector.  But one can have more
arguments and pass those through \maxlik as additional arguments to
the \verb|maxLik| function.  For instance, let's change the
log-likelihood function in a way that it expects data $\vec{x}$ to be
passed as an argument.  Now we just have to add \verb|x| as an
additional argument:
<<>>=
loglik <- function(theta, x) {
   mu <- theta[1]
   sigma <- theta[2]
   sum(dnorm(x, mean=mu, sd=sigma, log=TRUE))
}
m <- maxLik(loglik, start=c(mu=1, sigma=2), x=x)
summary(m)
@
This approach works with most of the argument names, except with those
that are the same as \verb|maxLik|'s arguments.  In the latter case it
prints an informative error message.


\subsection{Maximizing other functions}
\label{sec:maximizing-other-functions}

The \verb|maxLik| function is basically just a wrapper to a number of
maximization algorithms, together with likelihood-related goodies like
standard errors.  However, from time-to-time we need to optimize other
functions where inverting the Hessian to compute standard errors is
not applicable.  In such cases one can call the included optimizers
directly, using the form \verb|maxXXX| where \verb|XXX| stands for the
name of the method, e.g. \verb|maxNR| for Newton-Rapshon
(\verb|method="NR"|) and \verb|maxBFGS| for BFGS.  There is also
\verb|maxBHHH| although the information equality--based BHHH is not
correct if we do not work with likelihood function.  Let us optimize
the 2-dimensional bell curve,
\begin{equation}
  \label{eq:2d-bell-curve}
  f(x, y) = \me^{-x^{2} - y^{2}}:
\end{equation}
<<>>=
f <- function(theta) {
   x <- theta[1]
   y <- theta[2]
   exp(-x^2 - y^2)
                           # optimum at (0, 0)
}
m <- maxBFGS(f, start=c(1,1))
                           # give start value a bit off
summary(m)
@
Note that the summary output is slightly different: if reports the
parameter and gradient value, appropriate for a task that is not
likelihood optimization.  Note also that BFGS, based on the
\verb|stats::optim| does not report the convergence results in a
similar way as BHHH and NR, the algorithms provided by the \maxlik
package. 


condiNumber, 

fixed coefficients

mention SGA

\subsection{Tips and tricks}
\label{sec:suggestions}

analytic gradients

speed of convergence


\subsection{TODO}

example with Hessian

% \bibliographystyle{apecon}
% \bibliography{maxlik}

\end{document}
