\documentclass[12pt,a4paper]{article}

\usepackage{url}
\usepackage{amsmath}
\usepackage{Sweave}

\renewcommand{\title}[1]{\begin{center}{\bf \LARGE #1}\end{center}}
\newcommand{\affiliations}{\footnotesize}
\newcommand{\keywords}{\paragraph{Keywords:}}

\setlength{\oddsidemargin}{0cm} \setlength{\evensidemargin}{0cm}
\setlength{\textwidth}{16.5cm} \setlength{\topmargin}{-1cm}
\setlength{\textheight}{24.5cm}

\newcommand{\code}[1]{\texttt{#1}}
\setlength{\emergencystretch}{3em}

\begin{document}
\pagestyle{empty}

\title{maxLik: A Package for Maximum\\[3mm]Likelihood Estimation in \textsf{R}}

\begin{center}
  {\bf Ott Toomet$^{1,2}$ and Arne Henningsen$^{3,*}$}
\end{center}

\begin{affiliations}
1. Department of Economics, University of Tartu (Estonia)\par
2. Department of Economics, Aarhus School of Business, University of Aarhus (Denmark)\par
3. Institute of Food and Resource Economics, University of Copenhagen (Denmark)\par
* Contact author: arne.henningsen@gmail.com
\end{affiliations}

\keywords Maximum Likelihood, Optimisation

\vskip 0.8cm

The Maximum Likelihood (ML) method is one of the most important
techniques in statistics and econometrics.
Most statistical and econometric software packages include
ready-made routines for maximum likelihood estimations
of many standard models such as logit, probit, sample-selection,
count-data, or survival models.
However, if practitioners and researchers want to estimate
non-standard models or develop new models,
they have to implement the routines
for the maximum-likelihood estimations themselves.
In this case, the \textbf{maxLik} package~\cite{r-maxlik-0.5}
for the statistical software environment \textsf{R} \cite{r-project09}
might be very helpful.
Furthermore, developers that implement routines for maximul likelihood
estimations of specific models,
can save time and lines of code by using the \textbf{maxLik} package.
The \textbf{maxLik} package is available from
CRAN (\url{http://cran.r-project.org/package=maxLik}),
R-Forge (\url{http://r-forge.r-project.org/projects/maxlik/}), and its
homepage (\url{http://www.maxLik.org/}).

The most important tool for a user of the \textbf{maxLik} package
is probably the \code{maxLik} function.
It is a wrapper function
that delegates the maximum likelihood estimation
to the selected optimisation routine.
Five optimisation methods are currently available
(names of the corresponding functions in parenthesis):
Newton-Raphson (\code{maxNR}),
Berndt-Hall-Hall-Hausman (\code{maxBHHH} \cite{berndt74}),
Broyden-Fletcher-Goldfarb-Shanno~(\code{maxBFGS}
\cite{broyden70,fletcher70,goldfarb70,shanno70}),
Nelder-Mead~(\code{maxNM} \cite{nelder65}), and
simulated-annealing~(\code{maxSANN} \cite{belisle92}).
While the actual optimisation in
\code{maxBFGS}, \code{maxNM}, and \code{maxSANN}
is done by \code{optim},
the Newton-Raphson algorithm is implemented
in the function \code{maxNR} itself.
The actual optimisation in \code{maxBHHH}
is done by \code{maxNR}.

The first argument of \code{maxLik} (\code{loglik})
is mandatory and specifies the log-likelihood function.
Its first argument must be the vector of the parameters to be estimated
and it must return either a single log-likelihood value or
a numeric vector where each component is the log-likelihood value
corresponding to an individual observations.
The second and third argument (\code{grad} and \code{hess})
are optional and can be used to specify functions
that return the gradients and the Hessian of the objective function,
respectively.
If these functions are not provided by the user,
numerical gradients and Hessians are calculated if necessary.
The fourth argument (\code{start}) is mandatory and
must be used to specify a vector of starting values.
Finally, the fifth argument (\code{method}) is optional and
can be used to select the maximisation routine.
It defaults to \code{"NR"}, but it can also be \code{"BHHH"},
\code{"BFGS"}, \code{"NM"}, or \code{"SANN"}.  The \code{maxLik}
wrapper capabilities are designed in a transparent way, so that the
user can easily swap the methods without changing the
arguments.  The arguments not used by a particular optimisation
method, such as \code{hess} for the Berndt-Hall-Hall-Hausman method,
are ignored.

The \textbf{maxLik} package is implemented using S3 classes.
The \code{maxLik} wrapper returns a list of class \code{"maxLik"}.
Corresponding methods can handle the likelihood-specific properties
of the estimate including the fact
that the inverse of the negative Hessian is the variance-covariance matrix
of the estimated parameters.
The most important methods for objects of class \code{"maxLik"} are:
\code{summary} for returning (and printing) summary results,
\code{coef} for extracting the estimated parameters,
\code{vcov} for calculating the variance covariance matrix
of the estimated parameters,
\code{logLik} for extracting the log likelihood value, and
\code{AIC} for calculating the Akaike information criterion.

Currently, the \textbf{maxLik} package is used for maximum likelihood
estimations in three \textsf{R} packages that are available on CRAN:
\textbf{mlogit}, \textbf{sampleSelection},
and \textbf{truncreg}.
On the DSC conference,
we would like to demonstrate the implementation and the usage
of the \textbf{maxLik} package.
Furthermore, we want to discuss future improvements and features
with other participants
in order to make the \textbf{maxLik} package more attractive
to users and package writers.

After installing the \textbf{maxLik} package,
it must be loaded before it can be used.
The following command loads the \textbf{maxLik} package.
<<>>=
library( maxLik )
@

We demonstrate the usage of this package by a simple example:
we fit a normal distribution by maximum likelihood.
First, we generate a vector ($x$) of 100 draws
from a normal distribution with a mean of $\mu = 1$
and a standard deviation of~$\sigma = 2$:
<<echo=FALSE,results=hide>>=
set.seed( 123 )
@
<<>>=
x <- rnorm( 100, mean = 1, sd = 2 )
@
%
The probability density function of a standard normal distribution
for a value $x_i$ is
\begin{equation}
P(x_i) =
\frac{1}{\sigma \sqrt{2 \pi}}
\exp \left( - \frac{( x_i - \mu )^2}{2 \sigma^2} \right).
\end{equation}
Hence, the likelihood function for $\mu$, $\sigma$,
and the values in vector $x = ( x_1, \ldots, x_N )$ is
\begin{equation}
L( x, \mu, \sigma ) = \prod_{i=1}^N
\frac{1}{\sigma \sqrt{2 \pi}}
\exp \left( - \frac{( x_i - \mu )^2}{2 \sigma^2} \right)
\end{equation}
and its logarithm (i.e.\ the log likelihood function) is
\begin{equation}
\log( L( x, \mu, \sigma ) ) =
- \frac{1}{2} N \log ( 2 \pi ) - N \log ( \sigma )
- \frac{1}{2} \sum_{i=1}^N \frac{( x_i - \mu )^2}{\sigma^2}.
\end{equation}

The first step for the maximum likelihood estimation
is the implementation of the log likelihood function in \textsf{R}.
<<>>=
logLikFun <- function( param ) {
   mu <- param[ 1 ]
   sigma <- param[ 2 ]
   N <- length( x )
   logLikValue <- -0.5 * N * log( 2 * pi ) - N * log( sigma ) -
      0.5 * sum( ( x - mu )^2 / sigma^2 )
   return( logLikValue )
}
@
Now, we can use the \texttt{maxLik} function ---
which is probably the most important user interface
of the \textbf{maxLik} package ---
to find the values for the $\mu$ and $\beta$ parameters
that give the best fit, i.e.\ the largest value of the (log)
likelihood function.
We use the parameters of a standard normal distribution
($\mu = 0$, $\sigma = 1$) as starting values.
<<>>=
mle <- maxLik( logLik = logLikFun, start = c( 0, 1 ) )
mle
@
As expected, the estimated parameters are equal to the mean
and the standard deviation (without correction for degrees of freedom)
of the values in vector~$x$.
<<>>=
mean( x )
sqrt( var( x ) * 99 / 100 )
@

If no analytical gradients are provided by the user,
the optimisation algorithm uses numerical gradients.
While the maximisation of the likelihood function of this simple model
works well with numerical gradients,
providing analytical gradients could increase the speed and probability
of convergence.
The gradients of the likelihood function of the standard normal distribution
are
\begin{align}
\frac{\partial \log( L( x, \mu, \sigma ) )}{ \partial \mu } & =
   \sum_{i=1}^N \frac{( x_i - \mu )}{\sigma^2}\\
\frac{\partial \log( L( x, \mu, \sigma ) )}{ \partial \sigma } & =
   - \frac{ N }{ \sigma }
   + \sum_{i=1}^N \frac{( x_i - \mu )^2}{\sigma^3}.
\end{align}
These gradients can be calculated by following function:
<<>>=
logLikGrad <- function( param ) {
   mu <- param[ 1 ]
   sigma <- param[ 2 ]
   N <- length( x )
   logLikGradValues <- numeric( 2 )
   logLikGradValues[ 1 ] <- sum( ( x - mu ) / sigma^2 )
   logLikGradValues[ 2 ] <- - N / sigma + sum( ( x - mu )^2 / sigma^3 )
   return( logLikGradValues )
}
@
This function can be provided to the \texttt{maxLik} function
as an additional argument \texttt{grad}:
<<>>=
mleGrad <- maxLik( logLik = logLikFun, grad = logLikGrad, start = c( 0, 1 ) )
all.equal( mleGrad, mle )
names( mle )[ c(3,4) ]
@
Providing analytical gradients has no significant effect on the estimates
but the gradients and the Hessian calculated at the maximum
of the likelihood function are slightly different.%
\footnote{%
\texttt{all.equal} considers two elements as unequal
if both the mean absolute difference and the mean relative difference
is larger than the tolerance
(defaults to \texttt{.Machine\$double.eps\^{ }0.5},
usually \Sexpr{round(.Machine$double.eps^0.5,10)}).
}

Moreover, the user can provide a function to calculate the Hessian
analytically.
The elements of the Hessian are
\begin{align}
\frac{\partial^2 \log( L( x, \mu, \sigma ) )}{ ( \partial \mu )^2 } & =
   - \frac{ N }{\sigma^2}\\
\frac{\partial^2 \log( L( x, \mu, \sigma ) )}{ \partial \mu \; \partial \sigma } & =
   - 2 \sum_{i=1}^N \frac{( x_i - \mu )}{\sigma^3}\\
\frac{\partial^2 \log( L( x, \mu, \sigma ) )}{ ( \partial \sigma )^2 } & =
   \frac{ N }{ \sigma^2 }
   - 3 \sum_{i=1}^N \frac{( x_i - \mu )^2}{\sigma^4}.
\end{align}
<<>>=
logLikHess <- function( param ) {
   mu <- param[ 1 ]
   sigma <- param[ 2 ]
   N <- length( x )
   logLikHessValues <- matrix( 0, nrow = 2, ncol = 2 )
   logLikHessValues[ 1, 1 ] <- - N / sigma^2
   logLikHessValues[ 1, 2 ] <-  - 2 * sum( ( x - mu ) / sigma^3 )
   logLikHessValues[ 2, 1 ] <- logLikHessValues[ 1, 2 ]
   logLikHessValues[ 2, 2 ] <- N / sigma^2 - 3 * sum( ( x - mu )^2 / sigma^4 )
   return( logLikHessValues )
}
@
This function can be provided to the \texttt{maxLik} function
by the argument \texttt{hess}:
<<>>=
mleHess <- maxLik( logLik = logLikFun, grad = logLikGrad,
   hess = logLikHess, start = c( 0, 1 ) )
all.equal( mleHess, mleGrad )
@
Providing an analytical Hessian has no significant effect
on the outcome of the ML estimation.


\bibliographystyle{amsplain}
\bibliography{agrarpol}

\end{document}
